"""
Frontmatter generator for Z-Beam Gene    def _format_image_url(self, image_type, extension="jpg") -> str:
        """Format image URL based on image type.
        
        Args:
            image_type: Type of image (e.g., 'hero', 'thumbnail')
            extension: File extension (default: 'jpg')
            
        Returns:
            str: Formatted image URL
        """
        base_url = "/images"
        slug = self.data.get("slug", "").strip()
        
        if not slug:
            # Generate a fallback slug if not available
            title = self.data.get("title", "untitled").lower()
            slug = "-".join(title.split())
        
        # Format URL with appropriate components
        return f"{base_url}/{slug}-{image_type}.{extension}"implementation with robust error handling and auto-recovery.
"""

import logging
import yaml
import re
from components.base.component import BaseComponent
from components.base.utils.validation import (
    validate_length, validate_required_fields, validate_category_consistency
)
from components.base.utils.formatting import format_frontmatter_with_comment

logger = logging.getLogger(__name__)

class FrontmatterGenerator(BaseComponent):
    """Generator for article frontmatter with robust validation and auto-recovery."""
    
    def _get_prompt_path(self) -> str:
        """Override to use the correct directory name.
        
        Returns:
            str: Path to prompt template
        """
        return "components/frontmatter/prompt.yaml"
    
    def _get_base_data(self) -> dict:
        """Get base data for the prompt template."""
        data = super()._get_base_data()
        return data
    
    def _get_subject_slug(self) -> str:
        """Get standardized subject slug for URLs.
        
        Returns:
            str: Hyphenated lowercase subject name
        """
        return self.subject.lower().replace(' ', '-').replace('_', '-')
    
    def _format_image_url(self, image_type, extension="jpg") -> str:
        """Generate standardized image URL.
        
        Args:
            image_type: Type of image (hero, closeup)
            extension: File extension (default: jpg)
            
        Returns:
            str: Formatted image URL
        """
        subject_slug = self._get_subject_slug()
        
        # For consistency with original code, closeup images sometimes omit "laser-cleaning-"
        if image_type == "closeup" and self._use_short_closeup_url():
            return f"/images/{subject_slug}-closeup.{extension}"
        
        return f"/images/{subject_slug}-laser-cleaning-{image_type}.{extension}"
    
    def _use_short_closeup_url(self) -> bool:
        """Determine if we should use short URL format for closeup images.
        This maintains backward compatibility with existing content.
        """
        # Default to false for new content, implement your logic here
        # if needed to maintain consistency with existing URLs
        return False
    
    def _process_images(self, data) -> dict:
        """Process all image URLs in the data dictionary.
        
        Args:
            data: Dictionary containing image data
            
        Returns:
            dict: Updated data with standardized image URLs
        """
        if not isinstance(data, dict) or "images" not in data:
            return data
            
        for image_type, image_data in data["images"].items():
            if isinstance(image_data, dict):
                # If URL is missing or empty, generate standardized URL
                if "url" not in image_data or not image_data["url"]:
                    image_data["url"] = self._format_image_url(image_type)
                else:
                    # Normalize existing URL
                    url = image_data["url"].lower()
                    
                    # Remove domain if present (handle various formats)
                    if "://" in url:
                        url = "/" + "/".join(url.split("/")[3:])
                    
                    # Ensure URL starts with /images/
                    if not url.startswith("/images/"):
                        url = "/images/" + url.split("/")[-1]
                    
                    # Get extension (default to jpg)
                    extension = "jpg"
                    if "." in url:
                        extension = url.split(".")[-1]
                    
                    # Create standardized URL
                    image_data["url"] = self._format_image_url(image_type, extension)
        
        return data
    
    def _extract_yaml_from_markdown(self, content) -> str:
        """Extract YAML content from markdown code block if needed.
        
        Args:
            content: Raw content that might be markdown
            
        Returns:
            str: Extracted YAML content
        """
        if not content.startswith('```yaml') and not content.startswith('```'):
            return content
            
        lines = content.split('\n')
        content_lines = []
        in_yaml_block = False
        
        for line in lines:
            if line.startswith('```yaml') or line.startswith('```'):
                if in_yaml_block:
                    break  # End of YAML block
                in_yaml_block = True
                continue
            if in_yaml_block:
                content_lines.append(line)
        
        if content_lines:
            return '\n'.join(content_lines)
        
        logger.warning("Failed to extract YAML content from markdown code block")
        return content
    
    def _cleanup_string_values(self, data) -> dict:
        """Clean up string values by handling escape sequences.
        
        Args:
            data: Dictionary with string values to clean up
            
        Returns:
            dict: Dictionary with cleaned string values
        """
        if not isinstance(data, dict):
            return data
            
        for key, value in list(data.items()):
            if isinstance(value, str) and '\\' in value:
                # Handle line continuations with \\n
                if "\\n" in value:
                    data[key] = value.replace("\\n", "\n")
                
                # Remove backslash+space sequences
                data[key] = data[key].replace('\\ ', ' ')
                
                # Handle YAML's line continuation format with backslashes at line end
                if data[key].endswith('\\'):
                    lines = data[key].split('\\')
                    if len(lines) > 1:
                        # Join with actual newlines and strip whitespace from each line
                        data[key] = '\n'.join(line.strip() for line in lines if line.strip())
            
            # Recursively process nested dictionaries
            elif isinstance(value, dict):
                data[key] = self._cleanup_string_values(value)
            
            # Process items in a list
            elif isinstance(value, list):
                for i, item in enumerate(value):
                    if isinstance(item, dict):
                        value[i] = self._cleanup_string_values(item)
        
        return data
    
    def _sanitize_content(self, content: str) -> str:
        """Remove malformed content and standardize image URLs.
        
        Args:
            content: String content to sanitize
            
        Returns:
            str: Sanitized content
        """
        # Remove standalone URL fragments
        lines = content.split('\n')
        cleaned_lines = []
        
        for line in lines:
            # Skip standalone lines with broken URL fragments
            if re.match(r'^-*>*-*laser-cleaning.*\.jpg$', line.strip()):
                continue
            cleaned_lines.append(line)
        
        content = '\n'.join(cleaned_lines)
        
        # Fix URLs with arrow characters
        content = re.sub(r'-+>+-*', '-', content)
        content = re.sub(r'([^a-z])>+-*', r'\1', content)
        
        # Fix missing hyphens between subject and "laser-cleaning"
        content = re.sub(r'(/images/[a-z0-9-]+)laser-cleaning', r'\1-laser-cleaning', content)
        
        return content
    
    def _generate_placeholder(self, field_name) -> any:
        """Generate a placeholder value for a missing required field.
        
        Args:
            field_name: Name of the field to generate placeholder for
            
        Returns:
            any: Appropriate placeholder value for the field
        """
        if field_name == "name":
            return self.subject
            
        elif field_name == "title":
            return f"{self.subject} Laser Cleaning | Technical Guide"
            
        elif field_name == "headline":
            return f"Technical guide to {self.subject} for laser cleaning applications"
            
        elif field_name == "description":
            return f"A comprehensive technical overview of {self.subject} for laser cleaning applications, including properties, composition, and optimal processing parameters."
            
        elif field_name == "author":
            # Use author data from BATCH_CONFIG
            if self.author_data and "author_name" in self.author_data:
                author = {
                    "name": self.author_data["author_name"],
                    "country": self.author_data["author_country"],
                    "credentials": self.author_data.get("author_title", "Laser Cleaning Expert") + 
                                   (", " + self.author_data.get("author_specialties", [""])[0] if self.author_data.get("author_specialties") else "")
                }
                # Add author ID if available
                if "author_id" in self.author_data:
                    author["id"] = self.author_data["author_id"]
                return author
            else:
                # Fallback if author data is not available
                return {
                    "name": "Material Science Institute", 
                    "country": "United States",
                    "credentials": f"Expert in {self.subject} and Laser Cleaning Technology"
                }
                
        elif field_name == "keywords":
            keywords = [
                f"{self.subject.lower()} laser cleaning",
                f"{self.subject.lower()} surface treatment",
                "laser ablation",
                "non-contact cleaning",
                "industrial laser applications",
                "precision surface cleaning"
            ]
            
            # Add category-based keywords
            if hasattr(self, 'category') and self.category:
                keywords.append(f"{self.category.lower()} laser cleaning")
                keywords.append(f"{self.category.lower()} materials")
                
            # Add type-specific keywords
            if self.article_type == "material":
                keywords.extend([
                    "material properties",
                    "surface preparation",
                    "contaminant removal",
                    "high-temperature materials"
                ])
            
            return keywords
            
        elif field_name == "category":
            if hasattr(self, 'category') and self.category:
                return self.category
            else:
                return "unknown"
                
        elif field_name == "chemicalProperties":
            # Use material formula service if available
            try:
                from components.base.material_formula_service import get_material_formula, get_material_symbol
                formula = get_material_formula(self.subject)
                symbol = get_material_symbol(self.subject)
                
                if formula and symbol:
                    return {
                        "formula": formula,
                        "symbol": symbol,
                        "materialType": getattr(self, 'category', "unknown")
                    }
                else:
                    return {"formula": "N/A", "symbol": "N/A", "materialType": getattr(self, 'category', "unknown")}
            except (ImportError, Exception):
                return {"formula": "N/A", "symbol": "N/A", "materialType": getattr(self, 'category', "unknown")}
                
        elif field_name == "properties":
            return {
                "density": "See technical datasheet",
                "meltingPoint": "See technical datasheet",
                "hardness": "See technical datasheet",
                "thermalConductivity": "See technical datasheet",
                "laserType": "Nd:YAG or fiber laser (1064nm)",
                "wavelength": "1064 nm (IR range)",
                "fluenceRange": "1-10 J/cm²"
            }
            
        elif field_name == "applications":
            return [
                {"name": "Industrial Cleaning", "description": f"Surface preparation of {self.subject} components for manufacturing processes"},
                {"name": "Precision Maintenance", "description": f"Removal of contaminants from {self.subject} surfaces without damage"},
                {"name": "Surface Preparation", "description": f"Pre-treatment of {self.subject} for coating or bonding applications"}
            ]
            
        elif field_name == "environmentalImpact":
            return [
                {"benefit": "Chemical Reduction", "description": "Eliminates need for hazardous chemical cleaners, reducing environmental impact"},
                {"benefit": "Energy Efficiency", "description": "Consumes less energy than traditional cleaning methods, with precise energy application"}
            ]
            
        elif field_name == "technicalSpecifications":
            return {
                "powerRange": "100-1000W (pulsed)",
                "pulseDuration": "10-200ns",
                "wavelength": "1064nm ±2nm",
                "spotSize": "0.05-3mm",
                "repetitionRate": "10-500kHz",
                "fluenceRange": "0.5-20 J/cm²",
                "safetyClass": "IV (enclosed system)"
            }
            
        elif field_name == "outcomes":
            return [
                {"result": "High purity surface", "metric": "SEM contamination analysis"},
                {"result": "Precise surface preparation", "metric": "Surface profilometry measurements"}
            ]
            
        elif field_name == "composition":
            return [{
                "component": self.subject,
                "percentage": "99-100%",
                "type": "primary"
            }]
            
        elif field_name == "compatibility":
            return [
                {"material": "Stainless Steel", "application": "Surface preparation"},
                {"material": "Various metals", "application": "Contaminant removal"}
            ]
            
        elif field_name == "regulatoryStandards":
            return [
                {"code": "ISO Standards", "description": "International standards for material quality and processing"},
                {"code": "ASTM Standards", "description": "American standards for material testing and specification"}
            ]
            
        elif field_name == "images":
            return {
                "hero": {
                    "alt": f"Industrial laser system cleaning {self.subject} components in a manufacturing facility, showing precise beam positioning",
                    "url": self._format_image_url("hero")
                },
                "closeup": {
                    "alt": f"Microscopic view of {self.subject} surface after laser cleaning, revealing uniform texture and contaminant-free grain structure",
                    "url": self._format_image_url("closeup")
                }
            }
            
        else:
            return f"Placeholder for {field_name}"
    
    def _fix_common_model_errors(self, parsed: dict) -> dict:
        """Fix common errors in model-generated frontmatter.
        
        Args:
            parsed: The parsed frontmatter data
            
        Returns:
            dict: Frontmatter with fixed common errors
        """
        # Handle materialProfile wrapper (sometimes the model wraps everything in this object)
        if len(parsed.keys()) == 1 and 'materialProfile' in parsed and isinstance(parsed['materialProfile'], dict):
            logger.warning("Found 'materialProfile' wrapper, extracting contents")
            profile_data = parsed.pop('materialProfile')
            # Merge the profile data into the main dictionary
            parsed.update(profile_data)
            logger.info(f"Extracted fields from materialProfile: {list(profile_data.keys())}")
        
        # Special handling for common error: using 'title' instead of 'name'
        if 'name' not in parsed and 'title' in parsed:
            # Auto-fix instead of error
            logger.warning("Found 'title' field but 'name' is required. Copying 'title' to 'name'.")
            parsed['name'] = parsed['title']
        
        # Ensure name field only contains the subject name
        if 'name' in parsed and parsed['name'] != self.subject:
            logger.warning(f"Name field '{parsed['name']}' doesn't match subject '{self.subject}'. Setting to subject only.")
            parsed['name'] = self.subject
            
        return parsed
    
    def _ensure_schema_structure(self, parsed: dict) -> dict:
        """Ensure the frontmatter follows the schema structure for the article type.
        
        Args:
            parsed: The parsed frontmatter data
            
        Returns:
            dict: The frontmatter with enforced schema structure
        """
        profile_key = f"{self.article_type}Profile"
        
        if profile_key not in self.schema:
            logger.warning(f"No schema found for article type: {self.article_type}")
            return parsed
            
        schema_structure = self.schema[profile_key]
        
        # Check for generatorConfig section which might contain structure information
        if "generatorConfig" in schema_structure:
            config = schema_structure["generatorConfig"]
            
            # Extract any field mapping or structure information
            if "fieldContentMapping" in config:
                field_mappings = config["fieldContentMapping"]
                
                # Ensure all mapped fields exist in the frontmatter
                for field_name in field_mappings.keys():
                    if field_name not in parsed:
                        logger.warning(f"Adding missing field from schema mapping: {field_name}")
                        parsed[field_name] = f"Information about {field_name} for {self.subject}"
            
            # Check for research structure if available
            if "research" in config and "dataStructure" in config["research"]:
                data_structure = config["research"]["dataStructure"]
                
                # Validate complex nested structures based on schema
                for field_name, field_structure in data_structure.items():
                    if field_name in parsed:
                        # Check if field should be an object but isn't
                        if field_structure.get("type") == "object" and not isinstance(parsed[field_name], dict):
                            logger.warning(f"Field {field_name} should be an object, converting")
                            parsed[field_name] = {}
                            
                        # Check if field should be an array but isn't
                        if field_structure.get("type") == "array" and not isinstance(parsed[field_name], list):
                            logger.warning(f"Field {field_name} should be an array, converting")
                            parsed[field_name] = []
        
        return parsed
    
    def _enforce_length_limits(self, parsed: dict) -> dict:
        """Enforce length limits on frontmatter fields.
        
        Args:
            parsed: The parsed frontmatter data
            
        Returns:
            dict: Frontmatter with enforced length limits
        """
        # Title and headline should be concise
        if "title" in parsed:
            validate_length(parsed["title"], 0, 100, "Title", "chars")
        
        if "headline" in parsed:
            validate_length(parsed["headline"], 0, 150, "Headline", "chars")
        
        # Description and summary should be reasonable length
        if "description" in parsed:
            # Auto-truncate description if it's too long
            if len(parsed["description"]) > 250:
                logger.warning(f"Description too long ({len(parsed['description'])} chars), truncating to 250 chars")
                parsed["description"] = parsed["description"][:247] + "..."
            
            # Just validate after truncating
            validate_length(parsed["description"], 0, 250, "Description", "chars")
        
        # Keywords should be limited in number and length
        if "keywords" in parsed and isinstance(parsed["keywords"], list):
            if len(parsed["keywords"]) > 15:
                logger.warning(f"Too many keywords: {len(parsed['keywords'])}, truncating to 15")
                parsed["keywords"] = parsed["keywords"][:15]
            
            for i, keyword in enumerate(parsed["keywords"]):
                if len(keyword) > 50:
                    logger.warning(f"Keyword too long: {keyword}")
                    parsed["keywords"][i] = keyword[:47] + "..."
        
        return parsed
    
    def _add_missing_required_fields(self, parsed: dict, required_fields: list) -> dict:
        """Add missing required fields with placeholders.
        
        Args:
            parsed: The parsed frontmatter data
            required_fields: List of required field names
            
        Returns:
            dict: Frontmatter with all required fields
        """
        for field in required_fields:
            if field not in parsed:
                logger.warning(f"Auto-fixing missing required field: {field}")
                parsed[field] = self._generate_placeholder(field)
        
        return parsed
    
    def _component_specific_processing(self, content: str) -> str:
        """Process the generated frontmatter with enhanced error handling.
        
        Args:
            content: Pre-validated, clean API response
            
        Returns:
            str: Validated and formatted frontmatter
            
        Raises:
            ValueError: If content is invalid
        """
        # Extract YAML if content is in a markdown code block
        content = self._extract_yaml_from_markdown(content)
        
        # Attempt to parse as YAML to validate structure
        try:
            parsed = yaml.safe_load(content)
            if not isinstance(parsed, dict):
                raise ValueError("Frontmatter must be a valid YAML dictionary")
        except yaml.YAMLError as e:
            # Additional debugging
            logger.error(f"YAML parsing error: {e}")
            logger.error(f"Content causing error: {content}")
            raise ValueError(f"Invalid YAML in frontmatter: {e}")
        
        # Get validation requirements from schema
        profile_key = f"{self.article_type}Profile"
        if profile_key not in self.schema:
            raise ValueError(f"Missing schema for article type: {self.article_type}. Schema should contain {profile_key}.")
            
        validation = self.schema[profile_key]["validation"]["frontmatter"]
        required_fields = validation["requiredFields"]
        
        # Log validation info
        logger.info(f"Validating frontmatter for article type '{self.article_type}' with required fields: {required_fields}")
        logger.info(f"Frontmatter contains fields: {list(parsed.keys())}")
        
        # Process the data in a series of transformation steps
        parsed = self._fix_common_model_errors(parsed)
        parsed = self._enforce_length_limits(parsed)
        parsed = self._add_missing_required_fields(parsed, required_fields)
        parsed = self._ensure_schema_structure(parsed)
        parsed = self._cleanup_string_values(parsed)
        parsed = self._process_images(parsed)
        
        # Clean content - use allow_unicode to preserve Unicode characters properly
        cleaned_content = yaml.dump(parsed, default_flow_style=False, sort_keys=False, allow_unicode=True)
        
        # Store parsed frontmatter for other components to access
        self._frontmatter_data = parsed
        
        # Get category from instance attribute
        category = getattr(self, 'category', '')
        
        # Format frontmatter with HTML comment (metadata comment first, then frontmatter)
        final_content = format_frontmatter_with_comment(
            cleaned_content, category, self.article_type, self.subject
        )
        
        # Run required fields validation to ensure we've fixed everything
        try:
            validate_required_fields(parsed, required_fields, "frontmatter")
            logger.info("All required fields are now present in frontmatter")
        except ValueError as e:
            logger.error(f"Auto-fixing failed, still missing fields: {e}")
            raise
        
        # Final sanitization to remove malformed parts and standardize image URLs
        final_content = self._sanitize_content(final_content)
        
        return final_content
    
    def validate_category_consistency(self, content: str) -> bool:
        """Validates category consistency in frontmatter.
        
        Args:
            content: Frontmatter content
            
        Returns:
            bool: True if consistent
        """
        category = getattr(self, 'category', None)
        if not category:
            return True
            
        return validate_category_consistency(content, category, self.article_type, self.subject)
    
    def _process_response(self, response_data):
        """Process the raw response data from the AI model."""
        # Apply image URL formatting
        return self._process_images(response_data)
