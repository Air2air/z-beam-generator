#!/usr/bin/env python3
"""
ValidationOrchestrator - Unified Validation Interface

Consolidates all validation operations into a single, coordinated interface.
Replaces the scattered validation entry points with a comprehensive orchestrator.

Consolidates:
- validation/services/pre_generation_service.py
- validation/services/post_generation_service.py  
- components/frontmatter/services/validation_service.py
- components/frontmatter/services/material_auditor.py
- Legacy validation utilities

Follows fail-fast principles:
- No mocks or fallbacks in production
- Explicit error handling with specific exception types
- Validates all inputs immediately
- Single point of validation coordination

Author: Consolidation Phase 1 - October 22, 2025
"""

import logging
from pathlib import Path
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, field
from datetime import datetime

# Import validation results and errors
from validation.errors import ValidationError, ValidationResult, ErrorSeverity

# Lazy imports to avoid circular dependencies - services imported at runtime

logger = logging.getLogger(__name__)


@dataclass
class ComprehensiveValidationResult:
    """Result of complete validation lifecycle"""
    material_name: str
    validation_timestamp: str
    overall_status: str  # PASS, FAIL, WARNING
    
    # Phase results
    pre_generation_result: Optional[Any] = None
    post_generation_result: Optional[Any] = None
    material_audit_result: Optional[Any] = None
    schema_validation_result: Optional[Any] = None
    
    # Aggregated metrics
    total_issues: int = 0
    critical_issues: int = 0
    high_issues: int = 0
    medium_issues: int = 0
    low_issues: int = 0
    
    # Detailed breakdown
    pre_generation_issues: List[str] = field(default_factory=list)
    post_generation_issues: List[str] = field(default_factory=list)
    audit_issues: List[str] = field(default_factory=list)
    schema_issues: List[str] = field(default_factory=list)
    
    # Performance metrics
    validation_duration_ms: int = 0
    phases_completed: int = 0
    auto_fixes_applied: int = 0


class ValidationOrchestrator:
    """
    Unified validation orchestrator coordinating all validation phases.
    
    Provides single interface for:
    1. Pre-generation validation (data quality, completeness)
    2. Post-generation quality assurance  
    3. Material auditing (comprehensive compliance)
    4. Schema validation (structure compliance)
    5. Legacy validation utilities (during transition)
    
    Benefits:
    - Single validation entry point
    - Coordinated validation phases
    - Comprehensive reporting
    - Consistent error handling
    - Performance optimization
    """
    
    def __init__(self):
        """Initialize validation orchestrator with all validation services"""
        self.logger = logging.getLogger(__name__)
        
        # Initialize validation services
        self._initialize_services()
        
        # Validation metrics
        self.validation_stats = {
            'total_validations': 0,
            'successful_validations': 0,
            'failed_validations': 0,
            'auto_fixes_applied': 0
        }
        
        self.logger.info("✅ ValidationOrchestrator initialized with all validation services")
    
    @property
    def property_rules(self):
        """Expose property_rules from pre_generation_service for pipeline compatibility"""
        return self.pre_generation_service.property_rules
    
    def validate_hierarchical(self, verbose: bool = False):
        """Delegate to pre_generation_service for pipeline compatibility"""
        return self.pre_generation_service.validate_hierarchical(verbose)
    
    def _initialize_services(self) -> None:
        """Initialize all validation services with lazy imports to avoid circular dependencies"""
        try:
            # Lazy imports to avoid circular dependencies
            from validation.services.pre_generation_service import PreGenerationValidationService
            from validation.content_validator import ContentValidationService
            from components.frontmatter.services.material_auditor import MaterialAuditor
            from components.frontmatter.services.validation_service import ValidationService
            
            # Core validation services
            self.pre_generation_service = PreGenerationValidationService()
            self.content_validation_service = ContentValidationService()  # Replaced PostGenerationQualityService
            self.material_auditor = MaterialAuditor()
            self.validation_service = ValidationService()
            
            # Service initialization successful
            self.logger.info("✅ All validation services initialized successfully")
            
        except Exception as e:
            self.logger.error(f"❌ Failed to initialize validation services: {e}")
            raise ValidationError(f"ValidationOrchestrator initialization failed: {e}")
    
    def validate_material_lifecycle(
        self,
        material_name: str,
        phases: Optional[List[str]] = None,
        auto_fix: bool = True,
        generate_reports: bool = True
    ) -> ComprehensiveValidationResult:
        """
        Execute complete material validation lifecycle.
        
        Args:
            material_name: Name of material to validate
            phases: Specific phases to run (None = all phases)
            auto_fix: Whether to apply automatic fixes where possible
            generate_reports: Whether to generate detailed reports
            
        Returns:
            Comprehensive validation result with all findings
            
        Raises:
            ValidationError: If critical validation infrastructure fails
        """
        start_time = datetime.now()
        
        try:
            self.logger.info(f"🚀 Starting comprehensive validation lifecycle for {material_name}")
            
            # Initialize result
            result = ComprehensiveValidationResult(
                material_name=material_name,
                validation_timestamp=start_time.isoformat(),
                overall_status="PASS"
            )
            
            # Default to all phases if none specified
            if phases is None:
                phases = ['pre_generation', 'material_audit', 'post_generation', 'schema_validation']
            
            # === PHASE 1: PRE-GENERATION VALIDATION ===
            if 'pre_generation' in phases:
                result.pre_generation_result = self._run_pre_generation_validation(
                    material_name, result
                )
                result.phases_completed += 1
            
            # === PHASE 2: MATERIAL AUDITING ===
            if 'material_audit' in phases:
                result.material_audit_result = self._run_material_audit(
                    material_name, result, auto_fix
                )
                result.phases_completed += 1
            
            # === PHASE 3: POST-GENERATION QUALITY ===
            if 'post_generation' in phases:
                result.post_generation_result = self._run_post_generation_validation(
                    material_name, result
                )
                result.phases_completed += 1
            
            # === PHASE 4: SCHEMA VALIDATION ===
            if 'schema_validation' in phases:
                result.schema_validation_result = self._run_schema_validation(
                    material_name, result
                )
                result.phases_completed += 1
            
            # === FINALIZE RESULT ===
            self._finalize_validation_result(result, start_time)
            
            # Generate reports if requested
            if generate_reports:
                self._generate_comprehensive_report(result)
            
            # Update statistics
            self._update_validation_stats(result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"❌ Critical validation lifecycle failure for {material_name}: {e}")
            raise ValidationError(f"Validation lifecycle failure: {e}")
    
    def _run_pre_generation_validation(
        self, 
        material_name: str, 
        result: ComprehensiveValidationResult
    ) -> Any:
        """Run pre-generation validation phase"""
        try:
            self.logger.info(f"📋 Running pre-generation validation for {material_name}")
            
            # Use existing pre-generation service
            pre_result = self.pre_generation_service.validate_material_data_quality(material_name)
            
            # Extract issues and add to result
            if hasattr(pre_result, 'errors') and pre_result.errors:
                for error in pre_result.errors:
                    result.pre_generation_issues.append(str(error))
                    result.total_issues += 1
                    
                    # Categorize by severity
                    if 'CRITICAL' in str(error).upper():
                        result.critical_issues += 1
                        result.overall_status = "FAIL"
                    elif 'HIGH' in str(error).upper():
                        result.high_issues += 1
                        if result.overall_status == "PASS":
                            result.overall_status = "WARNING"
            
            return pre_result
            
        except Exception as e:
            self.logger.error(f"❌ Pre-generation validation failed: {e}")
            result.pre_generation_issues.append(f"Pre-generation validation failed: {e}")
            result.critical_issues += 1
            result.overall_status = "FAIL"
            return None
    
    def _run_material_audit(
        self, 
        material_name: str, 
        result: ComprehensiveValidationResult,
        auto_fix: bool
    ) -> Any:
        """Run material auditing phase"""
        try:
            self.logger.info(f"🔍 Running material audit for {material_name}")
            
            # Use existing material auditor
            audit_result = self.material_auditor.audit_material(
                material_name, 
                auto_fix=auto_fix
            )
            
            # Extract issues and add to result
            if hasattr(audit_result, 'issues') and audit_result.issues:
                for issue in audit_result.issues:
                    result.audit_issues.append(str(issue.description))
                    result.total_issues += 1
                    
                    # Categorize by severity
                    if issue.severity.name == 'CRITICAL':
                        result.critical_issues += 1
                        result.overall_status = "FAIL"
                    elif issue.severity.name == 'HIGH':
                        result.high_issues += 1
                        if result.overall_status == "PASS":
                            result.overall_status = "WARNING"
                    elif issue.severity.name == 'MEDIUM':
                        result.medium_issues += 1
                    else:
                        result.low_issues += 1
            
            # Track auto-fixes
            if hasattr(audit_result, 'auto_fixes_applied'):
                result.auto_fixes_applied += audit_result.auto_fixes_applied
            
            return audit_result
            
        except Exception as e:
            self.logger.error(f"❌ Material audit failed: {e}")
            result.audit_issues.append(f"Material audit failed: {e}")
            result.critical_issues += 1
            result.overall_status = "FAIL"
            return None
    
    def _run_post_generation_validation(
        self, 
        material_name: str, 
        result: ComprehensiveValidationResult
    ) -> Any:
        """Run post-generation quality validation phase using ContentValidationService"""
        try:
            self.logger.info(f"📊 Running post-generation validation for {material_name}")
            
            # Load material data to validate
            from data.materials import load_materials, get_material_by_name
            materials_data = load_materials()
            material_info = get_material_by_name(material_name, materials_data)
            
            if not material_info:
                result.post_generation_issues.append(f"Material {material_name} not found")
                result.medium_issues += 1
                return None
            
            # Get author info
            from utils.core.author_manager import get_author_info_for_material
            author_info = get_author_info_for_material(material_info)
            
            if not author_info:
                author_info = {'name': 'Unknown', 'country': 'Unknown'}
            
            # Validate components if they exist
            validation_results = []
            
            # Validate FAQ
            if 'questions' in material_info and material_info['questions']:
                from validation.integration import validate_generated_content
                faq_result = validate_generated_content(
                    content={'questions': material_info['questions']},
                    component_type='faq',
                    material_name=material_name,
                    author_info=author_info,
                    log_report=False
                )
                validation_results.append(('FAQ', faq_result))
                
                if not faq_result.success:
                    for issue in faq_result.critical_issues:
                        result.post_generation_issues.append(f"FAQ: {issue}")
                        result.medium_issues += 1
            
            # Validate Caption
            if 'beforeText' in material_info or 'afterText' in material_info:
                from validation.integration import validate_generated_content
                caption_result = validate_generated_content(
                    content={
                        'beforeText': material_info.get('beforeText', ''),
                        'afterText': material_info.get('afterText', '')
                    },
                    component_type='caption',
                    material_name=material_name,
                    author_info=author_info,
                    log_report=False
                )
                validation_results.append(('Caption', caption_result))
                
                if not caption_result.success:
                    for issue in caption_result.critical_issues:
                        result.post_generation_issues.append(f"Caption: {issue}")
                        result.medium_issues += 1
            
            # Validate Subtitle
            if 'subtitle' in material_info and material_info['subtitle']:
                from validation.integration import validate_generated_content
                subtitle_result = validate_generated_content(
                    content=material_info['subtitle'],
                    component_type='subtitle',
                    material_name=material_name,
                    author_info=author_info,
                    log_report=False
                )
                validation_results.append(('Subtitle', subtitle_result))
                
                if not subtitle_result.success:
                    for issue in subtitle_result.critical_issues:
                        result.post_generation_issues.append(f"Subtitle: {issue}")
                        result.medium_issues += 1
            
            return validation_results
            
        except Exception as e:
            self.logger.error(f"❌ Post-generation validation failed: {e}")
            result.post_generation_issues.append(f"Post-generation validation failed: {e}")
            result.medium_issues += 1
            return None
    
    def _run_schema_validation(
        self, 
        material_name: str, 
        result: ComprehensiveValidationResult
    ) -> Any:
        """Run schema validation phase"""
        try:
            self.logger.info(f"📄 Running schema validation for {material_name}")
            
            # Check if frontmatter file exists
            frontmatter_file = Path(f"content/frontmatter/{material_name.lower().replace(' ', '-')}-laser-cleaning.yaml")
            
            if not frontmatter_file.exists():
                result.schema_issues.append("No frontmatter file exists for schema validation")
                return None
            
            # This will be replaced by UnifiedSchemaValidator in Phase 2
            # For now, use basic validation
            schema_result = {
                'valid': True,
                'issues': []
            }
            
            return schema_result
            
        except Exception as e:
            self.logger.error(f"❌ Schema validation failed: {e}")
            result.schema_issues.append(f"Schema validation failed: {e}")
            result.medium_issues += 1
            return None
    
    def _finalize_validation_result(
        self, 
        result: ComprehensiveValidationResult, 
        start_time: datetime
    ) -> None:
        """Finalize validation result with summary statistics"""
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds() * 1000
        result.validation_duration_ms = int(duration)
        
        # Log final status
        if result.overall_status == "PASS":
            self.logger.info(f"✅ Validation PASSED for {result.material_name} ({duration:.0f}ms)")
        elif result.overall_status == "WARNING":
            self.logger.warning(f"⚠️  Validation WARNING for {result.material_name} ({result.total_issues} issues)")
        else:
            self.logger.error(f"❌ Validation FAILED for {result.material_name} ({result.critical_issues} critical issues)")
    
    def _generate_comprehensive_report(self, result: ComprehensiveValidationResult) -> None:
        """Generate comprehensive validation report"""
        try:
            report_dir = Path("validation_reports")
            report_dir.mkdir(exist_ok=True)
            
            report_file = report_dir / f"{result.material_name}_comprehensive_validation.txt"
            
            lines = []
            lines.append("=" * 80)
            lines.append(f"COMPREHENSIVE VALIDATION REPORT: {result.material_name}")
            lines.append("=" * 80)
            lines.append(f"Validation Date: {result.validation_timestamp}")
            lines.append(f"Overall Status: {result.overall_status}")
            lines.append(f"Total Issues: {result.total_issues}")
            lines.append(f"Phases Completed: {result.phases_completed}")
            lines.append(f"Duration: {result.validation_duration_ms}ms")
            lines.append("")
            
            # Issue breakdown
            lines.append("📊 ISSUE BREAKDOWN:")
            lines.append(f"  • Critical: {result.critical_issues}")
            lines.append(f"  • High: {result.high_issues}")
            lines.append(f"  • Medium: {result.medium_issues}")
            lines.append(f"  • Low: {result.low_issues}")
            lines.append("")
            
            # Phase details
            if result.pre_generation_issues:
                lines.append("📋 PRE-GENERATION ISSUES:")
                for issue in result.pre_generation_issues:
                    lines.append(f"  • {issue}")
                lines.append("")
            
            if result.audit_issues:
                lines.append("🔍 MATERIAL AUDIT ISSUES:")
                for issue in result.audit_issues:
                    lines.append(f"  • {issue}")
                lines.append("")
            
            if result.post_generation_issues:
                lines.append("📊 POST-GENERATION ISSUES:")
                for issue in result.post_generation_issues:
                    lines.append(f"  • {issue}")
                lines.append("")
            
            if result.schema_issues:
                lines.append("📄 SCHEMA VALIDATION ISSUES:")
                for issue in result.schema_issues:
                    lines.append(f"  • {issue}")
                lines.append("")
            
            lines.append("=" * 80)
            
            with open(report_file, 'w') as f:
                f.write('\n'.join(lines))
            
            self.logger.info(f"📄 Comprehensive validation report saved: {report_file}")
            
        except Exception as e:
            self.logger.error(f"❌ Failed to generate validation report: {e}")
    
    def _update_validation_stats(self, result: ComprehensiveValidationResult) -> None:
        """Update validation statistics"""
        self.validation_stats['total_validations'] += 1
        
        if result.overall_status == "PASS":
            self.validation_stats['successful_validations'] += 1
        else:
            self.validation_stats['failed_validations'] += 1
        
        self.validation_stats['auto_fixes_applied'] += result.auto_fixes_applied
    
    # === LEGACY COMPATIBILITY METHODS ===
    
    def validate_material(self, material_name: str) -> ComprehensiveValidationResult:
        """Legacy compatibility method - delegates to validate_material_lifecycle"""
        return self.validate_material_lifecycle(material_name)
    
    def validate_pre_generation(self, material_name: str) -> Any:
        """Legacy compatibility - run only pre-generation validation"""
        return self.validate_material_lifecycle(
            material_name, 
            phases=['pre_generation'],
            generate_reports=False
        )
    
    def validate_post_generation(self, material_name: str) -> Any:
        """Legacy compatibility - run only post-generation validation"""
        return self.validate_material_lifecycle(
            material_name,
            phases=['post_generation'], 
            generate_reports=False
        )
    
    def audit_material(self, material_name: str, auto_fix: bool = True) -> Any:
        """Legacy compatibility - run only material audit"""
        result = self.validate_material_lifecycle(
            material_name,
            phases=['material_audit'],
            auto_fix=auto_fix,
            generate_reports=False
        )
        return result.material_audit_result
    
    # === UTILITY METHODS ===
    
    def get_validation_stats(self) -> Dict[str, Any]:
        """Get validation statistics"""
        return self.validation_stats.copy()
    
    def normalize_confidence(self, confidence: Union[int, float]) -> int:
        """Legacy utility method - delegates to ValidationService"""
        return self.validation_service.normalize_confidence(confidence)


# Convenience functions for backward compatibility
def validate_material_lifecycle(material_name: str, **kwargs) -> ComprehensiveValidationResult:
    """Convenience function for material lifecycle validation"""
    orchestrator = ValidationOrchestrator()
    return orchestrator.validate_material_lifecycle(material_name, **kwargs)


def validate_material(material_name: str) -> ComprehensiveValidationResult:
    """Convenience function for basic material validation"""
    orchestrator = ValidationOrchestrator()
    return orchestrator.validate_material(material_name)