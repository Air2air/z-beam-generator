# System Interactions & Dependencies

**For AI Assistants**: This document maps how components interact and what happens when you change one part.

## ğŸ¯ Purpose

Understanding cascading effects prevents:
- Breaking unrelated features
- Creating circular dependencies
- Violating architectural boundaries
- Repeating past mistakes

---

## ğŸ“Š Core System Flow

```
User Request
    â†“
Material Data Loading (Materials.yaml)
    â†“
Component Generator (DynamicGenerator)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generation Loop         â”‚
â”‚                         â”‚
â”‚ Prompt Building         â”‚ â† Loads prompts/*.txt
â”‚    â†“                    â”‚
â”‚ Parameter Adaptation    â”‚ â† Learns from database
â”‚    â†“                    â”‚
â”‚ API Call (Grok)        â”‚ â† Uses cached client
â”‚    â†“                    â”‚
â”‚ Content Extraction      â”‚ â† Uses adapter pattern
â”‚    â†“                    â”‚
â”‚ Quality Gates           â”‚ â† Multiple validators
â”‚    â†“                    â”‚
â”‚ Learning & Feedback     â”‚ â† Updates database
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Success: Save to frontmatter
Failure: Retry with adjusted parameters
```

---

## ğŸ”— Dependency Map

### When You Change Prompts

**File**: `shared/text/templates/components/*.txt` or `shared/text/templates/evaluation/*.txt`

**Direct Impact**:
- Content generation immediately affected
- Quality gate behavior may change
- Learning patterns update based on new evaluations

**Cascade Effects**:
1. **Generation Quality**: Different voice guidance â†’ different content
2. **Realism Scores**: Stricter requirements â†’ more failures initially
3. **Learning Database**: New patterns learned based on new rules
4. **Parameter Sweet Spots**: May need recalibration

**Safe Changes**:
- âœ… Adding examples to existing rules
- âœ… Clarifying ambiguous requirements
- âœ… Adding more forbidden phrases

**Dangerous Changes**:
- âš ï¸ Removing voice guidance (causes generation failures - see ADR-001)
- âš ï¸ Contradicting existing rules (confuses learning)
- âš ï¸ Making requirements much stricter (causes cascade of failures)

**Example**: November 18, 2025 - Removed voice guidance from prompts
- Result: 100% failure rate (0/4 batch tests)
- Realism scores dropped to 4.0-5.0/10 (below 7.0 threshold)
- Required adding guidance back to restore functionality

### When You Change Generation Code

**File**: `processing/generator.py`

**Direct Impact**:
- Parameter calculation logic
- Retry behavior
- Learning integration
- Quality gate enforcement

**Cascade Effects**:
1. **Quality Consistency**: Changed exploration rate â†’ different consistency
2. **Database Schema**: New parameters â†’ need migration
3. **Adapter Interface**: Changed extraction â†’ update all adapters
4. **Learning Loop**: Changed feedback â†’ affects future generations

**Safe Changes**:
- âœ… Adding new parameters to track
- âœ… Improving error messages
- âœ… Adding logging for debugging

**Dangerous Changes**:
- âš ï¸ Changing exploration rate without testing (affects consistency)
- âš ï¸ Removing retry logic (affects resilience)
- âš ï¸ Bypassing quality gates (degrades output)

**Example**: November 18, 2025 - Reduced exploration 15% â†’ 5%
- Result: 3x improvement in consistency (67% pass rate)
- Database: No schema changes needed
- Learning: Still functional, just less frequent exploration

### When You Change Quality Gates

**Files**: `processing/validation/`, `processing/subjective/`, `processing/detection/`

**Direct Impact**:
- Pass/fail criteria
- Retry frequency
- Learning feedback quality

**Cascade Effects**:
1. **Generation Success Rate**: Stricter â†’ more retries
2. **Parameter Adaptation**: Different feedback â†’ different adjustments
3. **Database Growth**: More failures â†’ more learning entries
4. **User Experience**: More retries â†’ slower generation

**Safe Changes**:
- âœ… Adding new validation checks (if not gates)
- âœ… Improving error messages
- âœ… Logging more details

**Dangerous Changes**:
- âš ï¸ Changing thresholds without data analysis
- âš ï¸ Adding new required gates (causes failures)
- âš ï¸ Removing existing gates (degrades quality)

**Example**: Winston threshold dynamically calculated (currently 30.9% AI / 69.1% human at humanness_intensity=7)
- If humanness_intensity increased to 9: More content rejected â†’ more retries â†’ slower
- If humanness_intensity decreased to 5: More content accepted â†’ lower quality â†’ defeats purpose
- Threshold formula: Higher humanness_intensity = stricter detection (lower AI tolerance)

### When You Change Learning Systems

**Files**: `processing/learning/*.py`

**Direct Impact**:
- Parameter recommendations
- Sweet spot calculations
- Pattern detection

**Cascade Effects**:
1. **Generation Quality**: Better learning â†’ better parameters â†’ better content
2. **Database Size**: More tracking â†’ more storage
3. **Performance**: Complex learning â†’ slower recommendations
4. **Consistency**: Learning changes â†’ behavior changes over time

**Safe Changes**:
- âœ… Improving algorithms (with backward compatibility)
- âœ… Adding new metrics to track
- âœ… Better visualization/logging

**Dangerous Changes**:
- âš ï¸ Changing database schema without migration
- âš ï¸ Breaking backward compatibility with old data
- âš ï¸ Removing learning features (loses accumulated knowledge)

### When You Change API Clients

**Files**: `shared/api/*.py`

**Direct Impact**:
- All generation stops if broken
- Retry behavior changes
- Cache effectiveness changes

**Cascade Effects**:
1. **Generation Reliability**: Client issues â†’ all content generation fails
2. **Cost**: Cache changes â†’ more/fewer API calls â†’ cost impact
3. **Performance**: Timeout changes â†’ faster/slower generation
4. **Error Handling**: New exceptions â†’ need handling everywhere

**Safe Changes**:
- âœ… Improving error messages
- âœ… Adding better logging
- âœ… Optimizing retry delays

**Dangerous Changes**:
- âš ï¸ Changing client interface (breaks all generators)
- âš ï¸ Modifying cache behavior (affects consistency)
- âš ï¸ Removing retry logic (reduces resilience)

---

## ğŸ­ The Learning Loop Interactions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LEARNING LOOP                             â”‚
â”‚                                                              â”‚
â”‚  Generation â†’ Quality Check â†’ Feedback â†’ Learning â†’ DB      â”‚
â”‚      â†“            â†“             â†“          â†“         â†“      â”‚
â”‚  Uses params  Pass/Fail?    Why failed  Update    Store    â”‚
â”‚      â†‘                                   sweet     patterns â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€spots    â†â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                           â†“
â”‚                                    Next generation
â”‚                                    uses learned params
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components Involved

1. **DynamicGenerator**: Orchestrates the loop
2. **ParameterBuilder**: Applies learned values
3. **Quality Validators**: Provide feedback
4. **Learning Modules**: Update sweet spots
5. **Database**: Persists knowledge

### What Happens When...

#### You Change Parameter Ranges
- Learning system explores new ranges
- May find better sweet spots
- Database accumulates new data
- Old sweet spots may become invalid

#### You Change Quality Criteria
- Different feedback to learning system
- Sweet spots recalculate for new criteria
- Database continues growing with new context
- May need to reset if incompatible

#### You Change Learning Algorithms
- Recommendations change immediately
- Database data remains valid (unless schema changes)
- May improve or degrade quality (test first)
- Backward compatibility important

---

## âš ï¸ Known Failure Cascades

### Cascade #1: Removing Voice Guidance from Prompts

**What**: Removed voice requirements from component prompts (Nov 18, 2025)

**Expected**: Generator learns from evaluator feedback

**Actually Happened**:
```
Prompt without guidance
    â†“
Generator produces random style
    â†“
Evaluator rejects (doesn't match requirements)
    â†“
Learning system adjusts parameters
    â†“
Generator still doesn't know target style
    â†“
Infinite loop of failures (0/4 success rate)
```

**Fix**: Voice guidance in BOTH prompt and evaluator (ADR-001)

### Cascade #2: High Exploration Rate

**What**: 15% of attempts used random parameters

**Expected**: Better learning through experimentation

**Actually Happened**:
```
High randomness (15%)
    â†“
Inconsistent quality across runs
    â†“
Batch tests fail unpredictably
    â†“
Winston scores vary wildly (0.9% to 74.6%)
    â†“
User frustration with unreliable system
```

**Fix**: Reduced to 5% + added random_seed for reproducibility (ADR-003)

### Cascade #3: Hardcoded Thresholds

**What**: Hardcoded multipliers instead of dynamic calculation

**Historical Issue**: Discovered in Priority 1 compliance fixes

**Why It's Bad**:
```
Hardcoded threshold
    â†“
Learning system can't adapt
    â†“
Sweet spots diverge from hardcoded values
    â†“
System performance degrades over time
    â†“
Manual intervention required to update hardcoded values
```

**Fix**: Always use dynamic_config for thresholds and calculations

---

## ğŸ”§ Safe Change Patterns

### Pattern 1: Additive Changes

**Safe**: Adding new features alongside existing ones
```python
# âœ… SAFE: Add new validation without breaking old
def validate_content(content):
    old_validation(content)  # Keep existing
    new_validation(content)  # Add new
```

**Unsafe**: Replacing existing features
```python
# âŒ UNSAFE: Breaks existing functionality
def validate_content(content):
    new_validation(content)  # Old validation gone!
```

### Pattern 2: Gradual Strictness

**Safe**: Tighten requirements gradually with warnings
```python
# âœ… SAFE: Warn before enforcing
if score < new_threshold:
    logger.warning(f"Score {score} below future threshold {new_threshold}")
if score < old_threshold:
    raise ValidationError("Below current threshold")
```

**Unsafe**: Sudden strict requirements
```python
# âŒ UNSAFE: Immediate enforcement breaks existing content
if score < much_higher_threshold:
    raise ValidationError("New strict threshold")
```

### Pattern 3: Versioned Interfaces

**Safe**: New version alongside old
```python
# âœ… SAFE: Backward compatible
def generate_v2(material, options):
    # New interface
    
def generate(material):  # Keep old interface
    return generate_v2(material, default_options)
```

**Unsafe**: Breaking interface changes
```python
# âŒ UNSAFE: Breaks all existing callers
def generate(material, required_new_param):
    # Old signature gone!
```

---

## ğŸ“š For AI Assistants

### Before Making ANY Change

1. **Check This Document**: What will your change affect?
2. **Check ADRs**: Is there a decision record about this?
3. **Check History**: Has this been tried before and failed?
4. **Test Cascade**: What downstream effects will occur?

### Red Flags (Stop and Ask)

- ğŸš© Removing existing functionality
- ğŸš© Changing interfaces that other code depends on
- ğŸš© Modifying quality thresholds
- ğŸš© Altering learning algorithms
- ğŸš© Changing database schemas
- ğŸš© Bypassing validation

### Green Lights (Probably Safe)

- âœ… Adding logging
- âœ… Improving error messages
- âœ… Adding optional parameters (with defaults)
- âœ… Fixing obvious bugs
- âœ… Adding tests
- âœ… Updating documentation

### When Uncertain

**Ask yourself**:
1. What components depend on this?
2. What will break if this fails?
3. Can I add this instead of changing?
4. Is there a safer way to achieve the goal?

**If still uncertain**: Document the concern and ask the user.

---

## Related Documentation

- [ADR-001: Dual Voice Enforcement](./decisions/ADR-001-dual-voice-enforcement.md)
- [ADR-002: Fail-Fast vs Runtime Recovery](./decisions/ADR-002-fail-fast-vs-runtime-recovery.md)
- [ADR-003: Exploration Rate](./decisions/ADR-003-exploration-rate-reproducibility.md)
- [WINSTON_CONSISTENCY_FIXES_NOV18_2025.md](../WINSTON_CONSISTENCY_FIXES_NOV18_2025.md)
