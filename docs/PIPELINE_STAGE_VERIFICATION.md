# Pipeline Stage Verification Guide

This document describes how to verify that each generation goes through all required pipeline stages.

## Pipeline Stages Overview

Every content generation goes through these stages:

1. **Humanness Layer Generation** - Generate 1428-char dynamic instructions
2. **Content Generation** - Create material-specific content with quality-gated retries
3. **Winston AI Detection** - Check human vs AI score (69%+ human threshold)
4. **Subjective Evaluation** - Assess realism score (7.0/10 minimum)
5. **Readability Check** - Validate readability metrics
6. **Database Logging** - Record parameters, scores, feedback
7. **Sweet Spot Learning** - Update optimal parameter recommendations

## Verification Methods

### Method 1: Real-Time Logging (Recommended)

Watch generation output in real-time by filtering stdout for stage markers:

```bash
python3 run.py --caption "Aluminum" --skip-integrity-check 2>&1 | \
  grep -E "Stage|Attempt|ðŸŽ¯|âœ… Generated|Winston Score|Realism Score|Humanness|Quality Gate|saved to|GENERATION COMPLETE"
```

**Output shows:**
```
âœ… HumannessOptimizer initialized (Winston DB: z-beam.db)
Threshold: 5.5/10 | Max Attempts: 5
âœ… Generated 1428 character instruction block
ðŸŽ¯ Target: 38 words (range: 30-120)
ðŸŽ¯ Max tokens: 418, Temperature: 0.815
âœ… Generated: 302 chars, 45 words
Winston Score: 85.2% human âœ… PASS
Realism Score: 7.5/10 âœ… PASS
Quality Gate: âœ… PASS
âœ… Caption generated and saved to Materials.yaml
ðŸ“Š GENERATION COMPLETE REPORT
```

**Stage Markers:**
- `âœ… HumannessOptimizer initialized` = Stage 1 (Humanness Layer)
- `âœ… Generated 1428 character instruction block` = Instructions loaded
- `ðŸŽ¯ Target` = Word count calculation
- `ðŸŽ¯ Max tokens, Temperature` = Dynamic parameter calculation
- `âœ… Generated: X chars` = Content generation attempt
- `Winston Score: X% human` = Stage 3 (AI Detection)
- `Realism Score: X/10` = Stage 4 (Subjective Evaluation)
- `Quality Gate: PASS/FAIL` = Overall quality check
- `âœ… saved to Materials.yaml` = Persistence confirmation
- `ðŸ“Š GENERATION COMPLETE REPORT` = Final report

### Method 2: Database Queries

Use the verification script to check all stages in database:

```bash
python3 scripts/verify_pipeline_stages.py
```

**Output shows:**
```
ðŸ” PIPELINE STAGE VERIFICATION
==============================

âœ… Database found at z-beam.db

ðŸ“Š DATABASE TABLES:
   â€¢ ai_patterns
   â€¢ detection_results
   â€¢ generation_parameters
   â€¢ subjective_evaluations
   â€¢ sweet_spot_recommendations

ðŸ”Ž STAGE 1: Winston AI Detection
   âœ… Found 5 recent detections
   â€¢ Aluminum/caption: 85.2% human, 14.8% AI âœ… PASS

ðŸŽ¨ STAGE 2: Subjective Evaluation (Realism)
   âœ… Found 5 recent evaluations
   â€¢ Aluminum/caption: 7.5/10 âœ… PASS

âš™ï¸  STAGE 3: Generation Parameters
   âœ… Found 5 parameter records
   â€¢ Aluminum/caption: temp=0.815, attempt=1

ðŸŽ¯ STAGE 4: Sweet Spot Learning
   âœ… Found recommendations for 1 component types
   â€¢ caption: 15 samples, confidence: high

ðŸ”— STAGE 5: End-to-End Pipeline Verification
   ðŸ“ Latest generation: Aluminum/caption
   âœ… Stage 1 (Winston): PASS
   âœ… Stage 2 (Subjective): 7.5/10 PASS
   âœ… Stage 3 (Parameters): temp=0.815, attempt=1
   âœ… Stage 4 (Sweet Spot): 15 recommendations exist
   
   ðŸ“Š Pipeline Status:
   4/4 stages verified in database

ðŸ§  STAGE 6: Humanness Layer Integration
   âœ… Winston patterns: 11 stored
   âœ… Humanness template: shared/text/templates/system/humanness_layer.txt
   âœ… Subjective patterns: shared/text/templates/evaluation/learned_patterns.yaml
```

### Method 3: Direct Database Inspection

Query database tables directly to see stage data:

```bash
# Check Winston AI detection results
sqlite3 z-beam.db "SELECT material, component_type, human_score, ai_score, success FROM detection_results ORDER BY timestamp DESC LIMIT 5;"

# Check subjective evaluations
sqlite3 z-beam.db "SELECT topic, component_type, overall_score, passes_quality_gate FROM subjective_evaluations ORDER BY timestamp DESC LIMIT 5;"

# Check generation parameters
sqlite3 z-beam.db "SELECT material, component_type, temperature, attempt_number FROM generation_parameters ORDER BY timestamp DESC LIMIT 5;"

# Check sweet spot recommendations
sqlite3 z-beam.db "SELECT component_type, sample_count, confidence_level FROM sweet_spot_recommendations;"

# Check Winston patterns learned
sqlite3 z-beam.db "SELECT COUNT(*) FROM ai_patterns;"
```

### Method 4: Integrity Checks (Full Validation)

Run generation WITH integrity checks enabled to see comprehensive validation:

```bash
python3 run.py --caption "Aluminum"
```

**Shows additional verification:**
```
ðŸ” Integrity Checks:
   âœ… Database Exists: z-beam.db
   âœ… Detection Logged: Aluminum/caption
   âœ… Evaluation Logged: Aluminum/caption
   âœ… Parameters Logged: Aluminum/caption
   âœ… Sweet Spot Updated: caption
   âœ… Humanness Layer Active: 1428 chars
   âœ… All Stages Complete
```

### Method 5: Filtering Full Output

For deep debugging, capture full output and filter for specific patterns:

```bash
# Capture full generation log
python3 run.py --description "Aluminum" > /tmp/generation.log 2>&1

# Extract humanness instructions
grep -A 50 "ðŸ§  Humanness Instructions" /tmp/generation.log

# Extract all generation attempts
grep "Attempt [0-9]" /tmp/generation.log

# Extract quality scores
grep -E "Winston Score|Realism Score|Readability" /tmp/generation.log

# Extract learning updates
grep -E "Sweet Spot|Learning|Correlation" /tmp/generation.log
```

## Stage-by-Stage Verification Checklist

### âœ… Stage 1: Humanness Layer Generation

**What to verify:**
- HumannessOptimizer initializes
- Loads Winston patterns from database
- Loads Subjective patterns from YAML
- Generates 1428-character instruction block
- Strictness level progresses (1-5) across retry attempts

**Verification commands:**
```bash
# Check template exists
ls -lh shared/text/templates/system/humanness_layer.txt

# Check patterns file exists
ls -lh prompts/evaluation/learned_patterns.yaml

# Check database has patterns
sqlite3 z-beam.db "SELECT COUNT(*) FROM ai_patterns;"

# Watch generation for humanness markers
python3 run.py --caption "Material" 2>&1 | grep -i humanness
```

**Expected output markers:**
```
âœ… HumannessOptimizer initialized (Winston DB: z-beam.db)
âœ… Generated 1428 character instruction block
Strictness Level: 1 (Lenient)  # First attempt
Strictness Level: 3 (Moderate) # Retry attempt
```

### âœ… Stage 2: Content Generation

**What to verify:**
- Dynamic parameter calculation (temperature, max_tokens, penalties)
- Word count targeting
- Quality-gated retries (up to 5 attempts)
- Content saved to Materials.yaml

**Verification commands:**
```bash
# Watch parameter calculation
python3 run.py --caption "Material" 2>&1 | grep "ðŸŽ¯"

# Check generation attempts
python3 run.py --caption "Material" 2>&1 | grep "Attempt"

# Verify content saved
python3 -c "import yaml; data=yaml.safe_load(open('data/materials/Materials.yaml')); print(data['Aluminum']['caption'])"
```

**Expected output markers:**
```
ðŸŽ¯ Target: 38 words (range: 30-120)
ðŸŽ¯ Max tokens: 418, Temperature: 0.815
Attempt 1/5
âœ… Generated: 302 chars, 45 words
Attempt 2/5
âœ… Generated: 285 chars, 42 words
âœ… Caption generated and saved to Materials.yaml
```

### âœ… Stage 3: Winston AI Detection

**What to verify:**
- Winston API called for each generation
- Human score meets threshold (69%+ default)
- Results logged to database
- Feedback used for learning

**Verification commands:**
```bash
# Watch Winston scoring
python3 run.py --caption "Material" 2>&1 | grep -i winston

# Check database for recent results
sqlite3 z-beam.db "SELECT material, component_type, human_score, ai_score FROM detection_results ORDER BY timestamp DESC LIMIT 5;"

# Verify patterns learned
sqlite3 z-beam.db "SELECT pattern_type, phrase, penalty_weight FROM ai_patterns LIMIT 10;"
```

**Expected output markers:**
```
Winston Score: 85.2% human (threshold: 69%) âœ… PASS
Winston Feedback: ["avoid passive voice", "reduce technical jargon"]
âœ… Detection logged to database
```

### âœ… Stage 4: Subjective Evaluation (Realism)

**What to verify:**
- Grok evaluates generated content
- Realism score meets threshold (7.0/10 default)
- Dimensional scores calculated (clarity, professionalism, accuracy, likeness, engagement)
- Results logged to database
- AI tendencies extracted for learning

**Verification commands:**
```bash
# Watch subjective scoring
python3 run.py --caption "Material" 2>&1 | grep -i "realism\|subjective"

# Check database for evaluations
sqlite3 z-beam.db "SELECT topic, component_type, overall_score, passes_quality_gate FROM subjective_evaluations ORDER BY timestamp DESC LIMIT 5;"

# Check learned patterns
cat shared/text/templates/evaluation/learned_patterns.yaml
```

**Expected output markers:**
```
Realism Score: 7.5/10 (threshold: 7.0) âœ… PASS
  â€¢ Clarity: 8/10
  â€¢ Professionalism: 7/10
  â€¢ Technical Accuracy: 9/10
  â€¢ Human Likeness: 7/10
  â€¢ Engagement: 6/10
âœ… Evaluation logged to database
AI Tendencies: ["formulaic structure", "technical tone"]
```

### âœ… Stage 5: Readability Check

**What to verify:**
- Readability metrics calculated
- Meets min/max thresholds
- Results included in final report

**Verification commands:**
```bash
# Watch readability scoring
python3 run.py --caption "Material" 2>&1 | grep -i readability

# Check readability in generation report
python3 run.py --caption "Material" 2>&1 | grep -A 5 "GENERATION COMPLETE"
```

**Expected output markers:**
```
Readability: âœ… PASS (Flesch-Kincaid: 65.3)
```

### âœ… Stage 6: Database Logging

**What to verify:**
- All stages logged to database
- Detection results recorded
- Subjective evaluations stored
- Generation parameters saved
- Sweet spot recommendations updated

**Verification commands:**
```bash
# Run full pipeline verification
python3 scripts/verify_pipeline_stages.py

# Check all tables have recent data
sqlite3 z-beam.db "SELECT name, (SELECT COUNT(*) FROM sqlite_master sm WHERE sm.name = t.name) as count FROM sqlite_master t WHERE type='table';"
```

**Expected database state:**
```
âœ… detection_results: 150+ rows
âœ… subjective_evaluations: 100+ rows
âœ… generation_parameters: 200+ rows
âœ… ai_patterns: 10+ patterns
âœ… sweet_spot_recommendations: 5+ component types
```

### âœ… Stage 7: Sweet Spot Learning

**What to verify:**
- Parameter correlations calculated
- Sweet spot recommendations updated
- Confidence levels computed (high/medium/low)
- Sample count increases over time

**Verification commands:**
```bash
# Check sweet spot recommendations
sqlite3 z-beam.db "SELECT component_type, sample_count, confidence_level FROM sweet_spot_recommendations;"

# Watch learning updates
python3 run.py --caption "Material" 2>&1 | grep -i "sweet spot\|learning\|correlation"
```

**Expected output markers:**
```
ðŸŽ¯ Sweet Spot Learning:
   â€¢ Temperature: 0.815 (correlation: 0.45)
   â€¢ Frequency Penalty: 0.3 (correlation: -0.12)
   â€¢ Sample Count: 25
   â€¢ Confidence: high
âœ… Sweet spot updated for caption
```

## Troubleshooting

### Problem: No output during generation

**Solution:** Remove output redirection:
```bash
# âŒ Wrong: Output hidden
python3 run.py --caption "Material" > /dev/null 2>&1

# âœ… Right: Full output visible
python3 run.py --caption "Material" 2>&1
```

### Problem: Database shows no recent records

**Solution:** Check if `--skip-integrity-check` was used:
```bash
# âŒ Skips some database logging
python3 run.py --caption "Material" --skip-integrity-check

# âœ… Full logging enabled
python3 run.py --caption "Material"
```

### Problem: Stage markers not appearing

**Solution:** Check logging level and ensure terminal output enabled:
```bash
# Check if generation is actually running
ps aux | grep "python3 run.py"

# Run with full verbosity
python3 run.py --caption "Material" -v 2>&1
```

### Problem: Quality gate keeps failing

**Solution:** Check current thresholds and recent feedback:
```bash
# Check Winston threshold
grep "detection_threshold" generation/config.yaml

# Check realism threshold
grep "realism_threshold" generation/config.yaml

# View recent failures
sqlite3 z-beam.db "SELECT material, component_type, human_score FROM detection_results WHERE success=0 ORDER BY timestamp DESC LIMIT 10;"
```

## Summary

**Primary Verification Method**: Real-time logging with grep filtering

```bash
python3 run.py --caption "Material" 2>&1 | grep -E "âœ…|ðŸŽ¯|Quality Gate"
```

**Comprehensive Verification**: Database inspection script

```bash
python3 scripts/verify_pipeline_stages.py
```

**Deep Debugging**: Full output capture and manual analysis

```bash
python3 run.py --caption "Material" > /tmp/gen.log 2>&1
grep -E "Stage|Attempt|Score|Quality" /tmp/gen.log
```

All verification methods confirm the Universal Humanness Layer v2.0 is fully operational with dual-feedback learning, quality-gated generation, and comprehensive stage logging.
