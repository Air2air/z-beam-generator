# Voice Prompt Chaining Research
**Research Date**: October 28, 2025  
**Context**: Investigating better ways to chain author voice prompts as reusable components

---

## ðŸŽ¯ Current State Analysis

### Existing Architecture

**VoiceOrchestrator** (`voice/orchestrator.py`):
- âœ… Centralized voice management
- âœ… Country-specific profiles (Taiwan, Italy, Indonesia, USA)
- âœ… Component-specific prompts (microscopy, subtitle, FAQ)
- âœ… Recently refactored to return `(user_prompt, system_prompt)` tuple for FAQs
- âŒ **Problem**: Voice indicators NOT appearing in generated content (11.1% for USA)

### Current Integration Pattern

```python
# Component calls VoiceOrchestrator
voice = VoiceOrchestrator(country=author_country)
user_prompt, system_prompt = voice.get_unified_prompt(
    component_type='technical_faq_answer',
    material_context=material_context,
    author=author_dict,
    **kwargs
)

# Component calls API
response = api_client.generate_simple(
    user_prompt,
    system_prompt=system_prompt,
    max_tokens=max_tokens,
    temperature=0.6
)
```

### Issues Identified

1. **Low Voice Adherence**: AI models ignore voice markers despite clear instructions
2. **Prompt Complexity**: System and user prompts both contain voice instructions
3. **Duplication**: Voice requirements repeated across system and user prompts
4. **No Enforcement**: No mechanism to force AI to use voice indicators

---

## ðŸ”¬ Research: Better Prompt Chaining Patterns

### Pattern 1: **Constitutional AI / Chain-of-Thought Voice**

**Concept**: Make voice adherence a validation step in the generation chain

```python
# Step 1: Generate content
draft_response = api_client.generate_simple(
    user_prompt=task_prompt,
    system_prompt="You are {author} answering technical questions",
    temperature=0.6
)

# Step 2: Voice validation & rewrite
voice_check_prompt = f"""
DRAFT ANSWER: {draft_response}

REQUIRED VOICE MARKERS ({country}): {voice_indicators}

TASK: Rewrite the draft to include 2-3 of these voice markers while keeping the technical content accurate.
"""

final_response = api_client.generate_simple(
    user_prompt=voice_check_prompt,
    system_prompt="You are a voice consistency editor",
    temperature=0.3  # Lower for consistency
)
```

**Pros**:
- âœ… Two-stage validation ensures voice compliance
- âœ… Separation of content generation and voice application
- âœ… Can detect and fix missing voice markers
- âœ… Lower temperature on rewrite for consistency

**Cons**:
- âŒ Doubles API calls (cost and latency)
- âŒ May alter technical accuracy during rewrite
- âŒ Complexity in managing two-stage pipeline

---

### Pattern 2: **Scoring-Based Voice Selection**

**Concept**: Generate multiple candidates, score for voice adherence, select best

```python
# Generate N candidates
candidates = []
for i in range(3):
    response = api_client.generate_simple(
        user_prompt,
        system_prompt=system_prompt,
        temperature=0.7,  # Higher for variation
        seed=random.randint(1, 10000)
    )
    
    # Score voice adherence
    voice_score = count_voice_indicators(response, voice_indicators)
    candidates.append((response, voice_score))

# Select best candidate
best_response = max(candidates, key=lambda x: x[1])[0]
```

**Pros**:
- âœ… Increases chances of voice compliance
- âœ… No rewriting needed (preserves accuracy)
- âœ… Can parallelize API calls for speed
- âœ… Natural selection of best voice fit

**Cons**:
- âŒ 3x API calls (expensive)
- âŒ No guarantee any candidate has good voice
- âŒ May waste calls on similar responses

---

### Pattern 3: **Few-Shot Voice Examples in System Prompt**

**Concept**: Provide concrete examples of voice-correct answers

```python
system_prompt = f"""You are {author_name} from {country}.

EXAMPLE ANSWERS IN YOUR VOICE:

Q: What makes aluminum challenging?
A: A systematic approach using 1064 nm wavelength requires precisely calibrated power settings. The methodology accounts for aluminum's high reflectivity (>90%) through comprehensive thermal management.
[Voice markers used: systematic, precisely, methodology, comprehensive]

Q: How to verify cleaning?
A: Through rigorous analysis, verify surface quality using empirical measurements. The structured protocol includes reflectivity testing and contamination-free verification across the theoretical baseline.
[Voice markers used: rigorous, empirical, structured, theoretical]

NOW ANSWER IN THE SAME VOICE STYLE:
"""
```

**Pros**:
- âœ… Concrete examples are stronger than abstract rules
- âœ… Single API call (no additional cost)
- âœ… Shows AI exactly what voice sounds like
- âœ… Examples can be pre-validated for quality

**Cons**:
- âŒ Examples may limit creativity/variation
- âŒ Need to create quality examples per country
- âŒ Longer system prompt (token usage)
- âŒ May lead to repetitive patterns

---

### Pattern 4: **Constrained Generation with Required Words**

**Concept**: Force API to use specific words from voice indicator list

```python
user_prompt = f"""
QUESTION: {question}

REQUIRED WORDS TO USE: Choose 2-3 from this list and incorporate naturally:
- {', '.join(voice_indicators[:10])}

MATERIAL DATA: {material_context}

Write your answer (20-60 words):
"""
```

**Pros**:
- âœ… Explicit requirement to use specific words
- âœ… Simple to implement
- âœ… Single API call
- âœ… Clear expectations set

**Cons**:
- âŒ AI may use words unnaturally
- âŒ Forced usage can sound robotic
- âŒ Quality may suffer from constraint
- âŒ Still no guarantee of compliance

---

### Pattern 5: **Post-Processing Voice Injection**

**Concept**: Generate content, then programmatically inject voice markers

```python
# Generate base content
response = api_client.generate_simple(user_prompt, system_prompt)

# Programmatically enhance with voice
enhanced_response = inject_voice_markers(
    text=response,
    voice_indicators=voice_indicators,
    count=2-3
)
```

**Example Injections**:
- "calibrated power" â†’ "precisely calibrated power"
- "analysis shows" â†’ "systematic analysis demonstrates"  
- "process" â†’ "rigorous process"
- "method" â†’ "comprehensive methodology"

**Pros**:
- âœ… Guaranteed voice marker presence
- âœ… Single API call (cost effective)
- âœ… Can be tuned for natural insertion
- âœ… Preserves technical accuracy

**Cons**:
- âŒ May sound artificial/forced
- âŒ Complex NLP for natural insertion
- âŒ Risk of grammatical errors
- âŒ Loses authentic authorship

---

### Pattern 6: **Voice-Weighted Prompt Templates**

**Concept**: Structure prompts to heavily weight voice requirements

```python
system_prompt = f"""PRIMARY OBJECTIVE: Write as {author_name} from {country}.

CRITICAL VOICE REQUIREMENTS (50% of scoring):
âœ… MUST use 2-3 of these words: {voice_indicators}
âœ… MUST follow {country} communication style
âœ… WILL BE REJECTED if voice markers absent

SECONDARY OBJECTIVE: Technical accuracy (50% of scoring)
"""
```

**Pros**:
- âœ… Makes voice the primary concern
- âœ… Single API call
- âœ… Clear priority signaling
- âœ… Psychological framing for AI

**Cons**:
- âŒ AI may prioritize voice over accuracy
- âŒ Still no enforcement mechanism
- âŒ May not actually change behavior

---

## ðŸ—ï¸ Recommended Pattern: **Hybrid Approach**

### Combination Strategy

**Combine Pattern 3 (Few-Shot) + Pattern 1 (Validation) + Pattern 2 (Selection)**

```python
def generate_faq_with_voice_enforcement(
    question: str,
    material_context: Dict,
    author: Dict,
    voice_indicators: List[str]
) -> str:
    """
    Three-stage voice-enforced generation:
    1. Few-shot examples for guidance
    2. Generate multiple candidates
    3. Validate and select best
    """
    
    # STAGE 1: Build few-shot system prompt
    system_prompt = build_few_shot_system_prompt(
        author=author,
        voice_examples=get_voice_examples(author['country']),
        voice_indicators=voice_indicators
    )
    
    # STAGE 2: Generate 2-3 candidates with variation
    candidates = []
    for seed in [42, 123, 789]:
        response = api_client.generate_simple(
            user_prompt=build_task_prompt(question, material_context),
            system_prompt=system_prompt,
            temperature=0.7,
            seed=seed
        )
        
        # Score voice adherence
        score = calculate_voice_score(response, voice_indicators)
        candidates.append((response, score))
    
    # STAGE 3: Select best or regenerate with voice emphasis
    best_candidate, best_score = max(candidates, key=lambda x: x[1])
    
    if best_score >= 2:  # At least 2 voice indicators present
        return best_candidate
    else:
        # Fallback: Voice-corrected regeneration
        return regenerate_with_voice_emphasis(
            best_candidate,
            voice_indicators
        )
```

### Implementation Plan

**Phase 1: Add Few-Shot Examples** (Low effort, high impact)
- Create 2-3 high-quality voice examples per country
- Add to `voice/profiles/{country}.yaml` under `voice_examples`
- Modify VoiceOrchestrator to inject examples into system prompt

**Phase 2: Add Candidate Scoring** (Medium effort, proven technique)
- Generate 2-3 candidates per FAQ question
- Score each for voice adherence
- Select best candidate
- Parallelize API calls for speed

**Phase 3: Add Voice Validation Chain** (High effort, maximum quality)
- If no candidate scores well, trigger validation chain
- Use second API call to rewrite with voice emphasis
- Log failures for prompt improvement

---

## ðŸ“Š Pattern Comparison Matrix

| Pattern | API Calls | Cost | Voice Compliance | Technical Accuracy | Complexity |
|---------|-----------|------|------------------|-------------------|------------|
| **Constitutional AI** | 2x | High | â­â­â­â­ | â­â­â­ | Medium |
| **Scoring Selection** | 3x | High | â­â­â­ | â­â­â­â­ | Low |
| **Few-Shot Examples** | 1x | Low | â­â­â­ | â­â­â­â­ | Low |
| **Constrained Generation** | 1x | Low | â­â­ | â­â­â­ | Low |
| **Post-Processing** | 1x | Low | â­â­â­â­â­ | â­â­ | High |
| **Voice-Weighted** | 1x | Low | â­â­ | â­â­â­ | Low |
| **Hybrid (Recommended)** | 2-3x | Medium | â­â­â­â­â­ | â­â­â­â­ | Medium |

---

## ðŸŽ¯ Actionable Next Steps

### Immediate (Start Tomorrow):
1. **Create few-shot examples** for each country (2-3 examples per country)
2. **Update VoiceOrchestrator** to inject examples into system prompts
3. **Test FAQ generation** with few-shot approach
4. **Measure improvement** in voice indicator presence

### Short-term (This Week):
5. **Implement candidate scoring** system
6. **Add parallel API calls** for 2-3 candidates
7. **Build voice_score calculator** function
8. **Test with Aluminum, Titanium, Bamboo**

### Medium-term (Next Week):
9. **Build validation chain** for low-scoring candidates
10. **Create voice correction prompts** for rewriting
11. **Add logging** for voice compliance tracking
12. **Optimize based on results**

---

## ðŸ’¡ Key Insights

1. **Current Approach Insufficient**: System/user prompt split alone doesn't enforce voice
2. **Few-Shot Most Promising**: Concrete examples > abstract rules for AI
3. **Hybrid Approach Necessary**: Combine few-shot + scoring + validation for reliability
4. **Cost-Quality Tradeoff**: 2-3x API calls acceptable for 5x improvement in voice compliance
5. **Voice Examples Are Key**: Need high-quality, validated examples per country

---

## ðŸ“š References

- **Caption Architecture**: `components/caption/ARCHITECTURE.md` - Proven reusable voice pattern
- **Voice Service**: `voice/voice_service.py` - Current integration approach
- **FAQ Component**: `materials/faq/generators/faq_generator.py` - Current implementation
- **Voice Orchestrator**: `voice/orchestrator.py` - Central voice management

---

**Status**: Research complete, ready for implementation planning  
**Recommendation**: Start with few-shot examples (Phase 1) as low-effort, high-impact improvement
