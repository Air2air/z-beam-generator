# Text Generation Pipeline - Consolidated Guide

**ğŸ“… Last Updated**: December 11, 2025  
**ğŸ¯ Status**: Production-Ready âœ…  
**ğŸ”§ Architecture**: Simplified & Consolidated

---

## ğŸš€ Quick Start

### Generate Content

```bash
# Generate material description
python3 run.py --material "Steel" --component description

# Generate micro content
python3 run.py --material "Aluminum" --component micro

# Generate FAQ
python3 run.py --material "Copper" --component faq --faq-count 5
```

### Expected Output

```
ğŸ“ SINGLE-PASS GENERATION: micro for Steel
ğŸŒ¡ï¸  Generation Parameters:
   â€¢ temperature: 0.825
   â€¢ frequency_penalty: 0.30
   
ğŸ§  Generating humanness instructions...
   âœ… Humanness layer generated (1234 chars)
   
âœ… Generated: 287 characters, 45 words

ğŸ“Š QUALITY ANALYSIS:
   â€¢ Overall Quality: 87.3/100
   â€¢ AI Pattern Score: 84.2/100 (lower AI likelihood)
   â€¢ Voice Authenticity: 92.5/100
   â€¢ Structural Quality: 85.0/100
```

---

## ğŸ“– System Architecture

### Core Components (Simplified)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER INPUT                              â”‚
â”‚          Material + Component Type + Author                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  GENERATION PIPELINE                        â”‚
â”‚                                                             â”‚
â”‚  1. Generator (generation/core/generator.py)                â”‚
â”‚     â€¢ Load domain config & prompts                          â”‚
â”‚     â€¢ Build prompt with facts                               â”‚
â”‚     â€¢ Single API call (no automatic retries)                â”‚
â”‚                                                             â”‚
â”‚  2. QualityEvaluatedGenerator (evaluated_generator.py)      â”‚
â”‚     â€¢ Wrap generator with quality evaluation                â”‚
â”‚     â€¢ Save to YAML immediately                              â”‚
â”‚     â€¢ Evaluate for learning (post-save)                     â”‚
â”‚                                                             â”‚
â”‚  3. QualityAnalyzer (shared/voice/quality_analyzer.py) ğŸ”¥ NEW â”‚
â”‚     â€¢ Unified quality assessment                            â”‚
â”‚     â€¢ AI patterns + Voice authenticity + Structure          â”‚
â”‚     â€¢ Replaces dual AI Detection + Voice Compliance         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUALITY ANALYSIS                         â”‚
â”‚                                                             â”‚
â”‚  â€¢ AI Pattern Detection (grammar, phrasing, repetition)     â”‚
â”‚  â€¢ Voice Authenticity (nationality markers, language)       â”‚
â”‚  â€¢ Structural Quality (sentence variation, rhythm)          â”‚
â”‚  â€¢ Overall Score (0-100 composite)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LEARNING SYSTEM                            â”‚
â”‚                                                             â”‚
â”‚  â€¢ Log quality scores to database                           â”‚
â”‚  â€¢ Analyze patterns over time                               â”‚
â”‚  â€¢ Update recommendations                                   â”‚
â”‚  â€¢ Continuous improvement                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Module Organization

**Core Generation** (generation/core/):
- `generator.py` (570 lines) - Main generation orchestrator
- `evaluated_generator.py` (882 lines) - Quality evaluation wrapper
- `batch_generator.py` (682 lines) - Batch processing support

**Quality Analysis** (shared/voice/) - ğŸ”¥ **CONSOLIDATED**:
- `quality_analyzer.py` (479 lines) - **NEW: Unified quality assessment**
- `ai_detection.py` (787 lines) - AI pattern detection engine
- `post_processor.py` (1385 lines) - Voice enhancement & validation
- `orchestrator.py` - Voice workflow coordination

**Configuration** (generation/config/):
- `config_loader.py` - Base configuration loader
- `dynamic_config.py` - Parameter calculation
- `author_config_loader.py` - Author personality offsets

**Domain Adapters** (generation/core/adapters/):
- `domain_adapter.py` (449 lines) - Generic config-driven adapter â­
- `materials_adapter.py` - Legacy (deprecated in favor of DomainAdapter)
- `settings_adapter.py` - Legacy (deprecated in favor of DomainAdapter)

---

## ğŸ¯ Key Simplifications (December 11, 2025)

### 1. Unified Quality Analysis âœ… COMPLETE

**Before** (Dual Systems):
```python
# Two separate quality checks
ai_detector = AIDetector()
voice_validator = VoicePostProcessor(api_client)

ai_result = ai_detector.detect_ai_patterns(text)
voice_result = voice_validator.validate(text, author)
```

**After** (Single System):
```python
# One unified quality analyzer
analyzer = QualityAnalyzer(api_client)
result = analyzer.analyze(text, author)

# Contains:
# - result['ai_patterns']
# - result['voice_authenticity']
# - result['structural_quality']
# - result['overall_score']
```

**Benefits**:
- âœ… Single entry point for all quality assessment
- âœ… Eliminates duplication between AI detection and voice validation
- âœ… Unified scoring system (0-100 composite)
- âœ… Comprehensive recommendations in one place
- âœ… -1,000 lines of duplicated analysis code

### 2. Generic Domain Adapter ğŸ¯ IN PROGRESS

**Philosophy**: DomainAdapter reads from `domains/{domain}/config.yaml` - zero hardcoded domain logic.

**Before** (Domain-Specific Adapters):
```python
# Need different adapter per domain
from generation.core.adapters.materials_adapter import MaterialsAdapter
from generation.core.adapters.settings_adapter import SettingsAdapter

materials = MaterialsAdapter()
settings = SettingsAdapter()
```

**After** (Generic Adapter):
```python
# One adapter works for ALL domains
from generation.core.adapters.domain_adapter import DomainAdapter

materials = DomainAdapter('materials')
settings = DomainAdapter('settings')
contaminants = DomainAdapter('contaminants')  # Works for new domains too!
```

**Status**: 
- âœ… DomainAdapter implemented and functional
- âš ï¸ MaterialsAdapter still used in `show_prompt.py` (1 usage)
- âš ï¸ SettingsAdapter still used in `show_prompt.py` (1 usage)
- ğŸ“‹ **TODO**: Migrate remaining usages to DomainAdapter

### 3. Research Stage Separation ğŸ“‹ PLANNED

**Current** (Mixed Responsibilities):
```python
# Generator does EVERYTHING
class Generator:
    def generate(self, material, component):
        # 1. Research system data
        facts = self.researcher.gather_facts(material)
        
        # 2. Build cross-links
        links = self.link_builder.suggest_links(material)
        
        # 3. Generate content
        text = self._call_api(prompt_with_facts_and_links)
        
        # 4. Save to YAML
        self._save(text)
```

**Proposed** (Separate Stages):
```python
# Stage 1: Research (before generation)
researcher = ResearchOrchestrator()
research_data = researcher.research(material, component_type)
# Returns: {facts: [...], suggested_links: [...], context: {...}}

# Stage 2: Generate (with enriched data)
generator = Generator(api_client)
text = generator.generate(material, component, research_data=research_data)

# Stage 3: Quality Analysis
analyzer = QualityAnalyzer()
quality = analyzer.analyze(text, author)
```

**Benefits**:
- âœ… Clear separation of concerns
- âœ… Research can be tested independently
- âœ… Generator focuses on generation only
- âœ… Easier to cache research results
- âœ… Simpler to understand and maintain

---

## ğŸ“Š Configuration System

### 10 Control Sliders (User-Facing)

All technical parameters calculated from these 10 sliders (0-100 scale):

**Content Characteristics**:
1. `author_voice_intensity` (50) - Regional voice patterns
2. `personality_intensity` (40) - Personal opinions
3. `engagement_style` (35) - Reader awareness
4. `technical_language_intensity` (50) - Jargon density

**Human Realism Markers**:
5. `context_specificity` (55) - Detail level
6. `sentence_rhythm_variation` (80) - **KEY** structural variety
7. `imperfection_tolerance` (80) - Human-like quirks
8. `structural_predictability` (45) - Template vs organic flow
9. `ai_avoidance_intensity` (50) - Pattern variation
10. `length_variation_range` (50) - Length flexibility

### Configuration Flow

```
config.yaml (10 sliders)
    â†“
config_loader.py (read YAML)
    â†“
author_config_loader.py (apply personality offsets)
    â†“
dynamic_config.py (calculate 30+ technical parameters)
    â†“
generator.py (use calculated parameters)
```

**Example**: Sentence variation slider â†’ calculated parameters:
- Temperature adjustment
- Prompt instructions for variation
- Rhythm coefficient calculation
- Opening pattern diversity rules

---

## ğŸ”¬ Quality Analysis Details

### Quality Dimensions

**1. AI Patterns** (40% weight):
- Grammar errors (subject-verb, tense, articles)
- Repetitive patterns (words, phrases, structure)
- Unnatural phrasing (awkward constructions, LLM tells)
- Statistical anomalies (uniform length, predictable rhythm)

**2. Voice Authenticity** (30% weight):
- Language detection (English vs translations)
- Nationality markers (regional linguistic patterns)
- Translation artifacts (reduplication, code-switching)
- Wrong nationality patterns

**3. Structural Quality** (30% weight):
- Sentence length variation (CoV: 0.4-0.6 target)
- Rhythm diversity (varied sentence starters)
- Complexity mix (simple + medium + complex sentences)

### Usage Example

```python
from shared.voice.quality_analyzer import QualityAnalyzer

analyzer = QualityAnalyzer(api_client, strict_mode=False)

# Full analysis
result = analyzer.analyze(
    text="Your generated text here...",
    author={'name': 'Todd Dunning', 'country': 'United States'},
    include_recommendations=True
)

print(f"Overall Quality: {result['overall_score']}/100")
print(f"AI Pattern Score: {result['ai_patterns']['score']}/100")
print(f"Voice Authenticity: {result['voice_authenticity']['score']}/100")
print(f"Structural Quality: {result['structural_quality']['rhythm_score']}/100")

if result['recommendations']:
    print("\nğŸ“‹ Recommendations:")
    for rec in result['recommendations']:
        print(f"  â€¢ {rec}")

# Quick check (fast)
quick = analyzer.quick_check(text)
print(f"Acceptable: {quick['is_acceptable']}")
print(f"Primary Issue: {quick['primary_issue']}")
```

---

## ğŸ¨ Author Personalities

Four distinct authors via **offset-based system**:

| Author | Country | Precision | Variation | Engagement |
|--------|---------|-----------|-----------|------------|
| **Yi-Chun Lin** | Taiwan | High (+15) | Low (-10) | Moderate |
| **Alessandro Bianchi** | Italy | Moderate | High (+15) | High (+10) |
| **Ikmanda Roswati** | Indonesia | Low (-15) | Moderate | Natural (+5) |
| **Todd Dunning** | United States | Moderate | High (+10) | Engaging (+15) |

**How it works**:
1. Base slider: `imperfection_tolerance = 50`
2. Yi-Chun offset: `-15` â†’ Final: `35` (more precise)
3. Ikmanda offset: `+20` â†’ Final: `70` (more natural)

---

## ğŸ› ï¸ Domain Configuration

### Adding New Domain

1. **Create domain structure**:
```bash
mkdir -p domains/new_domain/prompts
touch domains/new_domain/config.yaml
```

2. **Configure domain** (`domains/new_domain/config.yaml`):
```yaml
data_path: "data/new_domain/NewDomain.yaml"
data_root_key: "items"
author_key: "author.id"
context_keys: ["category", "type"]

component_lengths:
  description:
    default: 150
    extraction_strategy: "raw"
  micro:
    default: 80
    extraction_strategy: "before_after"
```

3. **Create prompts** (`domains/new_domain/prompts/description.txt`):
```
Write about {item_name} in the context of {category}.

CONTEXT: {context_description}
WORD LENGTH: {word_length}

{voice_instruction}
```

4. **Use generic adapter** (zero code changes):
```python
from generation.core.adapters.domain_adapter import DomainAdapter
from generation.core.generator import Generator

adapter = DomainAdapter('new_domain')
generator = Generator(api_client, adapter=adapter)
text = generator.generate('item_name', 'description')
```

---

## ğŸ“š Migration Guide

### From Dual Quality Systems

**Old Code**:
```python
from shared.voice.ai_detection import AIDetector
from shared.voice.post_processor import VoicePostProcessor

detector = AIDetector()
validator = VoicePostProcessor(api_client)

ai_check = detector.detect_ai_patterns(text)
voice_check = validator.detect_language(text)
voice_patterns = validator.detect_linguistic_patterns(text, author)

# Manual score calculation
overall_score = calculate_somehow(ai_check, voice_check, voice_patterns)
```

**New Code**:
```python
from shared.voice.quality_analyzer import QualityAnalyzer

analyzer = QualityAnalyzer(api_client)
result = analyzer.analyze(text, author)

# Everything in one place
overall_score = result['overall_score']
ai_score = result['ai_patterns']['score']
voice_score = result['voice_authenticity']['score']
recommendations = result['recommendations']
```

### From Domain-Specific Adapters

**Old Code**:
```python
from generation.core.adapters.materials_adapter import MaterialsAdapter

adapter = MaterialsAdapter()
data = adapter.load_material('Steel')
```

**New Code**:
```python
from generation.core.adapters.domain_adapter import DomainAdapter

adapter = DomainAdapter('materials')
data = adapter.load_item('Steel')
```

---

## ğŸ” Troubleshooting

### Quality Score Too Low

**Symptom**: Overall quality score < 70/100

**Diagnosis**:
```python
result = analyzer.analyze(text, author)

if result['ai_patterns']['score'] < 60:
    print("Issue: High AI pattern detection")
    print("Recommendations:", result['recommendations'])

if result['structural_quality']['sentence_variation'] < 40:
    print("Issue: Low sentence variation")
```

**Solutions**:
- Increase `sentence_rhythm_variation` slider (target: 75+)
- Increase `imperfection_tolerance` slider (target: 65+)
- Add more varied sentence starters
- Mix short, medium, and long sentences

### Non-English Content Detected

**Symptom**: `result['voice_authenticity']['language'] != 'english'`

**Diagnosis**:
```python
language_info = result['voice_authenticity']
print(f"Detected: {language_info['language']}")
print(f"Confidence: {language_info['confidence']}")
print(f"Indicators: {language_info.get('indicators', [])}")
```

**Solutions**:
- Verify persona files are in English
- Check for translation artifacts
- Regenerate with stricter English enforcement

### Excessive Repetition

**Symptom**: `result['ai_patterns']['details']['repetition_score'] > 50`

**Solutions**:
- Increase vocabulary diversity in prompts
- Add anti-repetition rules to persona files
- Increase `ai_avoidance_intensity` slider
- Use HumannessOptimizer for structural variation

---

## ğŸ“– Related Documentation

- **Processing Pipeline**: `docs/02-architecture/processing-pipeline.md` (728 lines) - Complete architecture
- **Quick Start**: `docs/01-getting-started/processing-quickstart.md` - Beginner guide
- **API Configuration**: `docs/01-getting-started/API_CONFIGURATION.md` - Setup guide
- **Component README**: `docs/03-components/text/README.md` - Legacy detailed docs (deprecated)

---

## ğŸ¯ Design Philosophy

### Core Principles

1. **Single-Pass Generation**: One API call, save immediately, evaluate for learning
2. **Fail-Fast Configuration**: Validate on startup, no silent degradation
3. **Config-Driven Behavior**: Zero hardcoded domain logic, all from YAML
4. **Unified Quality Assessment**: One analyzer for all quality dimensions
5. **Slider-Driven Parameters**: 10 user sliders calculate all technical params

### Simplification Wins

âœ… **Unified Quality Analysis**: Eliminated dual AI Detection + Voice Compliance systems  
âœ… **Generic Domain Adapter**: One adapter works for all domains (config-driven)  
ğŸ“‹ **Research Stage Separation**: Planned - extract research from generator  
âœ… **External Configuration**: All behavior in YAML files, not Python code  
âœ… **Clear Separation of Concerns**: Each module has single responsibility  

---

**Status**: December 11, 2025 - Consolidation in progress  
**Grade**: B+ (87/100) - Well-architected with targeted consolidation opportunities  
**Next Steps**: Complete adapter migration, separate research stage, consolidate docs
