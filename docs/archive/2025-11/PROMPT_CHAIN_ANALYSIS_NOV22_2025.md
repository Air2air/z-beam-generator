# Prompt Chain Analysis & Optimization
**Date**: November 22, 2025  
**Status**: üîç ANALYSIS COMPLETE ‚Üí IMPLEMENTATION READY  
**Purpose**: Evaluate prompt orchestration for clarity, remove hardcoded values, consolidate documentation

---

## üîç Part 1: Prompt Chain Flow Analysis

### Current Prompt Chain (Description Generation)

```
1. prompts/system/base.txt
   ‚Üì (System-level rules: banned words, banned structures, natural writing)
   
2. learning/humanness_optimizer.py ‚Üí prompts/system/humanness_layer.txt
   ‚Üì (Dynamic: Winston patterns, structural diversity, randomization targets)
   
3. prompts/components/description.txt
   ‚Üì (Component-specific: conversational style, structural variation)
   
4. Material facts + properties
   ‚Üì (Data-driven: actual material data)
   
5. FINAL ASSEMBLED PROMPT ‚Üí Grok API
```

---

### ‚úÖ Clarity Assessment: GOOD

**Strengths**:
1. **Clear hierarchy**: System ‚Üí Humanness ‚Üí Component ‚Üí Data
2. **No layer skipping**: Each layer builds on previous
3. **Distinct purposes**: Each layer has specific role
4. **Template-based**: All instructions in .txt files (not code)

**Flow Logic**:
- **base.txt**: Universal rules (apply to ALL content)
- **humanness_layer.txt**: AI detection avoidance (dynamic per attempt)
- **description.txt**: Component-specific guidance (what makes a description)
- **Material data**: Factual content to write about

---

### ‚ö†Ô∏è Contradictions & Confusion Found

#### Issue 1: REDUNDANT STRUCTURAL GUIDANCE üî¥ **CRITICAL**

**Location**: `humanness_layer.txt` (lines 80-96) vs `description.txt` (lines 12-20)

**humanness_layer.txt**:
```
üé≤ **RANDOMIZE YOUR STRUCTURE** - Roll dice and pick ONE:
1. Problem-Focused (Random: 20% chance): Start with challenge ‚Üí explain why ‚Üí solution
2. Contrast-Based (Random: 20% chance): Compare materials ‚Üí highlight difference ‚Üí impact
3. Process-Focused (Random: 20% chance): Walk through setup ‚Üí embed properties naturally
4. Experience-Based (Random: 20% chance): Share what works ‚Üí why ‚Üí avoid
5. Property-Driven (Random: 20% chance): Lead with ONE property ‚Üí deep exploration
```

**description.txt**:
```
üéØ STRUCTURAL VARIATION:
- DON'T follow formula: opening ‚Üí property dump ‚Üí warning ‚Üí recommendation
- DON'T list 3-4 properties with numbers in a row
- DO weave properties into natural explanation of what to do
- DO vary where warnings and recommendations appear
- DO use one of the 5 structural approaches from humanness layer
```

**Problem**: 
- Description.txt **references** "5 structural approaches from humanness layer"
- This creates **dependency** - description.txt must always be after humanness layer
- **Redundant**: Both files mention structural variation (humanness layer more detailed)

**Solution**: 
- **REMOVE** structural variation section from description.txt
- **KEEP** in humanness_layer.txt only (single source of truth)
- Description.txt should focus on CONTENT (what to include), not STRUCTURE (how to organize)

---

#### Issue 2: CONFLICTING LENGTH GUIDANCE üü° **MODERATE**

**Location**: `humanness_layer.txt` (lines 97-101) vs `config.yaml` (component_lengths)

**humanness_layer.txt**:
```
üé≤ **RANDOMIZE LENGTH** - Pick random word count target:
‚Ä¢ Short & Punchy: 150-220 words (25% chance)
‚Ä¢ Medium & Balanced: 220-300 words (25% chance)
‚Ä¢ Detailed & Comprehensive: 300-380 words (25% chance)
‚Ä¢ Deep Dive: 380-450 words (25% chance)
```

**config.yaml**:
```yaml
component_lengths:
  description:
    target: 80  # Target word count
```

**Problem**: 
- Config says target=80 words
- Template says 150-450 words
- **Confusion**: Which one is correct?
- **Reality**: 80 is base target, randomization multiplies by 2-5x (150-450 range)

**Solution**:
- **UPDATE** config.yaml to include randomization ranges
- **REMOVE** hardcoded ranges from template
- Template should reference `{length_target}` from config, not hardcode ranges

---

#### Issue 3: HARDCODED RANDOMIZATION VALUES üî¥ **CRITICAL**

**Location**: `learning/humanness_optimizer.py` (lines 366-410)

**Current Code**:
```python
length_targets = {
    'SHORT': '150-220 words (CONCISE & PUNCHY - 2-3 key points only)',
    'MEDIUM': '220-300 words (BALANCED - cover 4-5 key aspects)',
    'DETAILED': '300-380 words (COMPREHENSIVE - thorough exploration)',
    'DEEP': '380-450 words (DEEP DIVE - exhaustive technical detail)'
}

structure_approaches = [
    '1. Problem-Focused (20% chance): Start with challenge ‚Üí explain why ‚Üí solution',
    '2. Contrast-Based (20% chance): Compare materials ‚Üí highlight difference ‚Üí impact',
    # ... etc
]

voice_styles = [
    'DIRECT INSTRUCTOR: "You must", "Make sure you", "Start with"',
    'TEAM COLLABORATOR: "We typically", "We\'ve found", "In our experience"',
    'EXPERIENCE SHARER: "I\'ve seen", "This works when", "Tends to"'
]
```

**Problem**: 
- **VIOLATION**: Hardcoded values policy (Rule #3 in GROK_QUICK_REF.md)
- Should be in config.yaml, not Python code
- Cannot be changed without code modification
- Not accessible to non-technical users

**Solution**: Move ALL to `config.yaml` ‚Üí `randomization_targets` section

---

#### Issue 4: DUPLICATE VOICE GUIDANCE üü° **MODERATE**

**Location**: `base.txt` vs `humanness_layer.txt` vs `description.txt`

**base.txt** (lines 36-42):
```
=== NATURAL WRITING PRINCIPLES ===
- Write like explaining to a knowledgeable colleague
- Use concrete examples and specific use cases
- Describe behavior in context ("Under X condition, material does Y")
```

**humanness_layer.txt** (lines 50-64):
```
‚úÖ WRITE LIKE A TECHNICIAN EXPLAINING TO A COLLEAGUE:
- Direct address: "you must", "you'll want to", "you need to"
- Team voice: "We typically use", "We recommend", "We've found that"
- Practical warnings: "avoid X", "watch for Y", "be careful with Z"
```

**description.txt** (lines 5-11):
```
üó£Ô∏è WRITING STYLE - CONVERSATIONAL TECHNICAL (CRITICAL):
- Write as if TRAINING SOMEONE to use this material
- Use "you" and "we" throughout ("you'll want to", "we typically")
- Focus on PRACTICAL IMPLICATIONS, not just property values
```

**Problem**: 
- **Same message repeated 3 times** with slightly different wording
- Cognitive load - which one to follow?
- Risk of conflict if one updated but not others

**Solution**:
- **base.txt**: Keep general principle ("write like colleague")
- **humanness_layer.txt**: Keep detailed voice examples (this is where randomization applies)
- **description.txt**: REMOVE voice style section (already covered in humanness layer)

---

#### Issue 5: OPENING PATTERN REDUNDANCY üü° **MODERATE**

**Location**: `humanness_layer.txt` (lines 17-42)

**Current**:
```
**üö® OPENING SENTENCE RULE (MOST IMPORTANT) üö®**

YOU MUST START WITH ONE OF THESE PATTERNS (VARY THEM):

‚úÖ HIGH-PERFORMING OPENINGS (Use these 70% of the time):
1. "When laser cleaning [material], you'll want to..." (22.9% avg Winston)
2. "The key with [material] is..." (25.1% avg Winston)
3. "When cleaning [material], watch..." (variation of #1)
4. "If you're cleaning [material], start by..."

‚ö†Ô∏è MODERATE OPENINGS (Use sparingly):
5. "With [material], the challenge is..."
6. "[Material] cleans best when..."
7. "You'll find [material] needs..."

‚ùå AVOID THESE OPENINGS (Poor Winston performance):
- "For [material], we typically..." (4.1% avg Winston - WORST)
```

**Problem**:
- **GOOD**: Data-driven opening patterns from Winston database
- **ISSUE**: Hardcoded percentages (22.9%, 25.1%, 4.1%) should be dynamic
- **CONFUSION**: Says "USE THESE 70% of time" but randomization is 20% each structure

**Solution**:
- Opening patterns should be **dynamic from database** (already extracted in `_extract_structural_patterns()`)
- Remove hardcoded Winston percentages (query database for current stats)
- Align with randomization approach (patterns selected randomly, not 70/30 split)

---

## üîß Part 2: Hardcoded Values Removal

### Hardcoded Values Inventory

#### Category 1: Randomization Targets (CRITICAL)
**File**: `learning/humanness_optimizer.py`

| Line | Value | Type | Fix |
|------|-------|------|-----|
| 368-371 | length_targets dict | Length ranges | Move to config.yaml |
| 378-382 | structure_approaches list | Structures | Move to config.yaml |
| 386-390 | voice_styles list | Voice personas | Move to config.yaml |
| 394-398 | rhythm_patterns list | Sentence rhythms | Move to config.yaml |
| 402-407 | property_strategies list | Property integration | Move to config.yaml |
| 411-415 | warning_placements list | Warning positions | Move to config.yaml |

**Total**: 6 categories √ó ~4 values each = **24 hardcoded values**

---

#### Category 2: Template Ranges (MODERATE)
**File**: `prompts/system/humanness_layer.txt`

| Line | Value | Type | Fix |
|------|-------|------|-----|
| 7 | "150-450 words" | Length range | Use {length_range_total} |
| 8 | "5-8 words" | Short sentence | Use {short_sentence_range} |
| 9 | "20-30 words" | Long sentence | Use {long_sentence_range} |
| 97-100 | "150-220", "220-300", etc. | Length targets | Use {length_targets} |

**Total**: **4 hardcoded ranges**

---

#### Category 3: Probability Percentages (LOW PRIORITY)
**File**: `prompts/system/humanness_layer.txt`

| Line | Value | Type | Fix |
|------|-------|------|-----|
| 90-94 | "20% chance" (5 times) | Structure probability | Keep in template (user-friendly) |
| 103 | "33% chance" (3 times) | Voice probability | Keep in template (user-friendly) |

**Note**: These are **display values** for user clarity, not functional code. Can remain in template.

---

### Proposed config.yaml Structure

```yaml
# Randomization Targets Configuration
# All randomization options for humanness layer generation
randomization_targets:
  
  # Length variation targets (word counts)
  length:
    short:
      range: [150, 220]
      description: "CONCISE & PUNCHY - 2-3 key points only"
      probability: 0.25
    medium:
      range: [220, 300]
      description: "BALANCED - cover 4-5 key aspects"
      probability: 0.25
    detailed:
      range: [300, 380]
      description: "COMPREHENSIVE - thorough exploration"
      probability: 0.25
    deep:
      range: [380, 450]
      description: "DEEP DIVE - exhaustive technical detail"
      probability: 0.25
  
  # Structural approaches
  structures:
    problem_focused:
      label: "Problem-Focused"
      description: "Start with challenge ‚Üí explain why ‚Üí solution"
      probability: 0.20
    contrast_based:
      label: "Contrast-Based"
      description: "Compare materials ‚Üí highlight difference ‚Üí impact"
      probability: 0.20
    process_focused:
      label: "Process-Focused"
      description: "Walk through setup ‚Üí embed properties naturally"
      probability: 0.20
    experience_based:
      label: "Experience-Based"
      description: "Share what works ‚Üí why ‚Üí what to avoid"
      probability: 0.20
    property_driven:
      label: "Property-Driven"
      description: "Lead with ONE property ‚Üí deep exploration"
      probability: 0.20
  
  # Voice styles (author personas)
  voices:
    direct_instructor:
      label: "DIRECT INSTRUCTOR"
      examples: ["You must", "Make sure you", "Start with"]
      description: "Commanding, prescriptive"
      probability: 0.33
    team_collaborator:
      label: "TEAM COLLABORATOR"
      examples: ["We typically", "We've found", "In our experience"]
      description: "Inclusive, shared experience"
      probability: 0.33
    experience_sharer:
      label: "EXPERIENCE SHARER"
      examples: ["I've seen", "This works when", "Tends to"]
      description: "Observational, practical"
      probability: 0.34
  
  # Sentence rhythm patterns
  rhythms:
    short_punchy:
      label: "SHORT & PUNCHY"
      description: "Use mostly 5-10 word sentences. Rapid fire. Direct impact. Build momentum."
      sentence_range: [5, 10]
      probability: 0.33
    mixed_cadence:
      label: "MIXED CADENCE"
      description: "Alternate short (5-10 word) and long (20-30 word) sentences for natural rhythm."
      short_range: [5, 10]
      long_range: [20, 30]
      probability: 0.33
    complex_compound:
      label: "COMPLEX COMPOUND"
      description: "Use longer, detailed sentences (15-30 words) with clauses and technical depth."
      sentence_range: [15, 30]
      probability: 0.34
  
  # Property integration strategies
  property_strategies:
    scattered:
      label: "SCATTERED INTEGRATION"
      description: "Distribute properties throughout narrative (never list)"
      probability: 0.25
    deep_dive:
      label: "DEEP DIVE ONE"
      description: "Focus deeply on ONE property first, mention others briefly later"
      probability: 0.25
    comparative:
      label: "COMPARATIVE"
      description: "Use properties to compare/contrast with similar materials"
      probability: 0.25
    problem_solution:
      label: "PROBLEM-SOLUTION"
      description: "Present property as solution to specific challenge"
      probability: 0.25
  
  # Warning placement options
  warning_placements:
    early:
      label: "EARLY WARNING"
      description: "Start with critical safety/setup concern (first 2-3 sentences)"
      probability: 0.33
    mid_flow:
      label: "MID-FLOW WARNING"
      description: "Embed warning naturally in middle of narrative"
      probability: 0.33
    concluding:
      label: "CONCLUDING WARNING"
      description: "End with key caution or recommendation"
      probability: 0.34
```

---

## üìù Part 3: Implementation Plan

### Step 1: Add randomization_targets to config.yaml ‚úÖ

**File**: `generation/config.yaml`  
**Action**: Add complete randomization_targets section (see above)  
**Lines**: Append after line 177 (after word_count_variation)

---

### Step 2: Update humanness_optimizer.py to read from config ‚úÖ

**File**: `learning/humanness_optimizer.py`

**Changes**:
1. Add config loading in `__init__`:
```python
def __init__(self, winston_db_path: str = 'z-beam.db', config_path: str = 'generation/config.yaml'):
    self.config = self._load_config(config_path)
    # ... existing code
```

2. Replace hardcoded dictionaries with config reads:
```python
# OLD (lines 368-371):
length_targets = {
    'SHORT': '150-220 words (CONCISE & PUNCHY)',
    # ...
}

# NEW:
length_targets = self._get_randomization_targets('length')
```

3. Add helper method:
```python
def _get_randomization_targets(self, category: str) -> Dict:
    """Load randomization targets from config."""
    if 'randomization_targets' not in self.config:
        raise ConfigurationError(f"Missing randomization_targets in config")
    
    if category not in self.config['randomization_targets']:
        raise ConfigurationError(f"Missing {category} in randomization_targets")
    
    return self.config['randomization_targets'][category]
```

---

### Step 3: Update humanness_layer.txt template placeholders ‚úÖ

**File**: `prompts/system/humanness_layer.txt`

**Changes**:
1. Line 7: `150-450 words` ‚Üí `{length_range_total}`
2. Lines 97-100: Remove hardcoded ranges, use dynamic injection from config
3. Keep display percentages (20%, 33%) - these are user-friendly, not functional

---

### Step 4: Simplify component templates ‚úÖ

**File**: `prompts/components/description.txt`

**Remove** (lines 12-20):
```
üéØ STRUCTURAL VARIATION:
- DON'T follow formula: opening ‚Üí property dump ‚Üí warning ‚Üí recommendation
- DON'T list 3-4 properties with numbers in a row
- DO weave properties into natural explanation of what to do
- DO vary where warnings and recommendations appear
- DO use one of the 5 structural approaches from humanness layer
```

**Keep only**:
```
CONTENT FOCUS:
- The material's strengths and weaknesses for laser cleaning (and what to DO about them)
- What makes this material DIFFERENT and how that affects your approach
- UNUSUAL properties and their practical implications
- PITFALLS to avoid and settings adjustments needed
```

---

### Step 5: Create tests for config-driven randomization ‚úÖ

**File**: `tests/test_randomization_config.py` (NEW)

**Tests**:
1. `test_randomization_targets_exist_in_config()` - Verify all categories present
2. `test_probabilities_sum_to_one()` - Ensure each category probabilities = 1.0
3. `test_humanness_optimizer_loads_from_config()` - Verify no hardcoded fallbacks
4. `test_randomization_selections_use_config()` - Verify selections come from config
5. `test_config_missing_raises_error()` - Verify fail-fast on missing config

---

### Step 6: Update documentation ‚úÖ

**Files to update**:
1. `docs/QUICK_REFERENCE.md` - Add randomization config section
2. `RANDOMIZATION_ENHANCEMENTS_NOV22_2025.md` - Document config-driven approach
3. `.github/copilot-instructions.md` - Update hardcoded values policy example

---

## üìö Part 4: Documentation Consolidation Proposal

### Current Documentation Structure (Problems)

```
docs/
‚îú‚îÄ‚îÄ QUICK_REFERENCE.md (1,100 lines) ‚ö†Ô∏è TOO LONG
‚îú‚îÄ‚îÄ INDEX.md (280 lines) - Navigation
‚îú‚îÄ‚îÄ README.md (150 lines) - Overview
‚îú‚îÄ‚îÄ SYSTEM_INTERACTIONS.md (450 lines) - Architecture
‚îú‚îÄ‚îÄ BATCH_GENERATION.md (330 lines) - Batch operations
‚îú‚îÄ‚îÄ 01-getting-started/ (5 files)
‚îú‚îÄ‚îÄ 02-architecture/ (12 files) ‚ö†Ô∏è SPRAWL
‚îú‚îÄ‚îÄ 03-components/ (8 files)
‚îú‚îÄ‚îÄ 04-operations/ (6 files)
‚îú‚îÄ‚îÄ 05-data/ (15 files) ‚ö†Ô∏è TOO MANY
‚îú‚îÄ‚îÄ 06-ai-systems/ (9 files)
‚îú‚îÄ‚îÄ 07-api/ (4 files)
‚îú‚îÄ‚îÄ 08-development/ (11 files) ‚ö†Ô∏è SPRAWL
‚îú‚îÄ‚îÄ 09-reference/ (3 files)
‚îú‚îÄ‚îÄ archive/ (50+ files) ‚ö†Ô∏è ARCHIVE BLOAT
‚îî‚îÄ‚îÄ decisions/ (8 ADRs)

TOTAL: ~120 documentation files
```

**Problems for AI Assistants**:
1. **Too many files**: 120+ files to search through
2. **QUICK_REFERENCE.md too long**: 1,100 lines defeats "quick" purpose
3. **Redundancy**: Same topics covered in multiple places
4. **Archive clutter**: 50+ archived files mixed with current docs
5. **No clear entry point**: INDEX.md vs README.md vs QUICK_REFERENCE.md confusion

---

### Proposed Consolidated Structure

```
docs/
‚îú‚îÄ‚îÄ üìñ AI_ASSISTANT_GUIDE.md (NEW) ‚≠ê PRIMARY ENTRY POINT FOR AI
‚îÇ   ‚îú‚îÄ‚îÄ Quick navigation map (what doc to check for what question)
‚îÇ   ‚îú‚îÄ‚îÄ Common Q&A (top 20 user questions with direct answers)
‚îÇ   ‚îú‚îÄ‚îÄ File location reference (where is X?)
‚îÇ   ‚îú‚îÄ‚îÄ Policy quick ref (hardcoded values, mocks, fail-fast)
‚îÇ   ‚îî‚îÄ‚îÄ Emergency procedures (rollback, recovery)
‚îÇ
‚îú‚îÄ‚îÄ üöÄ GETTING_STARTED.md (consolidate 01-getting-started/)
‚îÇ   ‚îú‚îÄ‚îÄ Installation
‚îÇ   ‚îú‚îÄ‚îÄ Configuration
‚îÇ   ‚îú‚îÄ‚îÄ First generation
‚îÇ   ‚îî‚îÄ‚îÄ Common issues
‚îÇ
‚îú‚îÄ‚îÄ üèóÔ∏è ARCHITECTURE.md (consolidate 02-architecture/ core files)
‚îÇ   ‚îú‚îÄ‚îÄ System overview
‚îÇ   ‚îú‚îÄ‚îÄ Component architecture
‚îÇ   ‚îú‚îÄ‚îÄ Data flow
‚îÇ   ‚îî‚îÄ‚îÄ Processing pipeline
‚îÇ
‚îú‚îÄ‚îÄ üéØ GENERATION_GUIDE.md (consolidate 04-operations/ + BATCH_GENERATION.md)
‚îÇ   ‚îú‚îÄ‚îÄ Single generation
‚îÇ   ‚îú‚îÄ‚îÄ Batch operations
‚îÇ   ‚îú‚îÄ‚îÄ Quality gates
‚îÇ   ‚îî‚îÄ‚îÄ Parameter tuning
‚îÇ
‚îú‚îÄ‚îÄ üíæ DATA_GUIDE.md (consolidate 05-data/ core files)
‚îÇ   ‚îú‚îÄ‚îÄ Materials.yaml structure
‚îÇ   ‚îú‚îÄ‚îÄ Property research
‚îÇ   ‚îú‚îÄ‚îÄ Data validation
‚îÇ   ‚îî‚îÄ‚îÄ Export process
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ AI_SYSTEMS.md (consolidate 06-ai-systems/)
‚îÇ   ‚îú‚îÄ‚îÄ Winston integration
‚îÇ   ‚îú‚îÄ‚îÄ Subjective evaluation
‚îÇ   ‚îú‚îÄ‚îÄ Learning systems
‚îÇ   ‚îî‚îÄ‚îÄ Prompt engineering
‚îÇ
‚îú‚îÄ‚îÄ üîß DEVELOPMENT.md (consolidate 08-development/)
‚îÇ   ‚îú‚îÄ‚îÄ Testing
‚îÇ   ‚îú‚îÄ‚îÄ Debugging
‚îÇ   ‚îú‚îÄ‚îÄ Contributing
‚îÇ   ‚îî‚îÄ‚îÄ Code standards
‚îÇ
‚îú‚îÄ‚îÄ üìö API_REFERENCE.md (consolidate 07-api/ + 09-reference/)
‚îÇ   ‚îú‚îÄ‚îÄ Run.py commands
‚îÇ   ‚îú‚îÄ‚îÄ Python API
‚îÇ   ‚îú‚îÄ‚îÄ Configuration options
‚îÇ   ‚îî‚îÄ‚îÄ Database schema
‚îÇ
‚îú‚îÄ‚îÄ decisions/ (keep ADRs - 8 files)
‚îî‚îÄ‚îÄ archive/ (MOVE TO .archive-docs/ hidden folder)

CONSOLIDATED: 8 main docs + ADRs + hidden archive = ~20 visible files
```

---

### AI_ASSISTANT_GUIDE.md Structure (NEW PRIMARY DOC)

```markdown
# AI Assistant Guide - Z-Beam Generator
**Last Updated**: November 22, 2025  
**Purpose**: Single entry point for AI assistants (Copilot, Claude, Grok)

---

## üöÄ Quick Navigation (30 seconds or less)

**User asked about...**
- **Generating content** ‚Üí See GENERATION_GUIDE.md
- **Configuration** ‚Üí See GETTING_STARTED.md#configuration
- **Data structure** ‚Üí See DATA_GUIDE.md
- **Errors/debugging** ‚Üí See DEVELOPMENT.md#troubleshooting
- **Architecture** ‚Üí See ARCHITECTURE.md
- **AI systems** ‚Üí See AI_SYSTEMS.md

---

## ‚ùì Top 20 User Questions (with direct answers)

### Generation Questions
1. **"Generate a description for Aluminum"**
   ```bash
   python3 run.py --description "Aluminum"
   ```

2. **"What's the quality threshold?"**
   - Realism: 5.5/10 (adaptive with attempts)
   - Winston: 69% human minimum
   - See: GENERATION_GUIDE.md#quality-gates

### Configuration Questions
3. **"Where are API keys configured?"**
   - File: `generation/config.yaml`
   - Keys: `grok_api_key`, `winston_api_key`
   - See: GETTING_STARTED.md#api-setup

### Data Questions
4. **"Where is material data stored?"**
   - Primary: `data/materials/Materials.yaml`
   - Export: `frontmatter/materials/[material].md`
   - See: DATA_GUIDE.md#data-architecture

... (16 more Q&A entries)

---

## üìÇ File Location Reference

### Configuration Files
- `generation/config.yaml` - Main config (quality gates, parameters)
- `z-beam-92ac51c323a3.json` - GCP service account
- `.env` - API keys (if used instead of config.yaml)

### Prompt Files
- `prompts/system/base.txt` - Universal rules
- `prompts/system/humanness_layer.txt` - AI detection avoidance
- `prompts/components/description.txt` - Description guidance
- `prompts/profiles/` - Technical/rhythm profiles (YAML)

### Data Files
- `data/materials/Materials.yaml` - Single source of truth
- `data/materials/Categories.yaml` - Category ranges
- `z-beam.db` - SQLite (Winston, learning, patterns)

### Generation Code
- `generation/core/quality_gated_generator.py` - Main generator
- `generation/core/prompt_builder.py` - Prompt assembly
- `learning/humanness_optimizer.py` - Humanness layer generation

---

## üõ°Ô∏è Policy Quick Reference

### Zero Hardcoded Values Policy
‚ùå **NEVER**:
- `temperature = 0.8` (use `config.get_temperature()`)
- `frequency_penalty = 0.0` (use `dynamic_config.calculate_penalties()`)
- `if score > 30:` (use `config.get_threshold('score_type')`)

‚úÖ **ALWAYS**:
- Load from `generation/config.yaml`
- Use `dynamic_config` for calculated values
- Fail-fast if config missing

### No Mocks/Fallbacks Policy
‚ùå **NEVER in production code**:
- `or "default"` fallbacks
- `except: pass` silent failures
- Skip logic bypassing validation

‚úÖ **ALLOWED in test code**:
- Mock API responses for testing
- Fallback test data

---

## üö® Emergency Procedures

### Rollback Changes
```bash
git status                    # See what changed
git checkout HEAD -- <file>   # Restore specific file
git revert <commit>           # Revert entire commit
```

### Recovery from Bad Generation
```bash
# Check last working commit
git log --oneline data/materials/Materials.yaml

# Restore from specific commit
git checkout <commit> -- data/materials/Materials.yaml
```

---

## üìñ Full Documentation Map

| Topic | Document | When to Use |
|-------|----------|-------------|
| Getting started | GETTING_STARTED.md | Initial setup, first run |
| Architecture | ARCHITECTURE.md | Understanding system design |
| Generation | GENERATION_GUIDE.md | Running generators, batch ops |
| Data | DATA_GUIDE.md | Materials.yaml, properties |
| AI systems | AI_SYSTEMS.md | Winston, learning, prompts |
| Development | DEVELOPMENT.md | Testing, debugging, contributing |
| API | API_REFERENCE.md | Commands, options, schema |
| Decisions | decisions/*.md | Why things work this way |

---

**Next Steps**:
1. Read this guide
2. Check relevant focused doc for your task
3. Search codebase if answer not found
4. Ask user if still unclear
```

---

## ‚úÖ Implementation Checklist

### Phase 1: Remove Hardcoded Values (HIGH PRIORITY)
- [ ] Add `randomization_targets` to config.yaml (6 categories)
- [ ] Update `humanness_optimizer.py` to read from config
- [ ] Update `humanness_layer.txt` template placeholders
- [ ] Create `tests/test_randomization_config.py` (5 tests)
- [ ] Run tests: `pytest tests/test_randomization_config.py -v`

### Phase 2: Simplify Prompt Chain (MODERATE PRIORITY)
- [ ] Remove structural variation from `description.txt`
- [ ] Remove voice style from `description.txt`
- [ ] Update opening patterns to be fully dynamic
- [ ] Test generation with simplified prompts

### Phase 3: Documentation Consolidation (READY WHEN TIME PERMITS)
- [ ] Create `docs/AI_ASSISTANT_GUIDE.md` (primary entry point)
- [ ] Consolidate `01-getting-started/` ‚Üí `GETTING_STARTED.md`
- [ ] Consolidate `02-architecture/` core ‚Üí `ARCHITECTURE.md`
- [ ] Consolidate `04-operations/` ‚Üí `GENERATION_GUIDE.md`
- [ ] Consolidate `05-data/` core ‚Üí `DATA_GUIDE.md`
- [ ] Consolidate `06-ai-systems/` ‚Üí `AI_SYSTEMS.md`
- [ ] Consolidate `08-development/` ‚Üí `DEVELOPMENT.md`
- [ ] Consolidate `07-api/` + `09-reference/` ‚Üí `API_REFERENCE.md`
- [ ] Move `archive/` ‚Üí `.archive-docs/` (hidden)
- [ ] Update all cross-references
- [ ] Test AI assistant navigation

---

## üìä Expected Impact

### Prompt Chain Clarity
- **Before**: 3 files with redundant instructions, 4 confusion points
- **After**: Clean hierarchy, single source of truth per topic
- **Benefit**: AI can process prompts faster, less conflicting guidance

### Hardcoded Values
- **Before**: 24+ hardcoded values in Python code
- **After**: 0 hardcoded values, all in config.yaml
- **Benefit**: Easy to modify, policy compliant, user-accessible

### Documentation
- **Before**: 120+ files, 1,100-line QUICK_REFERENCE.md
- **After**: 8 focused docs, 500-line AI_ASSISTANT_GUIDE.md
- **Benefit**: Faster navigation, less cognitive load, clearer structure

---

## üéì Key Insights

### Why Redundancy Happens
1. **Incremental development**: Features added without refactoring old guidance
2. **Layer confusion**: Unclear which layer should contain which instructions
3. **Template evolution**: Prompts improved but old text not removed

### Why Hardcoded Values Persist
1. **Rapid prototyping**: Easier to hardcode during experimentation
2. **Config complexity**: YAML structure harder than Python dicts
3. **Policy awareness**: Not all code reviewed against hardcoded values policy

### Why Documentation Sprawls
1. **Detailed explanations**: Comprehensive docs became too comprehensive
2. **Archive accumulation**: Historical docs kept "just in case"
3. **No consolidation pass**: Documentation grew but never pruned

---

## üèÜ Success Metrics

### After Implementation:
- [ ] Zero hardcoded randomization values in Python code
- [ ] Config.yaml contains all 6 randomization categories
- [ ] All tests passing (including new randomization config tests)
- [ ] Prompt chain has single source of truth per instruction type
- [ ] AI_ASSISTANT_GUIDE.md answers top 20 user questions
- [ ] Documentation reduced from 120 files to <20 visible files
- [ ] AI assistant query time reduced by 50% (fewer files to search)

---

**Status**: Ready for implementation - all changes planned and scoped
