# Batch Test Report Requirements

**Last Updated**: November 16, 2025  
**Applies To**: All component types (caption, subtitle, FAQ, description, etc.)

---

## Report Format Specification

Batch test reports MUST include three sections in this order:

### 1. Immediate Alerts/Issues Section

**Purpose**: Surface critical problems at the top for quick triage  
**Location**: Before detailed results  
**Display**: Each material/component combination

#### Alert Criteria:
- üö® **GENERATION FAILED** - Component generation did not complete
- ‚ö†Ô∏è  **LOW HUMAN SCORE** - Winston AI score < 70% human
- ‚ö†Ô∏è  **SUBJECTIVE VALIDATION FAILED** - Excessive violations detected
- ‚úÖ **NO ISSUES DETECTED** - All checks passed

#### Format:
```
üö® ALERT: GENERATION FAILED
Error: [error message]

‚ö†Ô∏è  ALERT: LOW HUMAN SCORE
Winston Score: 65.3% (threshold: 70%)

‚ö†Ô∏è  ALERT: SUBJECTIVE VALIDATION FAILED
Violations: 8 (max: 6)

‚úÖ NO ISSUES DETECTED
```

---

### 2. Subjective Evaluation (Above Each Text Item)

**Purpose**: Show quality metrics before displaying generated content  
**Location**: Immediately before the generated text  
**Display**: For each successful generation

#### Required Metrics:
1. **Validation Status**: PASS/FAIL with violation count
2. **Winston Score**: Human percentage (if available)
3. **Generation Time**: Elapsed seconds
4. **Violation Details**: (if applicable)
   - Category breakdown
   - Specific words/patterns
   - Comma count (if excessive)

#### Format:
```
üìä SUBJECTIVE EVALUATION:
----------------------------------------------------------------------
‚úÖ PASS - No violations detected
Winston: 91.7% human
Generation Time: 16.2s

OR

‚ùå FAIL - 7 violations (HIGH severity)
  ‚Ä¢ conversational: now (2x), but (1x)
  ‚Ä¢ hedging: around (1x)
  ‚Ä¢ Excessive commas: 8 (AI pattern)
Winston: 45.2% human
Generation Time: 23.4s
```

---

### 3. Generated Text Item

**Purpose**: Display the actual generated content  
**Location**: After subjective evaluation  
**Display**: Full text as generated

#### Format:
```
üìù GENERATED [COMPONENT_TYPE]:
----------------------------------------------------------------------
[Generated content here - full text]
```

#### Component Type Labels:
- `GENERATED CAPTION` - For captions
- `GENERATED SUBTITLE` - For subtitles
- `GENERATED FAQ` - For FAQs
- `GENERATED DESCRIPTION` - For descriptions
- `GENERATED [TYPE]` - For any other component

---

## Terminal Output Example

```
======================================================================
Aluminum (Author 4)
======================================================================

‚úÖ NO ISSUES DETECTED

üìä SUBJECTIVE EVALUATION:
----------------------------------------------------------------------
‚úÖ PASS - No violations detected
Winston: 99.4% human
Generation Time: 28.1s

üìù GENERATED CAPTION:
----------------------------------------------------------------------
Aluminum powers cars and planes with its light weight, around 2.7 grams 
per cubic centimeter. But grime layers coat the surface, trapping oils 
and particles. At 1000x magnification, those contaminants sprawl like 
stubborn stains, blocking that smooth metallic gleam. Laser at 1064 
nanometer wavelength zaps it clean. Surface emerges bare and ready for 
aerospace use.
```

---

## Markdown Report Requirements

The generated markdown report (e.g., `BATCH_CAPTION_TEST_REPORT.md`) MUST include:

### Executive Summary
- Total materials tested
- Success/failure counts
- Average scores (Winston, subjective)
- Total credits/tokens used

### Quick Results Table
- Material name
- Status (‚úÖ PASS / ‚ùå FAIL)
- Human %
- AI %
- Notes

### Detailed Reports
For each material:
1. Alert section (if issues)
2. Subjective evaluation metrics
3. Generated text (full content)
4. Performance metrics (time, tokens, credits)

### Recommendations
- Actionable next steps based on results
- Pattern identification
- System health assessment

---

## Implementation Requirements

### Data Extraction
Scripts MUST extract from generation output:
1. ‚úÖ Success/failure status
2. ‚úÖ Winston human score
3. ‚úÖ Winston AI score
4. ‚úÖ Generated text (from Materials.yaml or equivalent)
5. ‚úÖ Subjective validation results
6. ‚úÖ Violation details (count, categories, words)
7. ‚úÖ Generation time (elapsed seconds)

### Report Generation
1. ‚úÖ Display terminal output with 3 sections
2. ‚úÖ Generate markdown file with comprehensive details
3. ‚úÖ Overwrite static report file (e.g., `BATCH_[TYPE]_TEST_REPORT.md`)
4. ‚úÖ Include timestamp in report header
5. ‚úÖ Provide file location and size after generation

---

## Testing Requirements

### Unit Tests
Test files MUST verify:
1. ‚úÖ Alert detection logic (failed generation, low scores, violations)
2. ‚úÖ Text extraction from data files
3. ‚úÖ Subjective evaluation parsing
4. ‚úÖ Report formatting (terminal and markdown)

### Integration Tests
Batch test scripts MUST:
1. ‚úÖ Test all 4 author personas
2. ‚úÖ Extract and display generated text
3. ‚úÖ Show subjective evaluation before text
4. ‚úÖ Surface alerts/issues immediately
5. ‚úÖ Generate markdown report
6. ‚úÖ Complete within reasonable time (< 3 minutes for 4 materials)

---

## File Locations

### Scripts
- `scripts/batch_caption_test.py` - Caption batch test
- `scripts/batch_subtitle_test.py` - Subtitle batch test (future)
- `scripts/batch_faq_test.py` - FAQ batch test (future)

### Reports
- `BATCH_CAPTION_TEST_REPORT.md` - Caption batch report (static filename)
- `BATCH_SUBTITLE_TEST_REPORT.md` - Subtitle batch report (future)
- `BATCH_FAQ_TEST_REPORT.md` - FAQ batch report (future)

### Tests
- `tests/test_batch_report_format.py` - Report format validation
- `tests/test_batch_test_integration.py` - End-to-end batch test

---

## Command-Line Interface

### Run Batch Test
```bash
# Caption batch test
python3 run.py --batch-test

# Future: Component-specific batch tests
python3 run.py --batch-test --component caption
python3 run.py --batch-test --component subtitle
python3 run.py --batch-test --component faq
```

### Expected Output
1. ‚úÖ Terminal progress (each material)
2. ‚úÖ Detailed results (3-section format)
3. ‚úÖ Summary statistics
4. ‚úÖ Report file generation confirmation

---

## Quality Standards

### Alert Thresholds
- **Winston Human Score**: < 70% triggers LOW HUMAN SCORE alert
- **Subjective Violations**: > max threshold triggers VALIDATION FAILED alert
- **Generation Failure**: Any exception or non-zero exit code triggers FAILED alert

### Report Completeness
- ‚úÖ All generated text must be captured and displayed
- ‚úÖ All metrics must be extracted and reported
- ‚úÖ Missing data must show warning (‚ö†Ô∏è  Data not captured)
- ‚úÖ Errors must be surfaced in alert section

### Performance Standards
- ‚úÖ Batch test completes within 3 minutes (4 materials)
- ‚úÖ Report generation < 1 second
- ‚úÖ No hanging or timeout issues

---

## Maintenance Notes

### When Adding New Component Types
1. Create batch test script using this format
2. Update run.py with new command flag
3. Add tests for new component type
4. Document component-specific requirements

### When Modifying Report Format
1. Update this documentation first
2. Update all batch test scripts consistently
3. Update tests to match new format
4. Regenerate example reports

---

## References

- **Example Implementation**: `scripts/batch_caption_test.py`
- **Report Classes**: `processing/reports/generation_report.py`
- **Validation**: `processing/validation/subjective_validator.py`
- **Integration**: `run.py` (--batch-test command)
