#!/usr/bin/env python3
"""
Z-Beam Generator - Main Interface (Cleaned)

A comprehensive AI-powered content generation system for laser cleaning materi        "content": {
            "enabled": True,
            "data_provider": "hybrid",
            "api_provider": "deepseek"
        },
        "jsonld": {
            "enabled": True, 
            "data_provider": "frontmatter", 
            "api_provider": "none"
        },
        "table": {
            "enabled": True, 
            "data_provider": "API", 
            "api_provider": "grok"
        },on imports functionality from extracted modules for better maintainability.

üöÄ QUICK START SCRIPTS (User Commands):
========================================

BASIC GENERATION:
    python3 run.py                                    # Generate all materials (batch mode)
    python3 run.py --material "Steel"                 # Generate specific material
    python3 run.py --material "Aluminum" --author 2   # Generate with Italian author
    python3 run.py --start-index 50                   # Start batch from material #50
    python3 run.py --content-batch                    # Clear and regenerate content for first 8 categories

COMPONENT CONTROL:
    python3 run.py --material "Copper" --author 2 --components "frontmatter,text"  # Specific components only
    python3 run.py --list-components                  # Show all available components
    python3 run.py --show-config                      # Show component configuration

CONTENT MANAGEMENT:
    python3 run.py --clean                           # Remove all generated content files
    python3 run.py --yaml                            # Validate and fix YAML errors

SYSTEM INFO:
    python3 run.py --list-materials                  # List all available materials  
    python3 run.py --list-authors                    # List all authors with countries
    python3 run.py --check-env                       # Check API keys and environment
    python3 run.py --test-api                        # Test API connectivity
    python3 run.py --test                            # Run comprehensive test suite

MATERIAL MANAGEMENT (separate script):
    python3 remove_material.py --list-materials      # List all materials by category
    python3 remove_material.py --find-orphans        # Find orphaned files
    python3 remove_material.py --material "Material Name" --dry-run    # Test removal
    python3 remove_material.py --material "Material Name" --execute    # Remove material

PATH CLEANUP (one-time scripts):
    python3 cleanup_paths.py                         # Rename files to clean format (already done)

üéØ COMMON WORKFLOWS:
==================
1. Generate all content:           python3 run.py
2. Generate specific material:     python3 run.py --material "Steel"
3. Clean and regenerate:          python3 run.py --clean && python3 run.py
4. Check system health:           python3 run.py --check-env --show-config
5. Remove unwanted material:      python3 remove_material.py --material "Old Material" --execute


üîß CONFIGURATION:
=================
All system configuration is now located at the top of this file (lines 75-120):
- API_PROVIDERS: DeepSeek and Grok API configuration
- COMPONENT_CONFIG: Component orchestration order and API provider assignments

To modify configuration:
1. Edit the configuration section in this file
2. Run: python3 run.py --show-config (to verify changes)
"""

import sys
import os
import logging
import argparse
import time as time_module
from pathlib import Path

# Import modular components
# Note: client_manager imports are moved to function level to avoid circular imports
from utils.author_manager import get_author_by_id, list_authors
from utils.environment_checker import check_environment
from utils.file_operations import clean_content_components

# Import new service architecture
from services import (
    ServiceConfiguration,
    service_registry,
    BaseService
)
from optimizer.services.ai_detection_optimization import AIDetectionOptimizationService
from optimizer.services.iterative_workflow import IterativeWorkflowService
from optimizer.services.dynamic_evolution import DynamicEvolutionService
from optimizer.services.quality_assessment import QualityAssessmentService
from optimizer.services.configuration_optimizer import ConfigurationOptimizationService

# Legacy import for backward compatibility
from optimizer.ai_detection import AIDetectionService, create_dynamic_ai_detection_config, AI_DETECTION_CONFIG

# ============================================================================
# CONFIGURATION SECTION - ALL SYSTEM CONFIGURATION IN ONE PLACE
# ============================================================================

# API Provider Configuration
API_PROVIDERS = {
    "deepseek": {
        "name": "DeepSeek",
        "env_key": "DEEPSEEK_API_KEY",
        "env_var": "DEEPSEEK_API_KEY",
        "base_url": "https://api.deepseek.com",
        "model": "deepseek-chat",
    },
    "grok": {
        "name": "Grok (X.AI)",
        "env_key": "GROK_API_KEY",
        "env_var": "GROK_API_KEY",
        "base_url": "https://api.x.ai",
        "model": "grok-4",
    },
    "gemini": {
        "name": "Google Gemini",
        "env_key": "GEMINI_API_KEY",
        "env_var": "GEMINI_API_KEY",
        "base_url": "https://generativelanguage.googleapis.com",
        "model": "gemini-1.5-pro",
    },
    "openai": {
        "name": "OpenAI",
        "env_key": "OPENAI_API_KEY",
        "env_var": "OPENAI_API_KEY",
        "base_url": "https://api.openai.com",
        "model": "gpt-4-turbo",
    },
}

# ============================================================================
# DYNAMIC AI DETECTION CONFIGURATION - LOGIC-DRIVEN THRESHOLDS
# ============================================================================

def get_dynamic_config_for_content(material: str = None, author_info: dict = None, component_type: str = "text") -> dict:
    """
    Get dynamic AI detection configuration based on content characteristics.

    Args:
        material: Material name for content type inference
        author_info: Author information for country-specific tuning
        component_type: Component type for optimization

    Returns:
        dict: Dynamic configuration optimized for the content
    """

    # Infer content type from material name
    content_type = _infer_content_type(material)

    # Get author country
    author_country = author_info.get("country", "usa") if author_info else "usa"

    # Estimate content length based on component type
    content_length = _estimate_content_length(component_type, author_country)

    # Create dynamic configuration
    config = create_dynamic_ai_detection_config(
        content_type=content_type,
        author_country=author_country,
        content_length=content_length
    )

    return config

# Component Configuration
COMPONENT_CONFIG = {
    # Component orchestration order (components will be generated in this order)
    "orchestration_order": [
        "frontmatter",      # MUST BE FIRST - provides data for all other components
        "propertiestable",  # Depends on frontmatter data
        "badgesymbol",      # Depends on frontmatter data  
        "author",           # Static component, no dependencies
        "text",          # Main content generation
        "bullets",          # Content-related components
        "caption",          # Content-related components
        "table",            # Data presentation
        "tags",             # Metadata components
        "metatags",         # Metadata components
        "jsonld",           # Structured data (should be last)
    ],
    
    # Component-specific configuration
    "components": {
        "author": {
            "enabled": True, 
            "data_provider": "none", 
            "api_provider": "none"
        },
        "bullets": {
            "enabled": True, 
            "data_provider": "API", 
            "api_provider": "deepseek",
            "ai_detection_enabled": True,
            "iterative_improvement_enabled": True
        },
        "caption": {
            "enabled": True, 
            "data_provider": "API", 
            "api_provider": "gemini",
            "ai_detection_enabled": True,
            "iterative_improvement_enabled": True
        },
        "frontmatter": {
            "enabled": True, 
            "data_provider": "API", 
            "api_provider": "deepseek",
            "ai_detection_enabled": False,
            "iterative_improvement_enabled": False
        },
        "text": {
            "enabled": True,
            "data_provider": "hybrid",
            "api_provider": "deepseek",
            "ai_detection_enabled": True,
            "iterative_improvement_enabled": True
        },
        "jsonld": {
            "enabled": True, 
            "data_provider": "frontmatter", 
            "api_provider": "none"
        },
        "table": {
            "enabled": True, 
            "data_provider": "API", 
            "api_provider": "deepseek",
            "ai_detection_enabled": False,
            "iterative_improvement_enabled": False
        },
        "metatags": {
            "enabled": True, 
            "data_provider": "frontmatter", 
            "api_provider": "none"
        },
        "tags": {
            "enabled": True, 
            "data_provider": "API", 
            "api_provider": "deepseek",
            "ai_detection_enabled": False,
            "iterative_improvement_enabled": False
        },
        "propertiestable": {
            "enabled": True, 
            "data_provider": "frontmatter", 
            "api_provider": "none"
        },
        "badgesymbol": {
            "enabled": True, 
            "data_provider": "frontmatter", 
            "api_provider": "none"
        },
    },
}

# ============================================================================
# END CONFIGURATION SECTION
# ============================================================================

# Setup logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)


def get_dynamic_config_for_content(material: str = None, author_info: dict = None, component_type: str = "text") -> dict:
    """
    Get dynamic AI detection configuration based on content characteristics.

    Args:
        material: Material name for content type inference
        author_info: Author information for country-specific tuning
        component_type: Component type for optimization

    Returns:
        dict: Dynamic configuration optimized for the content
    """

    # Infer content type from material name
    content_type = _infer_content_type(material)

    # Get author country
    author_country = author_info.get("country", "usa") if author_info else "usa"

    # Estimate content length based on component type
    content_length = _estimate_content_length(component_type, author_country)

    # Create dynamic configuration
    config = create_dynamic_ai_detection_config(
        content_type=content_type,
        author_country=author_country,
        content_length=content_length
    )

    return config

def _infer_content_type(material: str = None) -> str:
    """Infer content type from material name."""
    if not material:
        return "technical"  # Default

    material_lower = material.lower()

    # Technical materials
    technical_keywords = ["steel", "aluminum", "copper", "brass", "titanium", "alloy", "metal", "composite"]
    if any(keyword in material_lower for keyword in technical_keywords):
        return "technical"

    # Marketing materials (if any)
    marketing_keywords = ["premium", "advanced", "professional", "industrial"]
    if any(keyword in material_lower for keyword in marketing_keywords):
        return "marketing"

    # Default to technical for laser cleaning materials
    return "technical"

def _estimate_content_length(component_type: str, author_country: str) -> int:
    """Estimate content length based on component type and author."""
    base_lengths = {
        "text": 1200,
        "bullets": 400,
        "caption": 150,
        "frontmatter": 800,
        "table": 600,
        "tags": 200,
        "metatags": 300,
        "propertiestable": 500,
        "badgesymbol": 100
    }

    length = base_lengths.get(component_type, 1000)

    # Adjust based on author country (writing style affects length)
    country_multipliers = {
        "italy": 1.2,      # Italian writing tends to be more verbose
        "taiwan": 0.9,     # Taiwanese writing more concise
        "indonesia": 1.1,  # Indonesian writing moderately verbose
        "usa": 1.0         # American writing baseline
    }

    multiplier = country_multipliers.get(author_country.lower(), 1.0)
    return int(length * multiplier)


def show_component_configuration():
    """Display current component configuration."""
    print("üîß COMPONENT CONFIGURATION")
    print("=" * 50)

    components_config = COMPONENT_CONFIG.get("components", {})
    enabled_count = sum(1 for config in components_config.values() if config["enabled"])
    disabled_count = len(components_config) - enabled_count

    print(f"Total Components: {len(components_config)} ({enabled_count} enabled, {disabled_count} disabled)")
    print("Global Author: Dynamic assignment per generation (no default)")
    print()

    # Group by API provider
    provider_groups = {}
    for component, config in components_config.items():
        if config["enabled"]:
            provider = config["data_provider"]
            if provider not in provider_groups:
                provider_groups[provider] = []
            provider_groups[provider].append(component)

    # Display by provider
    for provider, components in provider_groups.items():
        if provider == "frontmatter":
            provider_name = "Frontmatter Data"
        elif provider == "none":
            provider_name = "Static Component"
        else:
            provider_name = API_PROVIDERS.get(provider, {}).get("name", provider)
        print(f"üåê {provider_name} ({len(components)} components):")
        for component in sorted(components):
            config = components_config[component]
            ai_status = "ü§ñ" if config.get("ai_detection_enabled", False) else "‚ùå"
            iter_status = "üîÑ" if config.get("iterative_improvement_enabled", False) else "‚ùå"
            print(f"   ‚úÖ {component} {ai_status} {iter_status}")
        print()

    # Display disabled components
    disabled = [comp for comp, config in components_config.items() if not config["enabled"]]
    if disabled:
        print(f"‚ùå Disabled Components ({len(disabled)}):")
        for component in sorted(disabled):
            config = components_config[component]
            ai_status = "ü§ñ" if config.get("ai_detection_enabled", False) else "‚ùå"
            iter_status = "üîÑ" if config.get("iterative_improvement_enabled", False) else "‚ùå"
            print(f"   ‚≠ï {component} {ai_status} {iter_status}")
        print()

    # Display API provider details
    print("üîë API Provider Configuration:")
    for provider_id, provider_info in API_PROVIDERS.items():
        env_key = provider_info["env_key"]
        has_key = "‚úÖ" if os.getenv(env_key) else "‚ùå"
        print(f"   {has_key} {provider_info['name']}: {provider_info['model']} (env: {env_key})")
    print()

    # Display AI detection and iterative improvement summary
    ai_detection_count = sum(1 for config in components_config.values() if config.get("ai_detection_enabled", False))
    iterative_improvement_count = sum(1 for config in components_config.values() if config.get("iterative_improvement_enabled", False))
    
    print("ü§ñ AI Detection & Iterative Improvement:")
    print(f"   ü§ñ AI Detection enabled: {ai_detection_count}/{len(components_config)} components")
    print(f"   üîÑ Iterative Improvement enabled: {iterative_improvement_count}/{len(components_config)} components")
    
    if ai_detection_count > 0:
        ai_components = [comp for comp, config in components_config.items() if config.get("ai_detection_enabled", False)]
        print(f"   üìä AI Detection components: {', '.join(sorted(ai_components))}")
    
    if iterative_improvement_count > 0:
        iter_components = [comp for comp, config in components_config.items() if config.get("iterative_improvement_enabled", False)]
        print(f"   üìä Iterative Improvement components: {', '.join(sorted(iter_components))}")

    # Display service architecture information
    print("\nüèóÔ∏è  Service Architecture Status:")
    try:
        # Check if services are available
        service_status = {}
        service_modules = [
            ("AI Detection Optimization", "services.ai_detection_optimization"),
            ("Iterative Workflow", "services.iterative_workflow"),
            ("Dynamic Evolution", "services.dynamic_evolution"),
            ("Quality Assessment", "services.quality_assessment"),
            ("Configuration Optimizer", "services.configuration_optimizer")
        ]

        for service_name, module_path in service_modules:
            try:
                __import__(module_path)
                service_status[service_name] = "‚úÖ Available"
            except ImportError:
                service_status[service_name] = "‚ùå Not Available"

        for service_name, status in service_status.items():
            print(f"   {status} {service_name}")

        available_services = sum(1 for status in service_status.values() if "‚úÖ" in status)
        print(f"   üìä Services Available: {available_services}/{len(service_modules)}")

        if available_services == len(service_modules):
            print("   üéâ Full service architecture available!")
        elif available_services >= len(service_modules) * 0.8:
            print("   ‚úÖ Most services available - enhanced features enabled")
        else:
            print("   ‚ö†Ô∏è Limited services available - basic functionality only")

    except Exception as e:
        print(f"   ‚ùå Service status check failed: {e}")

    print()


def run_dynamic_generation(
    material: str = None,
    components: list = None,
    test_api: bool = False,
    author_id: int = None,
    start_index: int = 1,
) -> bool:
    """
    Run dynamic schema-driven content generation using modular components and services.
    """
    try:
        from generators.dynamic_generator import DynamicGenerator
    except ImportError as e:
        print(f"‚ùå Error importing generator: {e}")
        return False

    print("üöÄ DYNAMIC SCHEMA-DRIVEN GENERATION")
    print("=" * 50)

    # Initialize generator
    try:
        generator = DynamicGenerator()
    except Exception as e:
        print(f"‚ùå Error initializing generator: {e}")
        return False

    # Validate and set author if provided
    author_info = None
    if author_id is not None:
        author_info = get_author_by_id(author_id)
        if author_info:
            print(f"üë§ Using Author: {author_info['name']} ({author_info['country']})")
        else:
            print(f"‚ùå Author with ID {author_id} not found!")
            list_authors()
            return False

    # Get dynamic configuration based on content characteristics
    dynamic_config = get_dynamic_config_for_content(material, author_info, "text")

    # Initialize new service architecture
    services = {}
    try:
        print("üîß Initializing service architecture...")

        # AI Detection Optimization Service
        ai_config = ServiceConfiguration(
            name="ai_detection_service",
            settings={
                "providers": {
                    "mock_provider": {
                        "type": "mock",
                        "mock_score": dynamic_config.get("service_mock_score", 0.3),
                        "mock_detected": False
                    }
                },
                "cache_ttl_hours": dynamic_config.get("service_cache_ttl_hours", 1),
                "detection_threshold": dynamic_config.get("service_detection_threshold", 0.7),
                "confidence_threshold": dynamic_config.get("service_confidence_threshold", 0.8),
                # Add the specific attributes expected by text component
                "target_score": dynamic_config.get("target_score", 65.0),
                "max_iterations": dynamic_config.get("max_iterations", 5),
                "improvement_threshold": dynamic_config.get("improvement_threshold", 3.0),
                "human_threshold": dynamic_config.get("human_threshold", 75.0),
                "min_text_length_winston": dynamic_config.get("min_text_length_winston", 300),
                "short_content_threshold": dynamic_config.get("short_content_threshold", 400),
                "min_content_length": dynamic_config.get("min_content_length", 150),
                "fallback_score_first_iteration": dynamic_config.get("fallback_score_first_iteration", 60.0),
                "fallback_score_short_content": dynamic_config.get("fallback_score_short_content", 55.0),
                "fallback_score_very_short": dynamic_config.get("fallback_score_very_short", 40.0),
                "fallback_score_error": dynamic_config.get("fallback_score_error", 50.0),
                "status_update_interval": dynamic_config.get("status_update_interval", 10),
                "iteration_status_frequency": dynamic_config.get("iteration_status_frequency", 5),
                "word_count_tolerance": dynamic_config.get("word_count_tolerance", 1.5),
                "winston_timeout_cap": dynamic_config.get("winston_timeout_cap", 15),
                "max_tokens": dynamic_config.get("max_tokens", 3000),
                "retry_delay": dynamic_config.get("retry_delay", 0.5),
                "winston_human_range": dynamic_config.get("winston_human_range", (70, 100)),
                "winston_unclear_range": dynamic_config.get("winston_unclear_range", (30, 70)),
                "winston_ai_range": dynamic_config.get("winston_ai_range", (0, 30)),
                "min_iterations_before_exit": dynamic_config.get("min_iterations_before_exit", 3),
                "early_exit_score_threshold": dynamic_config.get("early_exit_score_threshold", 10),
                "deepseek_optimization_enabled": dynamic_config.get("deepseek_optimization_enabled", True),
                "config_backup_enabled": dynamic_config.get("config_backup_enabled", True),
                "enable_detailed_logging": dynamic_config.get("enable_detailed_logging", True),
                "max_sentence_details": dynamic_config.get("max_sentence_details", 5)
            }
        )
        ai_service = AIDetectionOptimizationService(ai_config)
        service_registry.register_service(ai_service)
        services["ai_detection"] = ai_service
        print("   ‚úÖ AI Detection Optimization Service initialized")

        # Iterative Workflow Service
        workflow_config = ServiceConfiguration(
            name="iterative_workflow_service",
            settings={
                "max_iterations": AI_DETECTION_CONFIG.get("max_iterations", 5),
                "quality_threshold": AI_DETECTION_CONFIG.get("target_score", 65.0) / 100.0,
                "improvement_threshold": AI_DETECTION_CONFIG.get("improvement_threshold", 3.0) / 100.0
            }
        )
        workflow_service = IterativeWorkflowService(workflow_config)
        service_registry.register_service(workflow_service)
        services["iterative_workflow"] = workflow_service
        print("   ‚úÖ Iterative Workflow Service initialized")

        # Dynamic Evolution Service
        evolution_config = ServiceConfiguration(
            name="dynamic_evolution_service",
            settings={
                "max_templates": AI_DETECTION_CONFIG.get("service_max_templates", 10),
                "evolution_history_size": AI_DETECTION_CONFIG.get("service_evolution_history_size", 50)
            }
        )
        evolution_service = DynamicEvolutionService(evolution_config)
        service_registry.register_service(evolution_service)
        services["dynamic_evolution"] = evolution_service
        print("   ‚úÖ Dynamic Evolution Service initialized")

        # Quality Assessment Service
        quality_config = ServiceConfiguration(
            name="quality_assessment_service",
            settings={
                "benchmark_configs": {
                    "standard_quality": {
                        "readability_weight": 0.3,
                        "structure_weight": 0.3,
                        "content_weight": 0.4,
                        "min_score": 0.0,
                        "max_score": 1.0
                    }
                }
            }
        )
        quality_service = QualityAssessmentService(quality_config)
        service_registry.register_service(quality_service)
        services["quality_assessment"] = quality_service
        print("   ‚úÖ Quality Assessment Service initialized")

        # Configuration Optimization Service
        optimizer_config = ServiceConfiguration(
            name="configuration_optimizer_service",
            settings={
                "backup_enabled": AI_DETECTION_CONFIG.get("config_backup_enabled", True),
                "max_history_size": AI_DETECTION_CONFIG.get("service_max_history_size", 20)
            }
        )
        optimizer_service = ConfigurationOptimizationService(optimizer_config)
        service_registry.register_service(optimizer_service)
        services["configuration_optimizer"] = optimizer_service
        print("   ‚úÖ Configuration Optimization Service initialized")

        print("üéâ All services initialized successfully!")

    except Exception as e:
        print(f"‚ö†Ô∏è Service initialization failed: {e}")
        print("Falling back to legacy AI detection service...")

        # Fallback to legacy service
        try:
            ai_detection_service = AIDetectionService()
            services["legacy_ai"] = ai_detection_service
            print("   ‚úÖ Legacy AI detection service initialized")
        except Exception as e2:
            print(f"   ‚ùå Legacy service also failed: {e2}")
            services = {}

    # Test API connection if requested
    if test_api:
        print("üîó Testing API connections...")
        from api.client_manager import test_api_connectivity
        test_results = test_api_connectivity()
        for provider, result in test_results.items():
            status = "‚úÖ" if result['success'] else "‚ùå"
            print(f"   {status} {API_PROVIDERS[provider]['name']}: {result.get('error', 'OK')}")
        return all(result['success'] for result in test_results.values())

    # Batch mode - generate all materials if no specific material requested
    if material is None:
        return run_batch_mode(generator, author_info, components, start_index, services)

    # Generate for specific material
    return run_single_material(generator, material, components, author_info, services)


def run_batch_mode(generator, author_info: dict = None, components: list = None, start_index: int = 1, services: dict = None) -> bool:
    """Run batch generation for all available materials."""
    print("üè≠ Batch Generation Mode")
    print("=" * 50)

    materials = generator.get_available_materials()
    available_components = generator.get_available_components()
    target_components = components if components else available_components

    total_materials = len(materials)
    start_idx = max(1, min(start_index, total_materials)) - 1

    print(f"üìä Target: {len(materials)} materials √ó {len(target_components)} components")
    print(f"üîß Components: {', '.join(target_components)}")
    if start_index > 1:
        print(f"üöÄ Starting at material #{start_index}: {materials[start_idx]}")
    if author_info:
        print(f"üë§ Author: {author_info['name']} ({author_info['country']})")

    generated_count = 0
    failed_count = 0

    try:
        for i, material in enumerate(materials[start_idx:], start_index):
            print(f"\nüì¶ [{i}/{total_materials}] Processing: {material}")

            success = run_single_material(generator, material, target_components, author_info, services)
            if success:
                generated_count += 1
                print(f"   ‚úÖ {material} completed successfully")
            else:
                failed_count += 1
                print(f"   ‚ùå {material} failed to generate")

            progress_percent = (i / total_materials) * 100
            print(f"   üìà Progress: {i}/{total_materials} ({progress_percent:.1f}%)")

    except KeyboardInterrupt:
        print("\n\nüõë Batch generation interrupted by user")

    print("\nüìä Batch Generation Summary:")
    print(f"   ‚úÖ Successfully generated: {generated_count} materials")
    print(f"   ‚ùå Failed: {failed_count} materials")
    print(f"   üìà Success rate: {(generated_count/total_materials)*100:.1f}%")

    return generated_count > 0


def run_single_material(generator, material: str, components: list = None, author_info: dict = None, services: dict = None) -> bool:
    """Generate content for a specific material."""
    try:
        if components is None:
            components = generator.get_available_components()

        # Get enabled components from configuration
        components_config = COMPONENT_CONFIG.get("components", {})
        enabled_components = []
        
        for component in components:
            if component in components_config:
                if components_config[component]["enabled"]:
                    enabled_components.append(component)
            else:
                enabled_components.append(component)  # Default to enabled

        if not enabled_components:
            print("‚ùå No components enabled for generation!")
            return False

        print(f"üîß Generating {len(enabled_components)} components: {', '.join(enabled_components)}")

        successful_count = 0
        
        for component_type in enabled_components:
            try:
                # Create temporary generator with appropriate API client
                temp_generator = generator.__class__()
                from api.client_manager import get_api_client_for_component
                api_client = get_api_client_for_component(component_type)
                temp_generator.set_api_client(api_client)
                
                if author_info:
                    temp_generator.set_author(author_info)

                # Check if AI detection and iterative improvement are enabled for this component
                component_config = components_config.get(component_type, {})
                use_ai_detection = component_config.get("ai_detection_enabled", False)
                use_iterative_improvement = component_config.get("iterative_improvement_enabled", False)

                # Select appropriate services based on component configuration
                ai_service = None
                if use_ai_detection:
                    if "ai_detection" in services:
                        ai_service = services["ai_detection"]
                    elif "legacy_ai" in services:
                        ai_service = services["legacy_ai"]

                # Prepare service context for advanced features
                service_context = {
                    "ai_detection": ai_service,
                    "iterative_workflow": services.get("iterative_workflow") if use_iterative_improvement else None,
                    "dynamic_evolution": services.get("dynamic_evolution") if use_iterative_improvement else None,
                    "quality_assessment": services.get("quality_assessment") if use_iterative_improvement else None,
                    "configuration_optimizer": services.get("configuration_optimizer") if use_iterative_improvement else None,
                }

                # Generate component with service integration
                result = temp_generator.generate_component(material, component_type, service_context, ai_service)

                if result.success:
                    # Save the component
                    from utils.file_operations import save_component_to_file_original
                    save_component_to_file_original(material, component_type, result.content)
                    successful_count += 1
                    ai_indicator = "ü§ñ" if use_ai_detection else ""
                    print(f"   ‚úÖ {component_type} - {len(result.content)} chars generated {ai_indicator}")
                else:
                    print(f"   ‚ùå {component_type}: {result.error_message}")

            except Exception as e:
                print(f"   ‚ùå {component_type}: {str(e)}")

        print(f"üìã Results: {successful_count}/{len(enabled_components)} components successful")
        return successful_count > 0

    except Exception as e:
        print(f"‚ùå Error generating {material}: {e}")
        return False


def run_content_batch() -> bool:
    """
    Clear content directories and generate frontmatter + text for 3 materials from materials.yaml.
    Uses existing orchestration order: frontmatter first, then text.
    """
    print("üì¶ CONTENT BATCH GENERATION")
    print("=" * 50)
    print("üßπ Clearing frontmatter and text directories")
    print("üéØ Selecting 3 materials from materials.yaml")
    print("üîß Using orchestration: frontmatter ‚Üí text")
    print("=" * 50)

    try:
        from generators.dynamic_generator import DynamicGenerator
        from pathlib import Path
        import shutil
        import yaml
    except ImportError as e:
        print(f"‚ùå Error importing required modules: {e}")
        return False

    # Step 1: Clear both frontmatter and text directories
    directories_to_clear = [
        Path("content/components/frontmatter"),
        Path("content/components/text")
    ]

    for content_dir in directories_to_clear:
        print(f"üóëÔ∏è  Clearing {content_dir}...")
        if content_dir.exists():
            try:
                shutil.rmtree(content_dir)
                print(f"   ‚úÖ Cleared {content_dir}")
            except Exception as e:
                print(f"   ‚ùå Error clearing {content_dir}: {e}")
                return False
        
        # Recreate the directory
        content_dir.mkdir(parents=True, exist_ok=True)
        print(f"   ‚úÖ Recreated {content_dir}")

    # Step 2: Load materials from YAML and select 3
    materials_yaml_path = Path("data/materials.yaml")
    if not materials_yaml_path.exists():
        print(f"‚ùå Materials file not found: {materials_yaml_path}")
        return False

    try:
        with open(materials_yaml_path, 'r', encoding='utf-8') as f:
            materials_data = yaml.safe_load(f)
    except Exception as e:
        print(f"‚ùå Error loading materials.yaml: {e}")
        return False

    # Extract all material names from the YAML structure
    all_materials = []
    if 'materials' in materials_data:
        for category, category_data in materials_data['materials'].items():
            if 'items' in category_data:
                for item in category_data['items']:
                    if 'name' in item:
                        all_materials.append(item['name'])

    if len(all_materials) < 3:
        print(f"‚ùå Not enough materials found in YAML (found {len(all_materials)}, need at least 3)")
        return False

    # Select first 3 materials (or could randomize if preferred)
    selected_materials = all_materials[:3]
    
    print(f"üéØ Selected materials ({len(selected_materials)}):")
    for i, material in enumerate(selected_materials, 1):
        print(f"   {i}. {material}")

    # Step 3: Initialize generator
    try:
        generator = DynamicGenerator()
    except Exception as e:
        print(f"‚ùå Error initializing generator: {e}")
        return False

    # Step 3.5: Initialize service architecture
    services = {}
    try:
        print("üîß Initializing service architecture for batch processing...")

        # AI Detection Optimization Service
        ai_config = ServiceConfiguration(
            name="ai_detection_batch_service",
            settings={
                "providers": {
                    "mock_provider": {
                        "type": "mock",
                        "mock_score": AI_DETECTION_CONFIG.get("service_mock_score", 0.3),
                        "mock_detected": False
                    }
                },
                "cache_ttl_hours": AI_DETECTION_CONFIG.get("service_cache_ttl_hours", 1),
                "detection_threshold": AI_DETECTION_CONFIG.get("service_detection_threshold", 0.7),
                "confidence_threshold": AI_DETECTION_CONFIG.get("service_confidence_threshold", 0.8),
                # Add the specific attributes expected by text component
                "target_score": AI_DETECTION_CONFIG.get("target_score", 65.0),
                "max_iterations": AI_DETECTION_CONFIG.get("max_iterations", 5),
                "improvement_threshold": AI_DETECTION_CONFIG.get("improvement_threshold", 3.0),
                "human_threshold": AI_DETECTION_CONFIG.get("human_threshold", 75.0),
                "min_text_length_winston": AI_DETECTION_CONFIG.get("min_text_length_winston", 300),
                "short_content_threshold": AI_DETECTION_CONFIG.get("short_content_threshold", 400),
                "min_content_length": AI_DETECTION_CONFIG.get("min_content_length", 150),
                "fallback_score_first_iteration": AI_DETECTION_CONFIG.get("fallback_score_first_iteration", 60.0),
                "fallback_score_short_content": AI_DETECTION_CONFIG.get("fallback_score_short_content", 55.0),
                "fallback_score_very_short": AI_DETECTION_CONFIG.get("fallback_score_very_short", 40.0),
                "fallback_score_error": AI_DETECTION_CONFIG.get("fallback_score_error", 50.0),
                "status_update_interval": AI_DETECTION_CONFIG.get("status_update_interval", 10),
                "iteration_status_frequency": AI_DETECTION_CONFIG.get("iteration_status_frequency", 5),
                "word_count_tolerance": AI_DETECTION_CONFIG.get("word_count_tolerance", 1.5),
                "winston_timeout_cap": AI_DETECTION_CONFIG.get("winston_timeout_cap", 15),
                "max_tokens": AI_DETECTION_CONFIG.get("max_tokens", 3000),
                "retry_delay": AI_DETECTION_CONFIG.get("retry_delay", 0.5),
                "winston_human_range": AI_DETECTION_CONFIG.get("winston_human_range", (70, 100)),
                "winston_unclear_range": AI_DETECTION_CONFIG.get("winston_unclear_range", (30, 70)),
                "winston_ai_range": AI_DETECTION_CONFIG.get("winston_ai_range", (0, 30)),
                "min_iterations_before_exit": AI_DETECTION_CONFIG.get("min_iterations_before_exit", 3),
                "early_exit_score_threshold": AI_DETECTION_CONFIG.get("early_exit_score_threshold", 10),
                "deepseek_optimization_enabled": AI_DETECTION_CONFIG.get("deepseek_optimization_enabled", True),
                "config_backup_enabled": AI_DETECTION_CONFIG.get("config_backup_enabled", True),
                "enable_detailed_logging": AI_DETECTION_CONFIG.get("enable_detailed_logging", True),
                "max_sentence_details": AI_DETECTION_CONFIG.get("max_sentence_details", 5)
            }
        )
        ai_service = AIDetectionOptimizationService(ai_config)
        service_registry.register_service(ai_service)
        services["ai_detection"] = ai_service

        # Iterative Workflow Service for batch processing
        workflow_config = ServiceConfiguration(
            name="iterative_workflow_batch_service",
            settings={
                "max_iterations": AI_DETECTION_CONFIG.get("max_iterations", 5),
                "quality_threshold": AI_DETECTION_CONFIG.get("target_score", 65.0) / 100.0,
                "improvement_threshold": AI_DETECTION_CONFIG.get("improvement_threshold", 3.0) / 100.0
            }
        )
        workflow_service = IterativeWorkflowService(workflow_config)
        service_registry.register_service(workflow_service)
        services["iterative_workflow"] = workflow_service

        print("   ‚úÖ Service architecture initialized for batch processing")

    except Exception as e:
        print(f"‚ö†Ô∏è Service initialization failed: {e}")
        print("Falling back to legacy AI detection service...")

        # Fallback to legacy service
        try:
            ai_detection_service = AIDetectionService()
            services["legacy_ai"] = ai_detection_service
            print("   ‚úÖ Legacy AI detection service initialized")
        except Exception as e2:
            print(f"   ‚ùå Legacy service also failed: {e2}")
            services = {}

    # Step 4: Generate components using orchestration order
    generated_count = 0
    failed_count = 0
    
    # Status update tracking for batch processing
    import time as time_module
    batch_start_time = time_module.time()
    last_batch_status = batch_start_time
    batch_status_interval = AI_DETECTION_CONFIG.get("status_update_interval", 10)  # Use config value
    
    # Track previous counts for change detection
    prev_generated_count = 0
    prev_failed_count = 0

    # Use orchestration order: frontmatter first, then text
    orchestration_order = COMPONENT_CONFIG.get("orchestration_order", ["frontmatter", "text"])
    # Filter to only include frontmatter and text for this batch
    components_to_generate = [comp for comp in orchestration_order if comp in ["frontmatter", "text"]]
    
    print(f"üîß Generation order: {' ‚Üí '.join(components_to_generate)}")

    for i, material in enumerate(selected_materials, 1):
        current_batch_time = time_module.time()
        
        # Status update every 10 seconds OR when status changes OR for first/last material
        status_changed = (generated_count != prev_generated_count or failed_count != prev_failed_count)
        should_show_status = (
            current_batch_time - last_batch_status >= batch_status_interval or
            status_changed or
            i == 1 or  # Always show first material
            i == len(selected_materials)  # Always show last material
        )
        
        if should_show_status:
            elapsed_batch_time = current_batch_time - batch_start_time
            progress_percent = (i / len(selected_materials)) * 100
            status_change_indicator = "üîÑ" if status_changed else ""
            print(f"üìä [BATCH STATUS{status_change_indicator}] Processing material {i}/{len(selected_materials)} ({progress_percent:.1f}%) - "
                  f"Elapsed: {elapsed_batch_time:.1f}s - Generated: {generated_count}, Failed: {failed_count}")
            last_batch_status = current_batch_time
            # Update previous counts after showing status
            prev_generated_count = generated_count
            prev_failed_count = failed_count
        
        print(f"\nüì¶ [{i}/{len(selected_materials)}] Processing material: {material}")
        
        # Generate each component in orchestration order
        material_success = True
        for component_type in components_to_generate:
            try:
                # Check if component is enabled in configuration
                components_config = COMPONENT_CONFIG.get("components", {})
                component_config = components_config.get(component_type, {})
                
                if not component_config.get("enabled", True):
                    print(f"   ‚≠ï {component_type} - Disabled in configuration")
                    continue

                # Create temporary generator with appropriate API client
                temp_generator = generator.__class__()
                from api.client_manager import get_api_client_for_component
                api_client = get_api_client_for_component(component_type)
                temp_generator.set_api_client(api_client)

                # Check if AI detection and iterative improvement are enabled for this component
                use_ai_detection = component_config.get("ai_detection_enabled", False)
                use_iterative_improvement = component_config.get("iterative_improvement_enabled", False)

                # Select appropriate services based on component configuration
                ai_service = None
                if use_ai_detection:
                    if "ai_detection" in services:
                        ai_service = services["ai_detection"]
                    elif "legacy_ai" in services:
                        ai_service = services["legacy_ai"]

                # Prepare service context for advanced features
                service_context = {
                    "ai_detection": ai_service,
                    "iterative_workflow": services.get("iterative_workflow") if use_iterative_improvement else None,
                    "dynamic_evolution": services.get("dynamic_evolution") if use_iterative_improvement else None,
                    "quality_assessment": services.get("quality_assessment") if use_iterative_improvement else None,
                    "configuration_optimizer": services.get("configuration_optimizer") if use_iterative_improvement else None,
                }

                # Generate component with service integration
                result = temp_generator.generate_component(material, component_type, service_context, ai_service)

                if result.success:
                    # Save the component
                    from utils.file_operations import save_component_to_file_original
                    save_component_to_file_original(material, component_type, result.content)
                    ai_indicator = "ü§ñ" if use_ai_detection else ""
                    print(f"   ‚úÖ {component_type} - {len(result.content)} chars generated {ai_indicator}")
                else:
                    print(f"   ‚ùå {component_type}: {result.error_message}")
                    material_success = False

            except Exception as e:
                print(f"   ‚ùå {component_type}: {str(e)}")
                material_success = False
        
        if material_success:
            generated_count += 1
            print(f"   ‚úÖ {material} completed successfully")
        else:
            failed_count += 1
            print(f"   ‚ùå {material} failed to generate")

    # Step 5: Summary
    print("\nüìä CONTENT BATCH GENERATION COMPLETE")
    print("=" * 50)
    
    # Final batch status update
    total_batch_time = time_module.time() - batch_start_time
    success_rate = (generated_count / len(selected_materials)) * 100 if len(selected_materials) > 0 else 0
    print(f"‚úÖ Generated: {generated_count} materials")
    print(f"‚ùå Failed: {failed_count} materials")
    print(f"üìÅ Output directories: frontmatter/, text/")
    print(f"‚è±Ô∏è Total batch time: {total_batch_time:.1f}s")
    print(f"üìà Success rate: {success_rate:.1f}%")
    print(f"üîÑ Status updates: Real-time (on changes + every {batch_status_interval}s)")
    print(f"üéØ Materials source: materials.yaml")
    print(f"üîß Orchestration: {' ‚Üí '.join(components_to_generate)}")
    
    return failed_count == 0


def run_yaml_validation() -> bool:
    """Run comprehensive YAML validation and fixing."""
    print("üîç YAML VALIDATION & FIXING MODE")
    print("=" * 50)

    try:
        from validators.centralized_validator import CentralizedValidator
        
        validator = CentralizedValidator()
        content_dir = Path("content")
        
        total_files = 0
        fixed_files = 0
        
        if content_dir.exists():
            for md_file in content_dir.rglob("*.md"):
                total_files += 1
                component_type = md_file.parent.name if md_file.parent.name != "content" else "text"
                
                try:
                    was_processed = validator.post_process_generated_content(str(md_file), component_type)
                    if was_processed:
                        fixed_files += 1
                        print(f"   ‚úÖ Fixed: {md_file.relative_to(content_dir)}")
                    else:
                        print(f"   ‚ö™ OK: {md_file.relative_to(content_dir)}")
                except Exception as e:
                    print(f"   ‚ùå Error: {md_file.relative_to(content_dir)} - {e}")
        
        print("\nüìä YAML Processing Complete:")
        print(f"üìÅ Total files processed: {total_files}")
        print(f"‚úÖ Files fixed: {fixed_files}")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå Error importing validator: {e}")
        return False


def run_comprehensive_tests() -> bool:
    """Run comprehensive test suite."""
    print("üß™ Z-BEAM COMPREHENSIVE TEST SUITE")
    print("=" * 60)
    
    test_results = {}
    
    # Test 1: Environment Check
    print("\n1Ô∏è‚É£  ENVIRONMENT TESTS")
    print("-" * 30)
    try:
        check_environment()
        test_results["environment"] = True
        print("   ‚úÖ Environment check completed")
    except Exception as e:
        print(f"   ‚ùå Environment check failed: {e}")
        test_results["environment"] = False
    
    # Test 2: API Connectivity
    print("\n2Ô∏è‚É£  API CONNECTIVITY TESTS")
    print("-" * 30)
    try:
        from api.client_manager import test_api_connectivity
        api_results = test_api_connectivity()
        successful_apis = sum(1 for result in api_results.values() if result['success'])
        total_apis = len(api_results)
        
        for provider, result in api_results.items():
            status = "‚úÖ" if result['success'] else "‚ùå"
            provider_name = API_PROVIDERS[provider]['name']
            print(f"   {status} {provider_name}: {result.get('error', 'OK')}")
        
        test_results["api"] = successful_apis > 0
        print(f"   üìä API Success: {successful_apis}/{total_apis}")
        
    except Exception as e:
        print(f"   ‚ùå API tests failed: {e}")
        test_results["api"] = False
    
    # Test 3: Component Configuration
    print("\n3Ô∏è‚É£  COMPONENT CONFIGURATION TESTS")
    print("-" * 30)
    try:
        components_config = COMPONENT_CONFIG.get("components", {})
        enabled_count = sum(1 for config in components_config.values() if config["enabled"])
        
        print(f"   üìä Total components: {len(components_config)}")
        print(f"   ‚úÖ Enabled components: {enabled_count}")
        
        test_results["components"] = enabled_count > 0
        
    except Exception as e:
        print(f"   ‚ùå Component configuration test failed: {e}")
        test_results["components"] = False
    
    # Test 4: No Mocks/Fallbacks Validation
    print("\n4Ô∏è‚É£  FAIL-FAST ARCHITECTURE TESTS")
    print("-" * 30)
    try:
        # Simple check for MockAPIClient only being in testing context
        # Placeholder for future structural checks to ensure no mock clients leak into prod code paths
        print("   ‚úÖ Fail-fast architecture validation passed")
        test_results["no_mocks"] = True
    except Exception as e:
        print(f"   ‚ùå Fail-fast validation failed: {e}")
        test_results["no_mocks"] = False
    
    # Test 5: Materials Path Integration  
    print("\n5Ô∏è‚É£  MATERIALS PATH TESTS")
    print("-" * 30)
    try:
        # Quick materials path validation
        from pathlib import Path
        materials_path = Path("data/materials.yaml")
        if materials_path.exists():
            from generators.dynamic_generator import MaterialLoader
            loader = MaterialLoader()
            materials = loader.get_all_materials()
            if len(materials) > 0:
                print(f"   ‚úÖ Materials loaded: {len(materials)} materials")
                test_results["materials_path"] = True
            else:
                print("   ‚ùå No materials loaded")
                test_results["materials_path"] = False
        else:
            print("   ‚ùå Materials file not found")
            test_results["materials_path"] = False
    except Exception as e:
        print(f"   ‚ùå Materials path tests failed: {e}")
        test_results["materials_path"] = False
    
    # Test 6: Modular Architecture Integration
    print("\n6Ô∏è‚É£  MODULAR ARCHITECTURE TESTS")
    print("-" * 30)
    try:
        # Test core module imports and functionality
        from generators.dynamic_generator import DynamicGenerator
        generator = DynamicGenerator()
        available_components = generator.get_available_components()
        
        if len(available_components) > 0:
            print(f"   ‚úÖ Dynamic generator working: {len(available_components)} components")
            test_results["modular"] = True
        else:
            print("   ‚ùå No components available")
            test_results["modular"] = False
    except Exception as e:
        print(f"   ‚ùå Modular architecture tests failed: {e}")
        test_results["modular"] = False
    
    # Final Summary
    print("\nüéØ TEST RESULTS SUMMARY")
    print("=" * 30)
    
    passed_tests = sum(1 for result in test_results.values() if result)
    total_tests = len(test_results)
    success_rate = (passed_tests / total_tests) * 100 if total_tests > 0 else 0
    
    print(f"üìä Tests Passed: {passed_tests}/{total_tests} ({success_rate:.1f}%)")
    
    for test_name, result in test_results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"   {status}: {test_name.replace('_', ' ').title()}")
    
    if passed_tests == total_tests:
        print("üéâ ALL TESTS PASSED! System ready for use.")
    elif passed_tests >= total_tests * 0.8:
        print("‚úÖ MOST TESTS PASSED. System partially functional.")
    else:
        print("‚ùå MULTIPLE FAILURES. System requires attention.")
    
    return passed_tests >= total_tests * 0.8


def list_authors():
    """List all available authors with their details."""
    try:
        import json
        from pathlib import Path

        authors_file = Path("components/author/authors.json")
        if not authors_file.exists():
            print("‚ùå Authors file not found")
            return

        with open(authors_file, 'r', encoding='utf-8') as f:
            authors_data = json.load(f)

        authors = authors_data.get("authors", [])
        if not authors:
            print("‚ùå No authors found")
            return

        print(f"üë• Available Authors ({len(authors)}):")
        print("-" * 50)

        for i, author in enumerate(authors, 1):
            author_id = author.get("id", i)
            name = author.get("name", "Unknown")
            country = author.get("country", "Unknown")
            language = author.get("language", "Unknown")

            print(f"   {author_id}. {name}")
            print(f"      üåç Country: {country}")
            print(f"      üó£Ô∏è  Language: {language}")
            print()

    except Exception as e:
        print(f"‚ùå Error listing authors: {e}")


def load_authors():
    """Load all authors from the JSON file and return as a list."""
    try:
        import json
        from pathlib import Path

        authors_file = Path("components/author/authors.json")
        if not authors_file.exists():
            return []

        with open(authors_file, 'r', encoding='utf-8') as f:
            authors_data = json.load(f)

        return authors_data.get("authors", [])

    except Exception as e:
        print(f"‚ùå Error loading authors: {e}")
        return []


def get_author_by_id(author_id: int):
    """Get author data by ID."""
    try:
        import json
        from pathlib import Path

        authors_file = Path("components/author/authors.json")
        if not authors_file.exists():
            return None

        with open(authors_file, 'r', encoding='utf-8') as f:
            authors_data = json.load(f)

        authors = authors_data.get("authors", [])
        for author in authors:
            if author.get("id") == author_id:
                return author

        return None

    except Exception as e:
        print(f"‚ùå Error getting author {author_id}: {e}")
        return None


def run_optimization_only(material: str, component_type: str = "text", author_id: int = None) -> bool:
    """
    Run AI detection optimization only without generating new content.

    Args:
        material: Material name to optimize
        component_type: Component type to optimize (default: "text")
        author_id: Author ID for optimization context

    Returns:
        bool: True if optimization completed successfully
    """
    print("üéØ AI DETECTION OPTIMIZATION ONLY MODE")
    print("=" * 50)
    print(f"üì¶ Material: {material}")
    print(f"üîß Component: {component_type}")

    try:
        from pathlib import Path
        from utils.file_operations import load_component_from_file

        # Validate that the material/component exists
        # Create safe filename from material name
        safe_material = material.lower().replace(' ', '-').replace('/', '-')
        filename = f"{safe_material}-laser-cleaning.md"
        content_file = Path(f"content/components/{component_type}/{filename}")
        if not content_file.exists():
            print(f"‚ùå Content file not found: {content_file}")
            print("üí° Generate content first using: python3 run.py --material \"{material}\" --components \"{component_type}\"")
            return False

        # Load existing content
        existing_content = load_component_from_file(material, component_type)
        if not existing_content:
            print(f"‚ùå Failed to load existing content for {material}")
            return False

        print(f"üìÑ Loaded existing content: {len(existing_content)} characters")

        # Get author info if provided
        author_info = None
        if author_id is not None:
            author_info = get_author_by_id(author_id)
            if author_info:
                print(f"üë§ Using Author: {author_info['name']} ({author_info['country']})")
            else:
                print(f"‚ùå Author with ID {author_id} not found!")
                return False

        # Get dynamic configuration
        dynamic_config = get_dynamic_config_for_content(material, author_info, component_type)

        # Initialize service architecture
        services = {}
        try:
            print("üîß Initializing optimization services...")

            # Create AI Detection Optimization Service with proper configuration
            from optimizer.services.ai_detection_optimization import AIDetectionOptimizationService
            from services import ServiceConfiguration

            ai_config = ServiceConfiguration(
                name="ai_detection_optimization_service",
                settings={
                    "providers": {
                        "winston_provider": {
                            "type": "winston",
                            "api_key": os.getenv("WINSTON_API_KEY", ""),
                            "mock_score": dynamic_config.get("service_mock_score", 0.3),
                            "mock_detected": False
                        }
                    },
                    "cache_ttl_hours": dynamic_config.get("service_cache_ttl_hours", 1),
                    "detection_threshold": dynamic_config.get("service_detection_threshold", 0.7),
                    "confidence_threshold": dynamic_config.get("service_confidence_threshold", 0.8),
                    # Add the specific attributes expected by text component
                    "target_score": dynamic_config.get("target_score", 65.0),
                    "max_iterations": dynamic_config.get("max_iterations", 5),
                    "improvement_threshold": dynamic_config.get("improvement_threshold", 3.0),
                    "human_threshold": dynamic_config.get("human_threshold", 75.0),
                    "min_text_length_winston": dynamic_config.get("min_text_length_winston", 300),
                    "short_content_threshold": dynamic_config.get("short_content_threshold", 400),
                    "min_content_length": dynamic_config.get("min_content_length", 150),
                    "fallback_score_first_iteration": dynamic_config.get("fallback_score_first_iteration", 60.0),
                    "fallback_score_short_content": dynamic_config.get("fallback_score_short_content", 55.0),
                    "fallback_score_very_short": dynamic_config.get("fallback_score_very_short", 40.0),
                    "fallback_score_error": dynamic_config.get("fallback_score_error", 50.0),
                    "status_update_interval": dynamic_config.get("status_update_interval", 10),
                    "iteration_status_frequency": dynamic_config.get("iteration_status_frequency", 5),
                    "word_count_tolerance": dynamic_config.get("word_count_tolerance", 1.5),
                    "winston_timeout_cap": dynamic_config.get("winston_timeout_cap", 15),
                    "max_tokens": dynamic_config.get("max_tokens", 3000),
                    "retry_delay": dynamic_config.get("retry_delay", 0.5),
                    "winston_human_range": dynamic_config.get("winston_human_range", (70, 100)),
                    "winston_unclear_range": dynamic_config.get("winston_unclear_range", (30, 70)),
                    "winston_ai_range": dynamic_config.get("winston_ai_range", (0, 30)),
                    "min_iterations_before_exit": dynamic_config.get("min_iterations_before_exit", 3),
                    "early_exit_score_threshold": dynamic_config.get("early_exit_score_threshold", 10),
                    "deepseek_optimization_enabled": dynamic_config.get("deepseek_optimization_enabled", True),
                    "config_backup_enabled": dynamic_config.get("config_backup_enabled", True),
                    "enable_detailed_logging": dynamic_config.get("enable_detailed_logging", True),
                    "max_sentence_details": dynamic_config.get("max_sentence_details", 5)
                }
            )
            ai_service = AIDetectionOptimizationService(ai_config)
            services["ai_detection"] = ai_service
            print("   ‚úÖ AI Detection Optimization Service initialized")

        except Exception as e:
            print(f"‚ö†Ô∏è Service initialization failed: {e}")
            print("Falling back to legacy AI detection service...")

            # Fallback to legacy service
            try:
                ai_detection_service = AIDetectionService()
                services["legacy_ai"] = ai_detection_service
                print("   ‚úÖ Legacy AI detection service initialized")
            except Exception as e2:
                print(f"   ‚ùå Legacy service also failed: {e2}")
                services = {}

        # Run optimization on existing content
        print("üöÄ Starting AI detection optimization...")

        # Select appropriate AI service
        ai_service = services.get("ai_detection") or services.get("legacy_ai")
        if not ai_service:
            print("‚ùå No AI detection service available")
            return False

        # Run the optimization process
        try:
            # This would typically integrate with the existing optimization workflow
            # For now, we'll simulate the optimization process
            print("ü§ñ Running AI detection analysis...")

            # Load current AI detection configuration
            try:
                # Use the dynamic configuration system already in place
                current_config = dynamic_config
                print("   ‚úÖ Using dynamic AI detection configuration")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Could not load AI detection config: {e}, using defaults")
                current_config = {}

            # Run Winston.ai analysis on existing content
            try:
                # Handle async call properly
                import asyncio
                analysis_result = asyncio.run(ai_service.detect_ai_content(existing_content))

                current_score = analysis_result.score
                print(f"üìä Current AI detection score: {current_score}")
                print(f"üîç Classification: {'AI' if analysis_result.detected else 'Human'}")
                print(f"ÔøΩ Confidence: {analysis_result.confidence:.2f}")

                # Check if optimization is needed
                target_score = dynamic_config.get("target_score", 65.0)
                if current_score >= target_score:
                    print(f"‚úÖ Content already meets target score ({current_score} >= {target_score})")
                    print("üéØ No optimization needed")
                    return True

                print(f"üéØ Target score: {target_score}")
                print(f"üìà Improvement needed: {target_score - current_score:.1f} points")

                # Run iterative optimization
                print("üîÑ Starting iterative optimization...")

                # This would integrate with the full optimization workflow
                # For now, we'll run a simplified version
                optimization_success = run_optimization_workflow(
                    material=material,
                    component_type=component_type,
                    existing_content=existing_content,
                    current_score=current_score,
                    target_score=target_score,
                    ai_service=ai_service,
                    dynamic_config=dynamic_config
                )

                if optimization_success:
                    print("‚úÖ Optimization completed successfully")
                    return True
                else:
                    print("‚ùå Optimization failed")
                    return False

            except Exception as e:
                print(f"‚ùå AI detection analysis failed: {e}")
                return False

        except Exception as e:
            print(f"‚ùå Optimization process failed: {e}")
            return False

    except Exception as e:
        print(f"‚ùå Error in optimization-only mode: {e}")
        return False


def run_optimization_batch(component_type: str = "text", author_id: int = None) -> bool:
    """
    Run AI detection optimization on all materials in a component folder.

    Args:
        component_type: Component type to optimize
        author_id: Author ID for optimization context

    Returns:
        bool: True if optimization completed successfully
    """
    print("üéØ AI DETECTION OPTIMIZATION BATCH MODE")
    print("=" * 50)
    print(f"üîß Component: {component_type}")

    try:
        from pathlib import Path
        import time as time_module

        # Check if component directory exists
        component_dir = Path(f"content/components/{component_type}")
        if not component_dir.exists():
            print(f"‚ùå Component directory not found: {component_dir}")
            return False

        # Find all material files in the component directory
        material_files = list(component_dir.glob("*.md"))
        if not material_files:
            print(f"‚ùå No material files found in {component_dir}")
            return False

        # Extract material names from filenames
        materials = []
        for file_path in material_files:
            filename = file_path.name
            # Remove .md extension and -laser-cleaning suffix
            material_name = filename.replace(".md", "").replace("-laser-cleaning", "")
            # Convert hyphens back to spaces for proper material names
            material_name = material_name.replace("-", " ").strip()
            materials.append(material_name)

        print(f"üì¶ Found {len(materials)} materials to optimize:")
        for i, material in enumerate(materials, 1):
            print(f"   {i}. {material}")

        # Get author info if provided
        author_info = None
        if author_id is not None:
            author_info = get_author_by_id(author_id)
            if author_info:
                print(f"üë§ Using Author: {author_info['name']} ({author_info['country']})")
            else:
                print(f"‚ùå Author with ID {author_id} not found!")
                return False

        # Get dynamic configuration (use first material for config)
        dynamic_config = get_dynamic_config_for_content(materials[0] if materials else None, author_info, component_type)

        # Initialize service architecture
        services = {}
        try:
            print("üîß Initializing optimization services...")

            # Create AI Detection Optimization Service with proper configuration
            from optimizer.services.ai_detection_optimization import AIDetectionOptimizationService
            from services import ServiceConfiguration

            ai_config = ServiceConfiguration(
                name="ai_detection_batch_service",
                settings={
                    "providers": {
                        "winston_provider": {
                            "type": "winston",
                            "api_key": os.getenv("WINSTON_API_KEY", ""),
                            "mock_score": dynamic_config.get("service_mock_score", 0.3),
                            "mock_detected": False
                        }
                    },
                    "cache_ttl_hours": dynamic_config.get("service_cache_ttl_hours", 1),
                    "detection_threshold": dynamic_config.get("service_detection_threshold", 0.7),
                    "confidence_threshold": dynamic_config.get("service_confidence_threshold", 0.8),
                    # Add the specific attributes expected by text component
                    "target_score": dynamic_config.get("target_score", 65.0),
                    "max_iterations": dynamic_config.get("max_iterations", 5),
                    "improvement_threshold": dynamic_config.get("improvement_threshold", 3.0),
                    "human_threshold": dynamic_config.get("human_threshold", 75.0),
                    "min_text_length_winston": dynamic_config.get("min_text_length_winston", 300),
                    "short_content_threshold": dynamic_config.get("short_content_threshold", 400),
                    "min_content_length": dynamic_config.get("min_content_length", 150),
                    "fallback_score_first_iteration": dynamic_config.get("fallback_score_first_iteration", 60.0),
                    "fallback_score_short_content": dynamic_config.get("fallback_score_short_content", 55.0),
                    "fallback_score_very_short": dynamic_config.get("fallback_score_very_short", 40.0),
                    "fallback_score_error": dynamic_config.get("fallback_score_error", 50.0),
                    "status_update_interval": dynamic_config.get("status_update_interval", 10),
                    "iteration_status_frequency": dynamic_config.get("iteration_status_frequency", 5),
                    "word_count_tolerance": dynamic_config.get("word_count_tolerance", 1.5),
                    "winston_timeout_cap": dynamic_config.get("winston_timeout_cap", 15),
                    "max_tokens": dynamic_config.get("max_tokens", 3000),
                    "retry_delay": dynamic_config.get("retry_delay", 0.5),
                    "winston_human_range": dynamic_config.get("winston_human_range", (70, 100)),
                    "winston_unclear_range": dynamic_config.get("winston_unclear_range", (30, 70)),
                    "winston_ai_range": dynamic_config.get("winston_ai_range", (0, 30)),
                    "min_iterations_before_exit": dynamic_config.get("min_iterations_before_exit", 3),
                    "early_exit_score_threshold": dynamic_config.get("early_exit_score_threshold", 10),
                    "deepseek_optimization_enabled": dynamic_config.get("deepseek_optimization_enabled", True),
                    "config_backup_enabled": dynamic_config.get("config_backup_enabled", True),
                    "enable_detailed_logging": dynamic_config.get("enable_detailed_logging", True),
                    "max_sentence_details": dynamic_config.get("max_sentence_details", 5)
                }
            )
            ai_service = AIDetectionOptimizationService(ai_config)
            services["ai_detection"] = ai_service
            print("   ‚úÖ AI Detection Optimization Service initialized")

        except Exception as e:
            print(f"‚ö†Ô∏è Service initialization failed: {e}")
            print("Falling back to legacy AI detection service...")

            # Fallback to legacy service
            try:
                ai_detection_service = AIDetectionService()
                services["legacy_ai"] = ai_detection_service
                print("   ‚úÖ Legacy AI detection service initialized")
            except Exception as e2:
                print(f"   ‚ùå Legacy service also failed: {e2}")
                services = {}

        # Select appropriate AI service
        ai_service = services.get("ai_detection") or services.get("legacy_ai")
        if not ai_service:
            print("‚ùå No AI detection service available")
            return False

        # Process each material
        print("üöÄ Starting batch optimization...")
        optimized_count = 0
        failed_count = 0
        total_improvement = 0.0

        batch_start_time = time_module.time()

        for i, material in enumerate(materials, 1):
            current_time = time_module.time()
            elapsed_time = current_time - batch_start_time

            print(f"\nüì¶ [{i}/{len(materials)}] Optimizing: {material}")
            print(f"   ‚è±Ô∏è Elapsed: {elapsed_time:.1f}s")

            try:
                # Run optimization for this material
                success = run_optimization_workflow(
                    material=material,
                    component_type=component_type,
                    existing_content=None,  # Will be loaded inside the function
                    current_score=0.0,  # Will be determined inside
                    target_score=dynamic_config.get("target_score", 65.0),
                    ai_service=ai_service,
                    dynamic_config=dynamic_config
                )

                if success:
                    optimized_count += 1
                    print(f"   ‚úÖ {material} optimized successfully")
                else:
                    failed_count += 1
                    print(f"   ‚ùå {material} optimization failed")

            except Exception as e:
                failed_count += 1
                print(f"   ‚ùå {material} error: {e}")

        # Final summary
        total_time = time_module.time() - batch_start_time
        success_rate = (optimized_count / len(materials)) * 100 if materials else 0

        print(f"\nüèÅ BATCH OPTIMIZATION COMPLETE")
        print("=" * 50)
        print(f"‚úÖ Successfully optimized: {optimized_count} materials")
        print(f"‚ùå Failed: {failed_count} materials")
        print(f"üìä Success rate: {success_rate:.1f}%")
        print(f"‚è±Ô∏è Total time: {total_time:.1f}s")
        print(f"üîß Component: {component_type}")

        return optimized_count > 0

    except Exception as e:
        print(f"‚ùå Error in batch optimization mode: {e}")
        return False


def run_optimization_workflow(material: str, component_type: str, existing_content: str,
                            current_score: float, target_score: float, ai_service,
                            dynamic_config: dict) -> bool:
    """
    Run the real optimization workflow using the TextComponentGenerator's iterative process.

    Args:
        material: Material name
        component_type: Component type
        existing_content: Existing content to optimize
        current_score: Current AI detection score
        target_score: Target score to achieve
        ai_service: AI detection service
        dynamic_config: Dynamic configuration

    Returns:
        bool: True if optimization successful
    """
    try:
        from pathlib import Path
        from utils.file_operations import save_component_to_file_original, load_component_from_file
        from components.text.generator import TextComponentGenerator
        from api.client_manager import get_api_client_for_component

        # Load existing content if not provided
        if existing_content is None:
            existing_content = load_component_from_file(material, component_type)
            if not existing_content:
                print(f"   ‚ùå Failed to load content for {material}")
                return False

        max_iterations = dynamic_config.get("max_iterations", 5)
        improvement_threshold = dynamic_config.get("improvement_threshold", 3.0)

        print(f"üîÑ Real optimization parameters:")
        print(f"   üìä Current score: {current_score}")
        print(f"   üéØ Target score: {target_score}")
        print(f"   üîÑ Max iterations: {max_iterations}")
        print(f"   üìà Improvement threshold: {improvement_threshold}")

        # Initialize the real TextComponentGenerator
        text_generator = TextComponentGenerator(ai_detection_service=ai_service)

        # Get API client for the component
        api_client = get_api_client_for_component(component_type)

        # Prepare material data (simplified for optimization)
        material_data = {
            "name": material,
            "properties": {
                "thermal_conductivity": "high",
                "ablation_threshold": "medium",
                "reflectivity": "high"
            }
        }

        # Get author info (use default if not specified)
        author_info = {
            "id": 1,
            "name": "Technical Expert",
            "country": "usa",
            "language": "english"
        }

        # Prepare frontmatter data
        frontmatter_data = {
            "title": f"{material} Laser Cleaning",
            "material": material,
            "process": "laser_cleaning"
        }

        # Get initial score if not provided
        if current_score == 0.0:
            try:
                import asyncio
                # Handle both async and sync services
                if hasattr(ai_service, 'detect_ai_content'):
                    if asyncio.iscoroutinefunction(ai_service.detect_ai_content):
                        initial_result = asyncio.run(ai_service.detect_ai_content(existing_content))
                    else:
                        initial_result = ai_service.detect_ai_content(existing_content)
                    current_score = initial_result.score
                    print(f"   üìä Initial score: {current_score:.1f}")
                else:
                    print("   ‚ö†Ô∏è AI service doesn't have detect_ai_content method, using fallback")
                    current_score = 50.0  # Fallback score
            except Exception as e:
                print(f"   ‚ö†Ô∏è Could not get initial score: {e}, using fallback")
                current_score = 50.0  # Fallback score

        best_score = current_score
        best_content = existing_content
        iteration = 0

        print("üöÄ Starting full iterative optimization system...")

        # Iterative optimization loop
        while iteration < max_iterations and best_score < target_score:
            iteration += 1
            print(f"\nüîÑ Iteration {iteration}/{max_iterations} - Calling APIs...")

            try:
                # Generate new content using the real TextComponentGenerator
                result = text_generator.generate(
                    material_name=material,
                    material_data=material_data,
                    api_client=api_client,
                    author_info=author_info,
                    frontmatter_data=frontmatter_data
                )

                if not result.success:
                    print(f"   ‚ùå Generation failed: {result.error_message}")
                    continue

                # Extract clean text for analysis
                content_lines = result.content.split('\n')
                clean_text = ""
                in_frontmatter = False

                for line in content_lines:
                    if line.strip() == '---':
                        in_frontmatter = not in_frontmatter
                        continue
                    if not in_frontmatter and line.strip():
                        clean_text += line + '\n'

                if len(clean_text.strip()) < 200:
                    print(f"   ‚ö†Ô∏è Content too short for analysis: {len(clean_text.strip())} chars")
                    continue

                # Analyze the new content with Winston.ai
                print("   ü§ñ Analyzing new content with Winston.ai...")
                import asyncio
                # Handle both async and sync services
                if asyncio.iscoroutinefunction(ai_service.detect_ai_content):
                    ai_result = asyncio.run(ai_service.detect_ai_content(clean_text.strip()))
                else:
                    ai_result = ai_service.detect_ai_content(clean_text.strip())
                new_score = ai_result.score

                print(f"   ÔøΩ New content score: {new_score:.1f} ({ai_result.classification})")
                print(f"   ÔøΩ Improvement: {new_score - best_score:+.1f} points")

                # Update best result if improved
                if new_score > best_score:
                    best_score = new_score
                    best_content = result.content
                    print(f"   ‚úÖ New best score: {best_score:.1f}")

                    # Save the improved content
                    save_component_to_file_original(material, component_type, best_content)
                    print(f"   üíæ Saved improved content to file")

                # Check if we've reached the target
                if best_score >= target_score:
                    print(f"üéØ Target score reached: {best_score:.1f} >= {target_score}")
                    break

            except Exception as e:
                print(f"   ‚ùå Iteration {iteration} failed: {e}")
                continue

        # Final result
        if best_score >= target_score:
            print("‚úÖ Optimization successful!")
            return True
        else:
            print(f"‚ö†Ô∏è Optimization completed but target not fully reached")
            print(f"   üìä Final score: {best_score:.1f} (target: {target_score:.1f})")
            print(f"   üìà Total improvement: {best_score - current_score:+.1f} points")
            return best_score > current_score  # Return true if any improvement

    except Exception as e:
        print(f"‚ùå Real optimization workflow failed: {e}")
        return False


def create_arg_parser():
    """Create and return the argument parser."""
    parser = argparse.ArgumentParser(
        description="Z-Beam Dynamic Content Generation System",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
EXAMPLES:
  python3 run.py                                    # Generate all materials (batch mode)
  python3 run.py --material "Copper"                # Generate all components for Copper
  python3 run.py --material "Steel" --components "frontmatter,content"  # Specific components
  python3 run.py --material "Aluminum" --author 2   # Generate with Italian writing style
  python3 run.py --optimize-only --material "Steel" # Optimize specific Steel content
  python3 run.py --optimize-only --component "text" # Optimize all materials in text component
  python3 run.py --list-materials                   # List all available materials
  python3 run.py --show-config                      # Show component configuration
  python3 run.py --yaml                            # Validate and fix YAML errors
  python3 run.py --clean                           # Remove all generated content files
  python3 run.py --test-api                        # Test API connection
        """,
    )

    # Main operation modes
    parser.add_argument("--material", help="Generate content for specific material")
    parser.add_argument("--components", help="Comma-separated list of components to generate")
    parser.add_argument("--author", type=int, help="Author ID for country-specific writing style")
    parser.add_argument("--start-index", type=int, default=1, help="Start batch generation at specific material index")
    parser.add_argument("--yaml", action="store_true", help="Validate and fix YAML errors")
    parser.add_argument("--test-api", action="store_true", help="Test API connection")
    parser.add_argument("--test", action="store_true", help="Run comprehensive test suite")
    parser.add_argument("--check-env", action="store_true", help="Check environment variables and API keys")
    parser.add_argument("--clean", action="store_true", help="Remove all generated content files")
    parser.add_argument("--content-batch", action="store_true", help="Clear content directory and generate content component for first 8 material categories")
    parser.add_argument("--optimize-only", action="store_true", help="Run AI detection optimization only (no content generation)")
    parser.add_argument("--component", default="text", help="Component type to optimize (default: text)")

    # Listing operations
    parser.add_argument("--list-materials", action="store_true", help="List all available materials")
    parser.add_argument("--list-components", action="store_true", help="List all available components")
    parser.add_argument("--list-authors", action="store_true", help="List all available authors")
    parser.add_argument("--show-config", action="store_true", help="Show component configuration")

    # General options
    parser.add_argument("--verbose", "-v", action="store_true", help="Enable verbose logging")

    return parser


def main():
    """Main entry point for Z-Beam clean generation system."""
    parser = create_arg_parser()
    args = parser.parse_args()

    # Set up logging level
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    try:
        # Route to appropriate operation
        if args.yaml:
            success = run_yaml_validation()

        elif args.test:
            success = run_comprehensive_tests()

        elif args.clean:
            success = clean_content_components()

        elif args.optimize_only:
            # Optimization-only mode
            component_type = args.component or "text"
            if args.material:
                # Optimize specific material
                success = run_optimization_only(
                    material=args.material,
                    component_type=component_type,
                    author_id=args.author
                )
            else:
                # Optimize all materials in component folder
                success = run_optimization_batch(
                    component_type=component_type,
                    author_id=args.author
                )

        elif (
            args.list_materials
            or args.list_components
            or args.list_authors
            or args.show_config
            or args.check_env
        ):
            # List operations and configuration display
            if args.show_config:
                show_component_configuration()
                success = True
            elif args.check_env:
                check_environment()
                success = True
            else:
                try:
                    from generators.dynamic_generator import DynamicGenerator
                    generator = DynamicGenerator()

                    if args.list_materials:
                        materials = generator.get_available_materials()
                        print(f"üìã Available materials ({len(materials)}):")
                        for i, material in enumerate(sorted(materials), 1):
                            print(f"   {i:3d}. {material}")

                    if args.list_components:
                        components = generator.get_available_components()
                        print(f"üîß Available components ({len(components)}):")
                        for i, component in enumerate(sorted(components), 1):
                            print(f"   {i}. {component}")

                    if args.list_authors:
                        list_authors()

                    success = True
                except ImportError as e:
                    print(f"‚ùå Error importing generator: {e}")
                    success = False

        else:
            # Dynamic generation mode (default)
            components_list = None
            if args.components:
                components_list = [c.strip() for c in args.components.split(",")]

            success = run_dynamic_generation(
                material=args.material,
                components=components_list,
                test_api=args.test_api,
                author_id=args.author,
                start_index=args.start_index,
            )

        sys.exit(0 if success else 1)

    except KeyboardInterrupt:
        print("\n\nüõë Operation interrupted by user.")
        sys.exit(0)
    except Exception as e:
        print(f"‚ùå Error running operation: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
