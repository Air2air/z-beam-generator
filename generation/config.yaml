# Generation Configuration
# Single-pass production generation

# Quality Gate Settings (used for post-generation analysis)
# Thresholds for logging and learning - generation always succeeds
quality_gates:
  realism_threshold: 3.0                 # Minimum realism score for logging
  max_retry_attempts: 5                  # Maximum generation attempts
  voice_authenticity_threshold: 3.0      # Voice authenticity minimum
  tonal_consistency_threshold: 3.0       # Tonal consistency minimum
  winston_threshold: 0.70                # Winston AI detection threshold (70% AI allowed)
  require_zero_ai_tendencies: false      # Allow AI patterns
  adaptive_threshold: true               # Learn from 75th percentile of successful content

# Evaluation Settings
evaluation:
  temperature: 0.2                       # Low temperature for consistent evaluation
  model: "grok-beta"                     # Evaluation model (Grok for subjective)
  verbose: true                          # Print detailed evaluation output

# Base Voice Parameters (Before Learning/Adjustment)
# These are the starting baseline - RealismOptimizer adjusts during retry
voice_parameters:
  emotional_tone: 0.3                    # Base: moderate emotion (0.0-1.0)
  opinion_rate: 0.2                      # Base: low opinion frequency (0.0-1.0)
  structural_predictability: 0.5         # Base: moderate structure (0.0-1.0)
  sentence_rhythm_variation: 1.0         # Base: maximum variation (0.0-1.0) - triggers 'varied' rhythm pattern
  imperfection_tolerance: 0.4            # Base: moderate imperfections (0.0-1.0)
  trait_frequency: 0.5                   # Base: moderate personality (0.0-1.0)
  colloquialism_frequency: 0.3           # Base: low casual language (0.0-1.0)
  technical_intensity: 1                 # Base: minimal technical detail (1-3 scale) - reduced jargon

# (simple_mode section REMOVED - always production mode)

# Length Variation Control (1-10 scale)
# This SINGLE slider controls variation for ALL components
# Calculation: variation_pct = 10% + (slider * 5%)
# Examples:
#   1 = ±15% (target 100 → range 85-115)
#   5 = ±35% (target 100 → range 65-135) 
#   10 = ±60% (target 100 → range 40-160)
length_variation_range: 10               # Maximum variation: ±60%

# Word Count Variation for Structural Diversity (0.0-1.0 scale)
# Applied in prompt_builder.py to create ranges instead of exact targets
# Used by structural_variation_checker.py to validate batch diversity
# Calculation: range = target ± (target * word_count_variation)
# Examples:
#   0.05 = ±5% (target 100 → range 95-105)
#   0.10 = ±10% (target 100 → range 90-110)
#   0.20 = ±20% (target 100 → range 80-120)
# Recommended: 0.10 (±10%) - supports ≥5% variance requirement
word_count_variation: 0.50               # ±50% variation for maximum diversity

# Randomization Targets Configuration
# MOVED TO DOMAIN-SPECIFIC CONFIGS:
# - Materials: domains/materials/config.yaml (structures, property_strategies, warning_placements, length, subtitle_length)
# - Settings: domains/settings/config.yaml (voices, rhythms)
# 
# Shared randomization targets (used across all domains):
randomization_targets:
  # Voice styles and rhythms now in domain configs
  # Material-specific structures now in domains/materials/config.yaml
  # Settings-specific voices now in domains/settings/config.yaml
  
# Winston Feedback Database
winston_feedback_db_path: "z-beam.db"    # SQLite database for Winston feedback

# Component Extraction Strategies
# Word counts are defined in domain prompts (Option B: Prompts Only)
# Config only defines HOW to parse the LLM output
component_extraction:
  micro:
    extraction_strategy: before_after  # Extract before/after paragraphs
  material_description:
    extraction_strategy: raw            # Return text as-is
  settings_description:
    extraction_strategy: raw            # Return text as-is
  description:
    extraction_strategy: raw            # Return text as-is (contamination descriptions)
  component_summary:
    extraction_strategy: raw            # Return text as-is (single component description)
  component_summaries:
    extraction_strategy: yaml           # Parse as YAML (deprecated monolithic)
  faq:
    extraction_strategy: json_list      # Parse as JSON array

# Component Token Targets
# Used by config_loader.get_max_tokens() to calculate API max_tokens
# Calculation: target_words × 1.3 = tokens
component_lengths:
  micro:
    target: 50                          # ~65 tokens
  material_description:
    target: 100                         # ~130 tokens
  settings_description:
    target: 100                         # ~130 tokens
  description:
    target: 200                         # ~260 tokens (contamination descriptions)
  component_summary:
    target: 70                          # 2 sentences × ~35 words = ~91 tokens
  faq:
    target: 500                         # FAQ can be longer (~650 tokens)

# Dynamic Calculation Parameters
# Zero hardcoded values policy: All calculation factors configured here
dynamic_calculations:
  # Completion detection (prevent truncation)
  completion:
    incomplete_patterns:
      - "\\s+$"                    # Trailing whitespace
      - "[^.!?]$"                 # No ending punctuation
      - "\\band\\s*$"              # Ends with "and"
      - "\\bto\\s*$"               # Ends with "to"
      - "\\bthat\\s*$"             # Ends with "that"
      - "\\bthe\\s*$"              # Ends with "the"
    max_retry_attempts: 3        # Try up to 3 times for completion
    token_increases: [650, 800, 1000]  # Very high token limits - effectively no limit
  
  # Token calculation (NO MULTIPLIER - direct word to token conversion)
  token_conversion:
    words_to_tokens_ratio: 1.3           # Tokens per word approximation
    # REMOVED: multiplier_min/max (was causing double-conversion)
  
  # API penalty ranges based on humanness_intensity (1-10)
  penalties:
    low_humanness:                       # humanness 1-3
      frequency: 0.0
      presence: 0.0
    medium_humanness:                    # humanness 4-7
      frequency_max: 0.6                 # Scale 0.0 to this
      presence_max: 0.6
    high_humanness:                      # humanness 8-10
      frequency_min: 0.6                 # Start from this
      frequency_max: 1.2                 # Scale to this
      presence_min: 0.6
      presence_max: 1.2
  
  # Retry behavior ranges
  retry:
    attempts_min: 3
    attempts_max: 7
    temp_increase_min: 0.05
    temp_increase_max: 0.15
  
  # Threshold adjustments
  thresholds:
    detection_adjustment_range: 15       # ±15 from base
    detection_min: 20
    detection_max: 60
    confidence_adjustment_range: 10      # ±10 from base
    readability_adjustment_range: 10     # ±10 from base

# What gets disabled in simple mode:
disabled_features:
  - temperature_advisor                  # No dynamic temperature learning
  - pattern_learner                      # No risky pattern detection
  - prompt_optimizer                     # No prompt enhancement
  - weight_learner                       # No composite weight learning
  - fix_strategy_manager                 # No adaptive fix strategies
  - success_predictor                    # No success prediction
  - stuck_pattern_detection              # No stuck pattern fresh regen
  
# What stays enabled:
enabled_features:
  - winston_detection                    # Winston AI quality check
  - realism_evaluation                   # Realism scoring
  - readability_check                    # Readability validation
  - subjective_validation                # Subjective language check
  - database_logging                     # Log results for later analysis
