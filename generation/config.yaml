# Generation Configuration
# Quality-gated generation with automatic retry and parameter adjustment

# Quality Gate Settings
# CRITICAL: Thresholds are LEARNED dynamically from database (ThresholdManager)
# These fallback values are ONLY used when insufficient learning data (<10 samples)
quality_gates:
  realism_threshold_fallback: 3.0        # PRODUCTION MODE: Accept good-enough content (was 4.0)
  max_retry_attempts: 5                  # Maximum generation attempts before failure
  voice_authenticity_threshold_fallback: 3.0  # PRODUCTION MODE: Accept good-enough content (was 4.0)
  tonal_consistency_threshold_fallback: 3.0   # PRODUCTION MODE: Accept good-enough content (was 4.0)
  winston_threshold_fallback: 0.70       # PRODUCTION MODE: 70% AI allowed (was 0.50)
  require_zero_ai_tendencies: false      # RELAXED: Allow AI patterns
  adaptive_threshold: true               # Learn from 75th percentile of successful content

# Evaluation Settings
evaluation:
  temperature: 0.2                       # Low temperature for consistent evaluation
  model: "grok-beta"                     # Evaluation model (Grok for subjective)
  verbose: true                          # Print detailed evaluation output

# Base Voice Parameters (Before Learning/Adjustment)
# These are the starting baseline - RealismOptimizer adjusts during retry
voice_parameters:
  emotional_tone: 0.3                    # Base: moderate emotion (0.0-1.0)
  opinion_rate: 0.2                      # Base: low opinion frequency (0.0-1.0)
  structural_predictability: 0.5         # Base: moderate structure (0.0-1.0)
  sentence_rhythm_variation: 1.0         # Base: maximum variation (0.0-1.0) - triggers 'varied' rhythm pattern
  imperfection_tolerance: 0.4            # Base: moderate imperfections (0.0-1.0)
  trait_frequency: 0.5                   # Base: moderate personality (0.0-1.0)
  colloquialism_frequency: 0.3           # Base: low casual language (0.0-1.0)
  technical_intensity: 1                 # Base: minimal technical detail (1-3 scale) - reduced jargon

# Simple Mode Configuration (Legacy - Deprecated)
# Use quality_gates instead for production
simple_mode:
  enabled: false                         # DISABLED: Using quality-gated generation
  fixed_temperature: 0.9                 # Fixed temperature (proven to work)
  max_attempts: 1                        # Single-pass generation (no retries in generation phase)
  temperature_increase_per_retry: 0.0    # N/A - no retries in generation phase

# Length Variation Control (1-10 scale)
# This SINGLE slider controls variation for ALL components
# Calculation: variation_pct = 10% + (slider * 5%)
# Examples:
#   1 = ±15% (target 100 → range 85-115)
#   5 = ±35% (target 100 → range 65-135) 
#   10 = ±60% (target 100 → range 40-160)
length_variation_range: 10               # Maximum variation: ±60%

# Word Count Variation for Structural Diversity (0.0-1.0 scale)
# Applied in prompt_builder.py to create ranges instead of exact targets
# Used by structural_variation_checker.py to validate batch diversity
# Calculation: range = target ± (target * word_count_variation)
# Examples:
#   0.05 = ±5% (target 100 → range 95-105)
#   0.10 = ±10% (target 100 → range 90-110)
#   0.20 = ±20% (target 100 → range 80-120)
# Recommended: 0.10 (±10%) - supports ≥5% variance requirement
word_count_variation: 0.50               # ±50% variation for maximum diversity

# Randomization Targets Configuration
# All randomization options for humanness layer generation
# Zero hardcoded values policy: ALL variation options configured here
randomization_targets:
  
  # Length variation targets (word counts)
  # Reduced 15% to account for LLM tendency to exceed targets
  length:
    short:
      range: [42, 63]
      description: "CONCISE - essential points only"
      probability: 0.33
    medium:
      range: [63, 93]
      description: "BALANCED - key aspects covered"
      probability: 0.33
    long:
      range: [93, 127]
      description: "DETAILED - comprehensive coverage"
      probability: 0.34
  
  # Structural approaches
  structures:
    problem_focused:
      label: "Problem-Focused"
      description: "Start with challenge → explain why → solution"
      probability: 0.20
    contrast_based:
      label: "Contrast-Based"
      description: "Compare materials → highlight difference → impact"
      probability: 0.20
    process_focused:
      label: "Process-Focused"
      description: "Walk through setup → embed properties naturally"
      probability: 0.20
    experience_based:
      label: "Experience-Based"
      description: "Share what works → why → what to avoid"
      probability: 0.20
    property_driven:
      label: "Property-Driven"
      description: "Lead with ONE property → deep exploration"
      probability: 0.20
  
  # Voice styles (author personas)
  voices:
    direct_instructor:
      label: "DIRECT INSTRUCTOR"
      examples: ["You must", "Make sure you", "Start with"]
      description: "Commanding, prescriptive"
      probability: 0.33
    team_collaborator:
      label: "TEAM COLLABORATOR"
      examples: ["We typically", "We've found", "In our experience"]
      description: "Inclusive, shared experience"
      probability: 0.33
    experience_sharer:
      label: "EXPERIENCE SHARER"
      examples: ["I've seen", "This works when", "Tends to"]
      description: "Observational, practical"
      probability: 0.34
  
  # Sentence rhythm patterns
  rhythms:
    short_punchy:
      label: "SHORT & PUNCHY"
      description: "Use mostly 5-10 word sentences. Rapid fire. Direct impact. Build momentum."
      sentence_range: [5, 10]
      probability: 0.33
    mixed_cadence:
      label: "MIXED CADENCE"
      description: "Alternate short (5-10 word) and long (20-30 word) sentences for natural rhythm."
      short_range: [5, 10]
      long_range: [20, 30]
      probability: 0.33
    complex_compound:
      label: "COMPLEX COMPOUND"
      description: "Use longer, detailed sentences (15-30 words) with clauses and technical depth."
      sentence_range: [15, 30]
      probability: 0.34
  
  # Property integration strategies
  property_strategies:
    scattered:
      label: "SCATTERED INTEGRATION"
      description: "Distribute properties throughout narrative (never list)"
      probability: 0.25
    deep_dive:
      label: "DEEP DIVE ONE"
      description: "Focus deeply on ONE property first, mention others briefly later"
      probability: 0.25
    comparative:
      label: "COMPARATIVE"
      description: "Use properties to compare/contrast with similar materials"
      probability: 0.25
    problem_solution:
      label: "PROBLEM-SOLUTION"
      description: "Present property as solution to specific challenge"
      probability: 0.25
  
  # Warning placement options
  warning_placements:
    early:
      label: "EARLY WARNING"
      description: "Start with critical safety/setup concern (first 2-3 sentences)"
      probability: 0.33
    mid_flow:
      label: "MID-FLOW WARNING"
      description: "Embed warning naturally in middle of narrative"
      probability: 0.33
    concluding:
      label: "CONCLUDING WARNING"
      description: "End with key caution or recommendation"
      probability: 0.34
  
# Winston Feedback Database
winston_feedback_db_path: "z-beam.db"    # SQLite database for Winston feedback

# Component Lengths (word count targets ONLY)
# Global length_variation_range applies uniformly to all components
# min/max calculated dynamically: target ± (target * variation_pct)
component_lengths:
  caption:
    target: 75                         # Target word count (variation applied from global slider)
    extraction_strategy: before_after  # Extract before/after sections
  
  subtitle:
    target: 25                         # Target word count (variation applied from global slider)
    extraction_strategy: raw           # Return text as-is
  
  faq:
    target: 150                        # Target word count (variation applied from global slider)
    extraction_strategy: json_list     # Parse JSON array
  
  description:
    target: 1000                       # No effective token limit - let prompt instructions control length
    extraction_strategy: raw           # Return text as-is

# Dynamic Calculation Parameters
# Zero hardcoded values policy: All calculation factors configured here
dynamic_calculations:
  # Completion detection (prevent truncation)
  completion:
    incomplete_patterns:
      - "\\s+$"                    # Trailing whitespace
      - "[^.!?]$"                 # No ending punctuation
      - "\\band\\s*$"              # Ends with "and"
      - "\\bto\\s*$"               # Ends with "to"
      - "\\bthat\\s*$"             # Ends with "that"
      - "\\bthe\\s*$"              # Ends with "the"
    max_retry_attempts: 3        # Try up to 3 times for completion
    token_increases: [650, 800, 1000]  # Very high token limits - effectively no limit
  
  # Token calculation (NO MULTIPLIER - direct word to token conversion)
  token_conversion:
    words_to_tokens_ratio: 1.3           # Tokens per word approximation
    # REMOVED: multiplier_min/max (was causing double-conversion)
  
  # API penalty ranges based on humanness_intensity (1-10)
  penalties:
    low_humanness:                       # humanness 1-3
      frequency: 0.0
      presence: 0.0
    medium_humanness:                    # humanness 4-7
      frequency_max: 0.6                 # Scale 0.0 to this
      presence_max: 0.6
    high_humanness:                      # humanness 8-10
      frequency_min: 0.6                 # Start from this
      frequency_max: 1.2                 # Scale to this
      presence_min: 0.6
      presence_max: 1.2
  
  # Retry behavior ranges
  retry:
    attempts_min: 3
    attempts_max: 7
    temp_increase_min: 0.05
    temp_increase_max: 0.15
  
  # Threshold adjustments
  thresholds:
    detection_adjustment_range: 15       # ±15 from base
    detection_min: 20
    detection_max: 60
    confidence_adjustment_range: 10      # ±10 from base
    readability_adjustment_range: 10     # ±10 from base

# What gets disabled in simple mode:
disabled_features:
  - temperature_advisor                  # No dynamic temperature learning
  - pattern_learner                      # No risky pattern detection
  - prompt_optimizer                     # No prompt enhancement
  - weight_learner                       # No composite weight learning
  - fix_strategy_manager                 # No adaptive fix strategies
  - success_predictor                    # No success prediction
  - stuck_pattern_detection              # No stuck pattern fresh regen
  
# What stays enabled:
enabled_features:
  - winston_detection                    # Winston AI quality check
  - realism_evaluation                   # Realism scoring
  - readability_check                    # Readability validation
  - subjective_validation                # Subjective language check
  - database_logging                     # Log results for later analysis
