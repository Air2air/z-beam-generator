#!/usr/bin/env python3
"""
Pipeline Process Service

Handles pipeline-specific frontmatter sections:
- Environmental impact assessment
- Regulatory standards (universal + material-specific)
- Outcome metrics
- Applications discovery from industry data

These sections represent the "pipeline" of information that flows
through the generation process, building up the complete frontmatter.

Follows fail-fast principles:
- No mocks or fallbacks in production
- Explicit error handling
- Validates required configuration data
"""

import logging
from typing import Dict, List

from generation.config.config_loader import ProcessingConfig
from shared.exceptions import ConfigurationError
from shared.validation.errors import MaterialDataError

logger = logging.getLogger(__name__)


class PipelineProcessService:
    """
    Service for handling pipeline-specific frontmatter sections.
    
    Generates environmental impact, regulatory standards, outcome metrics,
    and applications using AI generation (NO TEMPLATES).
    """
    
    def __init__(
        self,
        api_client,
        environmental_impact_templates: Dict,
        standard_outcome_metrics: Dict,
        universal_regulatory_standards: List[str]
    ):
        """
        Initialize pipeline process service.
        
        Args:
            api_client: AI client for generating descriptions (NO TEMPLATES ALLOWED)
            environmental_impact_templates: Structure templates from Categories.yaml (NO TEXT)
            standard_outcome_metrics: Metric structure definitions from Categories.yaml (NO TEXT)
            universal_regulatory_standards: Universal regulatory standards list
            
        Raises:
            ConfigurationError: If required configuration is missing
        """
        if not api_client:
            raise ConfigurationError("API client required for AI text generation - NO TEMPLATES ALLOWED")
            
        if not environmental_impact_templates:
            raise ConfigurationError("Environmental impact templates required")
        
        if not standard_outcome_metrics:
            raise ConfigurationError("Standard outcome metrics required")
        
        if not universal_regulatory_standards:
            raise ConfigurationError("Universal regulatory standards required")
        
        self.api_client = api_client
        self.environmental_impact_templates = environmental_impact_templates
        self.standard_outcome_metrics = standard_outcome_metrics
        self.universal_regulatory_standards = universal_regulatory_standards
        self.config = ProcessingConfig()
        self.logger = logger
    
    def add_environmental_impact_section(self, frontmatter: Dict, material_data: Dict) -> Dict:
        """
        Add environmental impact section with AI-generated descriptions.
        NO TEMPLATES - all descriptions generated by AI for this specific material.
        
        Args:
            frontmatter: Current frontmatter dict
            material_data: Material data from Materials.yaml
            
        Returns:
            Updated frontmatter with environmentalImpact section
        """
        try:
            if 'name' not in material_data or not isinstance(material_data['name'], str) or not material_data['name'].strip():
                raise MaterialDataError("Material data missing required non-empty 'name' for environmental impact generation")

            material_name = material_data['name']
            environmental_impact = []
            
            # Generate AI descriptions for each impact type (NO TEMPLATE TEXT)
            for impact_type, template in self.environmental_impact_templates.items():
                if not isinstance(template, dict):
                    raise MaterialDataError(
                        f"Invalid environmental impact template for '{impact_type}': expected dictionary"
                    )
                if 'applicable_industries' not in template or not isinstance(template['applicable_industries'], list):
                    raise MaterialDataError(
                        f"Environmental impact template '{impact_type}' missing required list 'applicable_industries'"
                    )

                benefit_name = impact_type.replace('_', ' ').title()
                
                # Generate material-specific description using AI
                description = self._generate_environmental_impact_description(
                    material_name=material_name,
                    material_data=material_data,
                    benefit_type=benefit_name,
                    industries=template['applicable_industries']
                )
                
                if not description:
                    self.logger.error(f"Failed to generate description for {benefit_name} - BLOCKING (no templates allowed)")
                    raise MaterialDataError(f"AI generation failed for environmentalImpact.{benefit_name} description")
                
                impact_entry = {
                    'benefit': benefit_name,
                    'applicableIndustries': template['applicable_industries'],
                    'description': description  # AI-generated, material-specific
                }
                
                # Generate quantified benefits if structure provided
                if template.get('quantified_benefits'):
                    quantified = self._generate_quantified_benefits(
                        material_name=material_name,
                        benefit_type=benefit_name
                    )
                    if quantified:
                        impact_entry['quantifiedBenefits'] = quantified
                
                environmental_impact.append(impact_entry)
                
            if environmental_impact:
                frontmatter['environmentalImpact'] = environmental_impact
                self.logger.info(f"✅ Generated {len(environmental_impact)} AI environmental impact descriptions for {material_name}")
            else:
                self.logger.error("No environmental impact items generated - BLOCKING")
                raise MaterialDataError("Failed to generate environmentalImpact section")
                
            return frontmatter
            
        except Exception as e:
            self.logger.error(f"Failed to generate environmental impact section: {e}")
            raise MaterialDataError(f"Environmental impact generation failed: {e}")
    
    def add_outcome_metrics_section(self, frontmatter: Dict, material_data: Dict) -> Dict:
        """
        Add outcome metrics section with AI-generated descriptions.
        NO TEMPLATES - all descriptions generated by AI for this specific material.
        
        Args:
            frontmatter: Current frontmatter dict
            material_data: Material data from Materials.yaml
            
        Returns:
            Updated frontmatter with outcomeMetrics section
        """
        try:
            if 'name' not in material_data or not isinstance(material_data['name'], str) or not material_data['name'].strip():
                raise MaterialDataError("Material data missing required non-empty 'name' for outcome metrics generation")

            material_name = material_data['name']
            outcome_metrics = []
            
            # Generate AI descriptions for each metric (NO TEMPLATE TEXT)
            for metric_type, metric_def in self.standard_outcome_metrics.items():
                if not isinstance(metric_def, dict):
                    raise MaterialDataError(
                        f"Invalid outcome metric definition for '{metric_type}': expected dictionary"
                    )

                required_metric_lists = ['measurement_methods', 'factors_affecting', 'units']
                missing_metric_keys = [key for key in required_metric_lists if key not in metric_def or not isinstance(metric_def[key], list)]
                if missing_metric_keys:
                    raise MaterialDataError(
                        f"Outcome metric definition '{metric_type}' missing required list fields: {', '.join(missing_metric_keys)}"
                    )

                metric_name = metric_type.replace('_', ' ').title()
                
                # Generate material-specific description using AI
                description = self._generate_outcome_metric_description(
                    material_name=material_name,
                    material_data=material_data,
                    metric_type=metric_name,
                    measurement_methods=metric_def['measurement_methods'],
                    factors_affecting=metric_def['factors_affecting']
                )
                
                if not description:
                    self.logger.error(f"Failed to generate description for {metric_name} - BLOCKING (no templates allowed)")
                    raise MaterialDataError(f"AI generation failed for outcomeMetrics.{metric_name} description")
                
                metric_entry = {
                    'metric': metric_name,
                    'description': description,  # AI-generated, material-specific
                    'measurementMethods': metric_def['measurement_methods'],
                    'factorsAffecting': metric_def['factors_affecting'],
                    'units': metric_def['units']
                }
                
                # Include typical ranges if provided
                if metric_def.get('typical_ranges'):
                    metric_entry['typicalRanges'] = metric_def['typical_ranges']
                    
                outcome_metrics.append(metric_entry)
                
            if outcome_metrics:
                frontmatter['outcomeMetrics'] = outcome_metrics
                self.logger.info(f"✅ Generated {len(outcome_metrics)} AI outcome metric descriptions for {material_name}")
            else:
                self.logger.error("No outcome metrics generated - BLOCKING")
                raise MaterialDataError("Failed to generate outcomeMetrics section")
                
            return frontmatter
            
        except Exception as e:
            self.logger.error(f"Failed to generate outcome metrics section: {e}")
            raise MaterialDataError(f"Outcome metrics generation failed: {e}")
    
    def add_regulatory_standards_section(self, frontmatter: Dict, material_data: Dict) -> Dict:
        """
        Add regulatory standards combining universal standards with material-specific ones.
        
        Args:
            frontmatter: Current frontmatter dict
            material_data: Material data from Materials.yaml
            
        Returns:
            Updated frontmatter with regulatory_standards section
        """
        try:
            all_regulatory_standards = []
            
            # Add universal regulatory standards (applies to ALL materials)
            if self.universal_regulatory_standards:
                all_regulatory_standards.extend(self.universal_regulatory_standards)
                self.logger.info(f"Added {len(self.universal_regulatory_standards)} universal regulatory standards")
            
            # Add material-specific regulatory standards from Materials.yaml
            material_specific_standards = []
            
            # Check for standards in metadata (optimized structure)
            if 'metadata' in material_data and 'regulatory_standards' in material_data['metadata']:
                material_specific_standards = material_data['metadata']['regulatory_standards']
            
            if material_specific_standards:
                all_regulatory_standards.extend(material_specific_standards)
                self.logger.info(f"Added {len(material_specific_standards)} material-specific regulatory standards")
            
            # Add combined regulatory standards to frontmatter
            if all_regulatory_standards:
                frontmatter['regulatory_standards'] = all_regulatory_standards
                self.logger.info(f"Total regulatory standards: {len(all_regulatory_standards)} (universal + specific)")
            else:
                # Ensure universal standards are always present
                frontmatter['regulatory_standards'] = self.universal_regulatory_standards
                
            return frontmatter
            
        except Exception as e:
            self.logger.error(f"Failed to add regulatory standards: {e}")
            raise MaterialDataError(f"Failed to add regulatory standards: {e}") from e
    
    def generate_applications_from_unified_industry_data(
        self,
        material_name: str,
        material_data: Dict
    ) -> List[str]:
        """
        Generate applications using unified industry data structure.
        
        Combines category primary industries with material-specific industry overrides.
        
        Args:
            material_name: Name of the material
            material_data: Material data from Materials.yaml
            
        Returns:
            List of application/industry strings
            
        Raises:
            MaterialDataError: If material category is missing
        """
        try:
            applications = []
            
            if 'category' not in material_data:
                raise MaterialDataError(
                    f"Material category required for {material_name} - "
                    "no fallbacks allowed per fail-fast principles"
                )
            
            material_category = material_data['category']
            
            # Get category primary industries from Categories.yaml (unified source)
            category_primary_industries = []
            if material_category in self.category_enhanced_data:
                enhanced_data = self.category_enhanced_data[material_category]
                if 'industryTags' in enhanced_data:
                    industry_tags_data = enhanced_data['industryTags']
                    if 'primary_industries' in industry_tags_data:
                        category_primary_industries = industry_tags_data['primary_industries']
            
            # Check for material-specific industry overrides (preserved unique tags)
            material_specific_industries = []
            if 'metadata' in material_data and 'industryTags' in material_data['metadata']:
                material_specific_industries = material_data['metadata']['industryTags']
            
            # Combine category primary + material-specific industries
            all_industries = list(set(category_primary_industries + material_specific_industries))
            
            if all_industries:
                applications = all_industries
                self.logger.info(
                    f"Generated {len(applications)} applications for {material_name} "
                    f"({len(category_primary_industries)} from category, "
                    f"{len(material_specific_industries)} material-specific)"
                )
            else:
                self.logger.warning(f"No applications found for {material_name}")
            
            return applications
            
        except MaterialDataError:
            # Re-raise MaterialDataErrors
            raise
        except Exception as e:
            self.logger.error(f"Failed to generate applications for {material_name}: {e}")
            raise MaterialDataError(f"Application generation failed for {material_name}: {e}")
    
    def validate_pipeline_configuration(self) -> bool:
        """
        Validate that pipeline configuration is complete.
        
        Returns:
            True if configuration appears complete, False otherwise
        """
        issues = []
        
        if not self.environmental_impact_templates:
            issues.append("Missing environmental impact templates")
        
        if not self.standard_outcome_metrics:
            issues.append("Missing standard outcome metrics")
        
        if not self.universal_regulatory_standards:
            issues.append("Missing universal regulatory standards")
        
        if issues:
            self.logger.warning(f"Pipeline configuration issues: {', '.join(issues)}")
            return False
        
        return True
    
    def get_pipeline_statistics(self, frontmatter: Dict) -> Dict[str, int]:
        """
        Get statistics about pipeline sections in frontmatter.
        
        Args:
            frontmatter: Generated frontmatter dict
            
        Returns:
            Dict with counts for each pipeline section
        """
        required_sections = ['environmentalImpact', 'outcomeMetrics', 'regulatory_standards', 'applications']
        missing_sections = [section for section in required_sections if section not in frontmatter]
        if missing_sections:
            raise MaterialDataError(
                f"Frontmatter missing required pipeline sections for statistics: {', '.join(missing_sections)}"
            )

        for section in required_sections:
            if not isinstance(frontmatter[section], list):
                raise MaterialDataError(
                    f"Frontmatter section '{section}' must be a list for statistics calculation"
                )

        return {
            'environmental_impact_count': len(frontmatter['environmentalImpact']),
            'outcome_metrics_count': len(frontmatter['outcomeMetrics']),
            'regulatory_standards_count': len(frontmatter['regulatory_standards']),
            'applications_count': len(frontmatter['applications'])
        }
    
    def _generate_environmental_impact_description(
        self,
        material_name: str,
        material_data: Dict,
        benefit_type: str,
        industries: List[str]
    ) -> str:
        """
        Generate AI description for environmental impact benefit.
        NO TEMPLATES - pure AI generation for this specific material.
        
        Args:
            material_name: Name of the material
            material_data: Material data from Materials.yaml
            benefit_type: Type of environmental benefit
            industries: Applicable industries
            
        Returns:
            AI-generated description
        """
        if 'properties' not in material_data or not isinstance(material_data['properties'], dict):
            raise MaterialDataError(
                f"Material '{material_name}' missing required 'properties' dictionary for environmental impact generation"
            )

        properties = material_data['properties']
        required_properties = ['thermalConductivity', 'meltingPoint']
        missing_properties = [key for key in required_properties if key not in properties]
        if missing_properties:
            raise MaterialDataError(
                f"Material '{material_name}' missing required properties for environmental impact generation: {', '.join(missing_properties)}"
            )

        if 'category' not in material_data or not isinstance(material_data['category'], str) or not material_data['category'].strip():
            raise MaterialDataError(
                f"Material '{material_name}' missing required non-empty 'category' for environmental impact generation"
            )

        if not industries:
            raise MaterialDataError(
                f"Environmental impact benefit '{benefit_type}' for material '{material_name}' missing applicable industries"
            )

        prompt = f"""Generate a concise technical description for the environmental benefit "{benefit_type}" specifically for {material_name} laser cleaning.

Material properties:
- Thermal conductivity: {properties['thermalConductivity']}
- Melting point: {properties['meltingPoint']}
- Material category: {material_data['category']}

Applicable industries: {', '.join(industries)}

Focus on material-specific aspects of this environmental benefit. Be technical and specific.
Output ONLY the description text, no prefix or explanation."""

        try:
            from generation.config.dynamic_config import DynamicConfig
            dynamic_config = DynamicConfig()
            
            response = self.api_client.generate_simple(
                prompt=prompt,
                max_tokens=int(self.config.get_required_config('constants.pipeline_process_service.environmental_impact_description_max_tokens')),
                temperature=dynamic_config.calculate_temperature('default')
            )
            
            description = response.content.strip()
            if not description or len(description) < 10:
                raise ValueError(f"Generated description too short: {description}")
            
            self.logger.info(f"✅ AI generated environmentalImpact description for {material_name}.{benefit_type}")
            return description
            
        except Exception as e:
            self.logger.error(f"❌ Failed to generate AI description for {benefit_type}: {e}")
            raise MaterialDataError(f"AI generation failed for environmentalImpact description: {e}")
    
    def _generate_quantified_benefits(
        self,
        material_name: str,
        benefit_type: str
    ) -> str:
        """
        Generate AI quantified benefits statement.
        
        Args:
            material_name: Name of the material
            benefit_type: Type of environmental benefit
            
        Returns:
            AI-generated quantified benefits statement
        """
        prompt = f"""Generate a brief quantified benefits statement for "{benefit_type}" in {material_name} laser cleaning.

Include specific percentages or measurable outcomes. Be concise (one sentence).
Output ONLY the statement, no prefix or explanation."""

        try:
            from generation.config.dynamic_config import DynamicConfig
            dynamic_config = DynamicConfig()
            
            response = self.api_client.generate_simple(
                prompt=prompt,
                max_tokens=int(self.config.get_required_config('constants.pipeline_process_service.quantified_benefits_max_tokens')),
                temperature=dynamic_config.calculate_temperature('default')
            )
            
            return response.content.strip()
            
        except Exception as e:
            self.logger.warning(f"Failed to generate quantified benefits: {e}")
            return ""
    
    def _generate_outcome_metric_description(
        self,
        material_name: str,
        material_data: Dict,
        metric_type: str,
        measurement_methods: List[str],
        factors_affecting: List[str]
    ) -> str:
        """
        Generate AI description for outcome metric.
        NO TEMPLATES - pure AI generation for this specific material.
        
        Args:
            material_name: Name of the material
            material_data: Material data from Materials.yaml
            metric_type: Type of outcome metric
            measurement_methods: Available measurement methods
            factors_affecting: Factors affecting this metric
            
        Returns:
            AI-generated description
        """
        if 'properties' not in material_data or not isinstance(material_data['properties'], dict):
            raise MaterialDataError(
                f"Material '{material_name}' missing required 'properties' dictionary for outcome metric generation"
            )

        properties = material_data['properties']
        required_properties = ['hardness', 'surfaceRoughness']
        missing_properties = [key for key in required_properties if key not in properties]
        if missing_properties:
            raise MaterialDataError(
                f"Material '{material_name}' missing required properties for outcome metric generation: {', '.join(missing_properties)}"
            )

        if 'category' not in material_data or not isinstance(material_data['category'], str) or not material_data['category'].strip():
            raise MaterialDataError(
                f"Material '{material_name}' missing required non-empty 'category' for outcome metric generation"
            )

        if not measurement_methods:
            raise MaterialDataError(
                f"Outcome metric '{metric_type}' for material '{material_name}' missing measurement methods"
            )

        if not factors_affecting:
            raise MaterialDataError(
                f"Outcome metric '{metric_type}' for material '{material_name}' missing factors affecting data"
            )

        prompt = f"""Generate a concise technical description for the outcome metric "{metric_type}" specifically for {material_name} laser cleaning.

Material properties:
- Hardness: {properties['hardness']}
- Surface properties: {properties['surfaceRoughness']}
- Material category: {material_data['category']}

Measurement methods available: {', '.join(measurement_methods)}
Key factors affecting outcome: {', '.join(factors_affecting[:3])}

Focus on material-specific measurement considerations. Be technical and specific.
Output ONLY the description text, no prefix or explanation."""

        try:
            from generation.config.dynamic_config import DynamicConfig
            dynamic_config = DynamicConfig()
            
            response = self.api_client.generate_simple(
                prompt=prompt,
                max_tokens=int(self.config.get_required_config('constants.pipeline_process_service.outcome_metric_description_max_tokens')),
                temperature=dynamic_config.calculate_temperature('default')
            )
            
            description = response.content.strip()
            if not description or len(description) < 10:
                raise ValueError(f"Generated description too short: {description}")
            
            self.logger.info(f"✅ AI generated outcomeMetrics description for {material_name}.{metric_type}")
            return description
            
        except Exception as e:
            self.logger.error(f"❌ Failed to generate AI description for {metric_type}: {e}")
            raise MaterialDataError(f"AI generation failed for outcomeMetrics description: {e}")
