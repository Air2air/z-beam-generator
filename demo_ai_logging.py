#!/usr/bin/env python3
"""
AI Research Logging Demo - Show verbose AI research in action
"""

import time
from hierarchical_validator import HierarchicalValidator
from pipeline_integration import InvisiblePipelineRunner

def demo_verbose_ai_research_logging():
    """Demonstrate verbose AI research logging across the system"""
    
    print("ğŸ”¬ VERBOSE AI RESEARCH LOGGING DEMONSTRATION")
    print("=" * 60)
    print("This demo shows detailed AI research logging throughout the validation pipeline")
    print()
    
    # Test 1: Hierarchical Validator AI Research Logging
    print("ğŸ“Š TEST 1: Hierarchical Validator AI Research")
    print("-" * 50)
    
    validator = HierarchicalValidator(ai_validation_enabled=True, silent_mode=False)
    
    print(f"âœ… Configuration:")
    print(f"   â€¢ AI Verbose Logging: {validator.ai_verbose_logging}")
    print(f"   â€¢ AI Log Prompts: {validator.ai_log_prompts}")
    print(f"   â€¢ AI Log Timing: {validator.ai_log_timing}")
    print(f"   â€¢ AI Research Logger: {validator.ai_research_logger_enabled}")
    print()
    
    # Load actual data and run validation
    try:
        validator_result = validator.run_hierarchical_validation()
        print(f"ğŸ“Š Hierarchical validation completed")
        print(f"   â€¢ AI Validation Status: {validator_result.get('ai_validation_status', 'Unknown')}")
        print()
    except Exception as e:
        print(f"âš ï¸  Hierarchical validation error: {e}")
        print()
    
    # Test 2: Pipeline Integration AI Research Logging
    print("ğŸ”§ TEST 2: Pipeline Integration AI Research")
    print("-" * 50)
    
    pipeline = InvisiblePipelineRunner(silent_mode=False)
    
    print(f"âœ… Configuration:")
    print(f"   â€¢ AI Verbose Logging: {pipeline.ai_verbose_logging}")
    print(f"   â€¢ AI Log Prompts: {pipeline.ai_log_prompts}")
    print(f"   â€¢ AI Log Timing: {pipeline.ai_log_timing}")
    print(f"   â€¢ AI Research Logger: {pipeline.ai_research_logger_enabled}")
    print()
    
    # Test AI validation of specific material properties
    test_properties = {
        'density': {'value': 2.7, 'unit': 'g/cmÂ³'},
        'thermalConductivity': {'value': 205, 'unit': 'W/mÂ·K'},
        'meltingPoint': {'value': 660, 'unit': 'Â°C'}
    }
    
    try:
        ai_result = pipeline._ai_validate_critical_properties('Aluminum', test_properties)
        print(f"ğŸ¯ AI property validation completed")
        print(f"   â€¢ Validation Passed: {ai_result.get('validation_passed', False)}")
        print(f"   â€¢ Confidence Score: {ai_result.get('confidence_score', 0):.1%}")
        print(f"   â€¢ Properties Validated: {len(ai_result.get('ai_responses', {}))}")
        print()
        
        # Show detailed AI responses
        for prop_name, ai_response in ai_result.get('ai_responses', {}).items():
            valid = ai_response.get('valid', True)
            confidence = ai_response.get('confidence', 0)
            reason = ai_response.get('reason', 'No reason provided')
            print(f"   ğŸ“‹ {prop_name}: {'âœ… VALID' if valid else 'âŒ INVALID'} (confidence: {confidence:.1%})")
            print(f"      Reason: {reason}")
        
    except Exception as e:
        print(f"âš ï¸  Pipeline AI validation error: {e}")
    
    print()
    print("ğŸ‰ DEMONSTRATION COMPLETE!")
    print("The verbose AI research logging is now enabled by default and shows:")
    print("   â€¢ ğŸ¤– AI research calls and timing")
    print("   â€¢ ğŸ“ AI prompts and responses (when enabled)")
    print("   â€¢ ğŸ¯ AI confidence scores and validation results")
    print("   â€¢ âš¡ Detailed timing information")
    print("   â€¢ ğŸ“Š Comprehensive validation summaries")

if __name__ == "__main__":
    demo_verbose_ai_research_logging()